{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import optuna\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV,TimeSeriesSplit, cross_validate, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "\n",
    "# To avoid truncating columns\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "\n",
    "# Setting random seed for reproducibility\n",
    "RANDOM_SEED = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tournament</th>\n",
       "      <th>Stage</th>\n",
       "      <th>Match Type</th>\n",
       "      <th>Match Name</th>\n",
       "      <th>Map</th>\n",
       "      <th>Team A</th>\n",
       "      <th>Team A Score</th>\n",
       "      <th>Team A Attacker Score</th>\n",
       "      <th>Team A Defender Score</th>\n",
       "      <th>Team A Overtime Score</th>\n",
       "      <th>Team B</th>\n",
       "      <th>Team B Score</th>\n",
       "      <th>Team B Attacker Score</th>\n",
       "      <th>Team B Defender Score</th>\n",
       "      <th>Team B Overtime Score</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Rating_TeamA</th>\n",
       "      <th>Average Combat Score_TeamA</th>\n",
       "      <th>Kills_TeamA</th>\n",
       "      <th>Deaths_TeamA</th>\n",
       "      <th>Assists_TeamA</th>\n",
       "      <th>Kills - Deaths (KD)_TeamA</th>\n",
       "      <th>Kill, Assist, Trade, Survive %_TeamA</th>\n",
       "      <th>Average Damage Per Round_TeamA</th>\n",
       "      <th>Headshot %_TeamA</th>\n",
       "      <th>First Kills_TeamA</th>\n",
       "      <th>First Deaths_TeamA</th>\n",
       "      <th>Kills - Deaths (FKD)_TeamA</th>\n",
       "      <th>Rating_TeamB</th>\n",
       "      <th>Average Combat Score_TeamB</th>\n",
       "      <th>Kills_TeamB</th>\n",
       "      <th>Deaths_TeamB</th>\n",
       "      <th>Assists_TeamB</th>\n",
       "      <th>Kills - Deaths (KD)_TeamB</th>\n",
       "      <th>Kill, Assist, Trade, Survive %_TeamB</th>\n",
       "      <th>Average Damage Per Round_TeamB</th>\n",
       "      <th>Headshot %_TeamB</th>\n",
       "      <th>First Kills_TeamB</th>\n",
       "      <th>First Deaths_TeamB</th>\n",
       "      <th>Kills - Deaths (FKD)_TeamB</th>\n",
       "      <th>Loadout Value_TeamA</th>\n",
       "      <th>Remaining Credits_TeamA</th>\n",
       "      <th>Type_TeamA</th>\n",
       "      <th>Loadout Value_TeamB</th>\n",
       "      <th>Remaining Credits_TeamB</th>\n",
       "      <th>Type_TeamB</th>\n",
       "      <th>2k_TeamA</th>\n",
       "      <th>3k_TeamA</th>\n",
       "      <th>4k_TeamA</th>\n",
       "      <th>5k_TeamA</th>\n",
       "      <th>1v1_TeamA</th>\n",
       "      <th>1v2_TeamA</th>\n",
       "      <th>1v3_TeamA</th>\n",
       "      <th>1v4_TeamA</th>\n",
       "      <th>1v5_TeamA</th>\n",
       "      <th>Econ_TeamA</th>\n",
       "      <th>Spike Plants_TeamA</th>\n",
       "      <th>Spike Defuses_TeamA</th>\n",
       "      <th>2k_TeamB</th>\n",
       "      <th>3k_TeamB</th>\n",
       "      <th>4k_TeamB</th>\n",
       "      <th>5k_TeamB</th>\n",
       "      <th>1v1_TeamB</th>\n",
       "      <th>1v2_TeamB</th>\n",
       "      <th>1v3_TeamB</th>\n",
       "      <th>1v4_TeamB</th>\n",
       "      <th>1v5_TeamB</th>\n",
       "      <th>Econ_TeamB</th>\n",
       "      <th>Spike Plants_TeamB</th>\n",
       "      <th>Spike Defuses_TeamB</th>\n",
       "      <th>Elimination_TeamA</th>\n",
       "      <th>Detonated_TeamA</th>\n",
       "      <th>Defused_TeamA</th>\n",
       "      <th>Time Expiry (No Plant)_TeamA</th>\n",
       "      <th>Eliminated_TeamA</th>\n",
       "      <th>Defused Failed_TeamA</th>\n",
       "      <th>Detonation Denied_TeamA</th>\n",
       "      <th>Time Expiry (Failed to Plant)_TeamA</th>\n",
       "      <th>Elimination_TeamB</th>\n",
       "      <th>Detonated_TeamB</th>\n",
       "      <th>Defused_TeamB</th>\n",
       "      <th>Time Expiry (No Plant)_TeamB</th>\n",
       "      <th>Eliminated_TeamB</th>\n",
       "      <th>Defused Failed_TeamB</th>\n",
       "      <th>Detonation Denied_TeamB</th>\n",
       "      <th>Time Expiry (Failed to Plant)_TeamB</th>\n",
       "      <th>KDA_TeamA</th>\n",
       "      <th>Round Win %_TeamA</th>\n",
       "      <th>First Blood %_TeamA</th>\n",
       "      <th>Clutches_TeamA</th>\n",
       "      <th>Attacker Win %_TeamA</th>\n",
       "      <th>Defender Win %_TeamA</th>\n",
       "      <th>Overtime Win %_TeamA</th>\n",
       "      <th>Rating_RollAvg_TeamA</th>\n",
       "      <th>Average Combat Score_RollAvg_TeamA</th>\n",
       "      <th>Average Damage Per Round_RollAvg_TeamA</th>\n",
       "      <th>KDA_RollAvg_TeamA</th>\n",
       "      <th>Kill, Assist, Trade, Survive %_RollAvg_TeamA</th>\n",
       "      <th>Round Win %_RollAvg_TeamA</th>\n",
       "      <th>Attacker Win %_RollAvg_TeamA</th>\n",
       "      <th>Defender Win %_RollAvg_TeamA</th>\n",
       "      <th>Overtime Win %_RollAvg_TeamA</th>\n",
       "      <th>First Blood %_RollAvg_TeamA</th>\n",
       "      <th>Headshot %_RollAvg_TeamA</th>\n",
       "      <th>Clutches_RollAvg_TeamA</th>\n",
       "      <th>Econ_RollAvg_TeamA</th>\n",
       "      <th>Recent Win %_TeamA</th>\n",
       "      <th>KDA_TeamB</th>\n",
       "      <th>Round Win %_TeamB</th>\n",
       "      <th>First Blood %_TeamB</th>\n",
       "      <th>Clutches_TeamB</th>\n",
       "      <th>Attacker Win %_TeamB</th>\n",
       "      <th>Defender Win %_TeamB</th>\n",
       "      <th>Overtime Win %_TeamB</th>\n",
       "      <th>Rating_RollAvg_TeamB</th>\n",
       "      <th>Average Combat Score_RollAvg_TeamB</th>\n",
       "      <th>Average Damage Per Round_RollAvg_TeamB</th>\n",
       "      <th>KDA_RollAvg_TeamB</th>\n",
       "      <th>Kill, Assist, Trade, Survive %_RollAvg_TeamB</th>\n",
       "      <th>Round Win %_RollAvg_TeamB</th>\n",
       "      <th>Attacker Win %_RollAvg_TeamB</th>\n",
       "      <th>Defender Win %_RollAvg_TeamB</th>\n",
       "      <th>Overtime Win %_RollAvg_TeamB</th>\n",
       "      <th>First Blood %_RollAvg_TeamB</th>\n",
       "      <th>Headshot %_RollAvg_TeamB</th>\n",
       "      <th>Clutches_RollAvg_TeamB</th>\n",
       "      <th>Econ_RollAvg_TeamB</th>\n",
       "      <th>Recent Win %_TeamB</th>\n",
       "      <th>Team A Tournament Win %</th>\n",
       "      <th>Team A Map Win %</th>\n",
       "      <th>Team A H2H Win %</th>\n",
       "      <th>Team B Tournament Win %</th>\n",
       "      <th>Team B Map Win %</th>\n",
       "      <th>Team B H2H Win %</th>\n",
       "      <th>Map_Abyss</th>\n",
       "      <th>Map_Ascent</th>\n",
       "      <th>Map_Bind</th>\n",
       "      <th>Map_Breeze</th>\n",
       "      <th>Map_Fracture</th>\n",
       "      <th>Map_Haven</th>\n",
       "      <th>Map_Icebox</th>\n",
       "      <th>Map_Lotus</th>\n",
       "      <th>Map_Pearl</th>\n",
       "      <th>Map_Split</th>\n",
       "      <th>Map_Sunset</th>\n",
       "      <th>Team A_Encoded</th>\n",
       "      <th>Team B_Encoded</th>\n",
       "      <th>Winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Champions Tour LATAM Stage 1: Challengers 1</td>\n",
       "      <td>Open Qualifier: LAS</td>\n",
       "      <td>Round of 16</td>\n",
       "      <td>Leviatán vs Furious Gaming</td>\n",
       "      <td>Ascent</td>\n",
       "      <td>Leviatán</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Furious Gaming</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.883333</td>\n",
       "      <td>0.990122</td>\n",
       "      <td>186.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>0.699855</td>\n",
       "      <td>119.6</td>\n",
       "      <td>0.250</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.990134</td>\n",
       "      <td>218.4</td>\n",
       "      <td>76.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.699858</td>\n",
       "      <td>132.8</td>\n",
       "      <td>0.190</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17455.584114</td>\n",
       "      <td>8510.17329</td>\n",
       "      <td>Full buy: 20k+</td>\n",
       "      <td>17455.711283</td>\n",
       "      <td>8510.381277</td>\n",
       "      <td>Full buy: 20k+</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.517956</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.51867</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.078947</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.683333</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.559545</td>\n",
       "      <td>0.534095</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Champions Tour LATAM Stage 1: Challengers 1</td>\n",
       "      <td>Open Qualifier: LAS</td>\n",
       "      <td>Round of 16</td>\n",
       "      <td>Leviatán vs Furious Gaming</td>\n",
       "      <td>Ascent</td>\n",
       "      <td>Furious Gaming</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Leviatán</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.883333</td>\n",
       "      <td>0.990122</td>\n",
       "      <td>218.4</td>\n",
       "      <td>76.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.699855</td>\n",
       "      <td>132.8</td>\n",
       "      <td>0.190</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.990134</td>\n",
       "      <td>186.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>0.699858</td>\n",
       "      <td>119.6</td>\n",
       "      <td>0.250</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17455.584114</td>\n",
       "      <td>8510.17329</td>\n",
       "      <td>Full buy: 20k+</td>\n",
       "      <td>17455.711283</td>\n",
       "      <td>8510.381277</td>\n",
       "      <td>Full buy: 20k+</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.517956</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.51867</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.683333</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.078947</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.465905</td>\n",
       "      <td>0.440455</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Champions Tour LATAM Stage 1: Challengers 1</td>\n",
       "      <td>Open Qualifier: LAS</td>\n",
       "      <td>Round of 16</td>\n",
       "      <td>Leviatán vs Furious Gaming</td>\n",
       "      <td>Bind</td>\n",
       "      <td>Leviatán</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Furious Gaming</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.933333</td>\n",
       "      <td>0.990122</td>\n",
       "      <td>175.8</td>\n",
       "      <td>56.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>0.699855</td>\n",
       "      <td>113.6</td>\n",
       "      <td>0.160</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.990134</td>\n",
       "      <td>228.8</td>\n",
       "      <td>81.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.699858</td>\n",
       "      <td>164.6</td>\n",
       "      <td>0.202</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17455.584114</td>\n",
       "      <td>8510.17329</td>\n",
       "      <td>Full buy: 20k+</td>\n",
       "      <td>17455.711283</td>\n",
       "      <td>8510.381277</td>\n",
       "      <td>Full buy: 20k+</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.517956</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.51867</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.024691</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.990122</td>\n",
       "      <td>186.0</td>\n",
       "      <td>119.6</td>\n",
       "      <td>1.078947</td>\n",
       "      <td>0.699855</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.517956</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.071429</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.990134</td>\n",
       "      <td>218.4</td>\n",
       "      <td>132.8</td>\n",
       "      <td>1.683333</td>\n",
       "      <td>0.699858</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.51867</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.559545</td>\n",
       "      <td>0.534095</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Champions Tour LATAM Stage 1: Challengers 1</td>\n",
       "      <td>Open Qualifier: LAS</td>\n",
       "      <td>Round of 16</td>\n",
       "      <td>Leviatán vs Furious Gaming</td>\n",
       "      <td>Bind</td>\n",
       "      <td>Furious Gaming</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Leviatán</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.933333</td>\n",
       "      <td>0.990122</td>\n",
       "      <td>228.8</td>\n",
       "      <td>81.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.699855</td>\n",
       "      <td>164.6</td>\n",
       "      <td>0.202</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.990134</td>\n",
       "      <td>175.8</td>\n",
       "      <td>56.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>0.699858</td>\n",
       "      <td>113.6</td>\n",
       "      <td>0.160</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17455.584114</td>\n",
       "      <td>8510.17329</td>\n",
       "      <td>Full buy: 20k+</td>\n",
       "      <td>17455.711283</td>\n",
       "      <td>8510.381277</td>\n",
       "      <td>Full buy: 20k+</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.517956</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.51867</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.071429</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.990122</td>\n",
       "      <td>218.4</td>\n",
       "      <td>132.8</td>\n",
       "      <td>1.683333</td>\n",
       "      <td>0.699855</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.517956</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.024691</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.990134</td>\n",
       "      <td>186.0</td>\n",
       "      <td>119.6</td>\n",
       "      <td>1.078947</td>\n",
       "      <td>0.699858</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.51867</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.465905</td>\n",
       "      <td>0.440455</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Champions Tour LATAM Stage 1: Challengers 1</td>\n",
       "      <td>Open Qualifier: LAS</td>\n",
       "      <td>Round of 16</td>\n",
       "      <td>Procyon Team vs KRÜ Esports</td>\n",
       "      <td>Bind</td>\n",
       "      <td>Procyon Team</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>KRÜ Esports</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.033333</td>\n",
       "      <td>0.990122</td>\n",
       "      <td>187.2</td>\n",
       "      <td>40.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>-27.0</td>\n",
       "      <td>0.699855</td>\n",
       "      <td>130.8</td>\n",
       "      <td>0.192</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.990134</td>\n",
       "      <td>253.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.699858</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.314</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17455.584114</td>\n",
       "      <td>8510.17329</td>\n",
       "      <td>Full buy: 20k+</td>\n",
       "      <td>17455.711283</td>\n",
       "      <td>8510.381277</td>\n",
       "      <td>Full buy: 20k+</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.517956</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.51867</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.910448</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.313396</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Tournament                Stage  \\\n",
       "0  Champions Tour LATAM Stage 1: Challengers 1  Open Qualifier: LAS   \n",
       "1  Champions Tour LATAM Stage 1: Challengers 1  Open Qualifier: LAS   \n",
       "2  Champions Tour LATAM Stage 1: Challengers 1  Open Qualifier: LAS   \n",
       "3  Champions Tour LATAM Stage 1: Challengers 1  Open Qualifier: LAS   \n",
       "4  Champions Tour LATAM Stage 1: Challengers 1  Open Qualifier: LAS   \n",
       "\n",
       "    Match Type                   Match Name     Map          Team A  \\\n",
       "0  Round of 16   Leviatán vs Furious Gaming  Ascent        Leviatán   \n",
       "1  Round of 16   Leviatán vs Furious Gaming  Ascent  Furious Gaming   \n",
       "2  Round of 16   Leviatán vs Furious Gaming    Bind        Leviatán   \n",
       "3  Round of 16   Leviatán vs Furious Gaming    Bind  Furious Gaming   \n",
       "4  Round of 16  Procyon Team vs KRÜ Esports    Bind    Procyon Team   \n",
       "\n",
       "   Team A Score  Team A Attacker Score  Team A Defender Score  \\\n",
       "0             7                      6                    1.0   \n",
       "1            13                      7                    6.0   \n",
       "2             7                      5                    2.0   \n",
       "3            13                      6                    7.0   \n",
       "4             1                      1                    0.0   \n",
       "\n",
       "   Team A Overtime Score          Team B  Team B Score  Team B Attacker Score  \\\n",
       "0                    0.0  Furious Gaming            13                      7   \n",
       "1                    0.0        Leviatán             7                      6   \n",
       "2                    0.0  Furious Gaming            13                      6   \n",
       "3                    0.0        Leviatán             7                      5   \n",
       "4                    0.0     KRÜ Esports            13                      2   \n",
       "\n",
       "   Team B Defender Score  Team B Overtime Score   Duration  Rating_TeamA  \\\n",
       "0                    6.0                    0.0  41.883333      0.990122   \n",
       "1                    1.0                    0.0  41.883333      0.990122   \n",
       "2                    7.0                    0.0  38.933333      0.990122   \n",
       "3                    2.0                    0.0  38.933333      0.990122   \n",
       "4                   11.0                    0.0  28.033333      0.990122   \n",
       "\n",
       "   Average Combat Score_TeamA  Kills_TeamA  Deaths_TeamA  Assists_TeamA  \\\n",
       "0                       186.0         60.0          76.0           22.0   \n",
       "1                       218.4         76.0          60.0           25.0   \n",
       "2                       175.8         56.0          81.0           27.0   \n",
       "3                       228.8         81.0          56.0           35.0   \n",
       "4                       187.2         40.0          67.0           21.0   \n",
       "\n",
       "   Kills - Deaths (KD)_TeamA  Kill, Assist, Trade, Survive %_TeamA  \\\n",
       "0                      -16.0                              0.699855   \n",
       "1                       16.0                              0.699855   \n",
       "2                      -25.0                              0.699855   \n",
       "3                       25.0                              0.699855   \n",
       "4                      -27.0                              0.699855   \n",
       "\n",
       "   Average Damage Per Round_TeamA  Headshot %_TeamA  First Kills_TeamA  \\\n",
       "0                           119.6             0.250               10.0   \n",
       "1                           132.8             0.190               10.0   \n",
       "2                           113.6             0.160               10.0   \n",
       "3                           164.6             0.202               10.0   \n",
       "4                           130.8             0.192                6.0   \n",
       "\n",
       "   First Deaths_TeamA  Kills - Deaths (FKD)_TeamA  Rating_TeamB  \\\n",
       "0                10.0                         0.0      0.990134   \n",
       "1                10.0                         0.0      0.990134   \n",
       "2                10.0                         0.0      0.990134   \n",
       "3                10.0                         0.0      0.990134   \n",
       "4                 8.0                        -2.0      0.990134   \n",
       "\n",
       "   Average Combat Score_TeamB  Kills_TeamB  Deaths_TeamB  Assists_TeamB  \\\n",
       "0                       218.4         76.0          60.0           25.0   \n",
       "1                       186.0         60.0          76.0           22.0   \n",
       "2                       228.8         81.0          56.0           35.0   \n",
       "3                       175.8         56.0          81.0           27.0   \n",
       "4                       253.0         67.0          40.0           23.0   \n",
       "\n",
       "   Kills - Deaths (KD)_TeamB  Kill, Assist, Trade, Survive %_TeamB  \\\n",
       "0                       16.0                              0.699858   \n",
       "1                      -16.0                              0.699858   \n",
       "2                       25.0                              0.699858   \n",
       "3                      -25.0                              0.699858   \n",
       "4                       27.0                              0.699858   \n",
       "\n",
       "   Average Damage Per Round_TeamB  Headshot %_TeamB  First Kills_TeamB  \\\n",
       "0                           132.8             0.190               10.0   \n",
       "1                           119.6             0.250               10.0   \n",
       "2                           164.6             0.202               10.0   \n",
       "3                           113.6             0.160               10.0   \n",
       "4                           150.0             0.314                8.0   \n",
       "\n",
       "   First Deaths_TeamB  Kills - Deaths (FKD)_TeamB  Loadout Value_TeamA  \\\n",
       "0                10.0                         0.0         17455.584114   \n",
       "1                10.0                         0.0         17455.584114   \n",
       "2                10.0                         0.0         17455.584114   \n",
       "3                10.0                         0.0         17455.584114   \n",
       "4                 6.0                         2.0         17455.584114   \n",
       "\n",
       "   Remaining Credits_TeamA      Type_TeamA  Loadout Value_TeamB  \\\n",
       "0               8510.17329  Full buy: 20k+         17455.711283   \n",
       "1               8510.17329  Full buy: 20k+         17455.711283   \n",
       "2               8510.17329  Full buy: 20k+         17455.711283   \n",
       "3               8510.17329  Full buy: 20k+         17455.711283   \n",
       "4               8510.17329  Full buy: 20k+         17455.711283   \n",
       "\n",
       "   Remaining Credits_TeamB      Type_TeamB  2k_TeamA  3k_TeamA  4k_TeamA  \\\n",
       "0              8510.381277  Full buy: 20k+       0.0       0.0       0.0   \n",
       "1              8510.381277  Full buy: 20k+       0.0       0.0       0.0   \n",
       "2              8510.381277  Full buy: 20k+       0.0       0.0       0.0   \n",
       "3              8510.381277  Full buy: 20k+       0.0       0.0       0.0   \n",
       "4              8510.381277  Full buy: 20k+       0.0       0.0       0.0   \n",
       "\n",
       "   5k_TeamA  1v1_TeamA  1v2_TeamA  1v3_TeamA  1v4_TeamA  1v5_TeamA  \\\n",
       "0       0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "1       0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "2       0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "3       0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "4       0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "\n",
       "   Econ_TeamA  Spike Plants_TeamA  Spike Defuses_TeamA  2k_TeamB  3k_TeamB  \\\n",
       "0   53.517956                 0.0                  0.0       0.0       0.0   \n",
       "1   53.517956                 0.0                  0.0       0.0       0.0   \n",
       "2   53.517956                 0.0                  0.0       0.0       0.0   \n",
       "3   53.517956                 0.0                  0.0       0.0       0.0   \n",
       "4   53.517956                 0.0                  0.0       0.0       0.0   \n",
       "\n",
       "   4k_TeamB  5k_TeamB  1v1_TeamB  1v2_TeamB  1v3_TeamB  1v4_TeamB  1v5_TeamB  \\\n",
       "0       0.0       0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "1       0.0       0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "2       0.0       0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "3       0.0       0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "4       0.0       0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "\n",
       "   Econ_TeamB  Spike Plants_TeamB  Spike Defuses_TeamB  Elimination_TeamA  \\\n",
       "0    53.51867                 0.0                  0.0                2.0   \n",
       "1    53.51867                 0.0                  0.0                9.0   \n",
       "2    53.51867                 0.0                  0.0                4.0   \n",
       "3    53.51867                 0.0                  0.0                8.0   \n",
       "4    53.51867                 0.0                  0.0                0.0   \n",
       "\n",
       "   Detonated_TeamA  Defused_TeamA  Time Expiry (No Plant)_TeamA  \\\n",
       "0              1.0            3.0                           1.0   \n",
       "1              0.0            3.0                           1.0   \n",
       "2              3.0            0.0                           0.0   \n",
       "3              0.0            5.0                           0.0   \n",
       "4              0.0            1.0                           0.0   \n",
       "\n",
       "   Eliminated_TeamA  Defused Failed_TeamA  Detonation Denied_TeamA  \\\n",
       "0               9.0                   0.0                      3.0   \n",
       "1               2.0                   1.0                      3.0   \n",
       "2               8.0                   0.0                      5.0   \n",
       "3               4.0                   3.0                      0.0   \n",
       "4               9.0                   3.0                      1.0   \n",
       "\n",
       "   Time Expiry (Failed to Plant)_TeamA  Elimination_TeamB  Detonated_TeamB  \\\n",
       "0                                  1.0                9.0              0.0   \n",
       "1                                  1.0                2.0              1.0   \n",
       "2                                  0.0                8.0              0.0   \n",
       "3                                  0.0                4.0              3.0   \n",
       "4                                  0.0                9.0              3.0   \n",
       "\n",
       "   Defused_TeamB  Time Expiry (No Plant)_TeamB  Eliminated_TeamB  \\\n",
       "0            3.0                           1.0               2.0   \n",
       "1            3.0                           1.0               9.0   \n",
       "2            5.0                           0.0               4.0   \n",
       "3            0.0                           0.0               8.0   \n",
       "4            1.0                           0.0               0.0   \n",
       "\n",
       "   Defused Failed_TeamB  Detonation Denied_TeamB  \\\n",
       "0                   1.0                      3.0   \n",
       "1                   0.0                      3.0   \n",
       "2                   3.0                      0.0   \n",
       "3                   0.0                      5.0   \n",
       "4                   0.0                      1.0   \n",
       "\n",
       "   Time Expiry (Failed to Plant)_TeamB  KDA_TeamA  Round Win %_TeamA  \\\n",
       "0                                  1.0   1.078947           0.350000   \n",
       "1                                  1.0   1.683333           0.650000   \n",
       "2                                  0.0   1.024691           0.350000   \n",
       "3                                  0.0   2.071429           0.650000   \n",
       "4                                  0.0   0.910448           0.071429   \n",
       "\n",
       "   First Blood %_TeamA  Clutches_TeamA  Attacker Win %_TeamA  \\\n",
       "0             0.500000             0.0              0.500000   \n",
       "1             0.500000             0.0              0.875000   \n",
       "2             0.500000             0.0              0.416667   \n",
       "3             0.500000             0.0              0.750000   \n",
       "4             0.428571             0.0              0.083333   \n",
       "\n",
       "   Defender Win %_TeamA  Overtime Win %_TeamA  Rating_RollAvg_TeamA  \\\n",
       "0              0.125000                   0.0              0.000000   \n",
       "1              0.500000                   0.0              0.000000   \n",
       "2              0.250000                   0.0              0.990122   \n",
       "3              0.583333                   0.0              0.990122   \n",
       "4              0.000000                   0.0              0.000000   \n",
       "\n",
       "   Average Combat Score_RollAvg_TeamA  Average Damage Per Round_RollAvg_TeamA  \\\n",
       "0                                 0.0                                     0.0   \n",
       "1                                 0.0                                     0.0   \n",
       "2                               186.0                                   119.6   \n",
       "3                               218.4                                   132.8   \n",
       "4                                 0.0                                     0.0   \n",
       "\n",
       "   KDA_RollAvg_TeamA  Kill, Assist, Trade, Survive %_RollAvg_TeamA  \\\n",
       "0           0.000000                                      0.000000   \n",
       "1           0.000000                                      0.000000   \n",
       "2           1.078947                                      0.699855   \n",
       "3           1.683333                                      0.699855   \n",
       "4           0.000000                                      0.000000   \n",
       "\n",
       "   Round Win %_RollAvg_TeamA  Attacker Win %_RollAvg_TeamA  \\\n",
       "0                       0.00                         0.000   \n",
       "1                       0.00                         0.000   \n",
       "2                       0.35                         0.500   \n",
       "3                       0.65                         0.875   \n",
       "4                       0.00                         0.000   \n",
       "\n",
       "   Defender Win %_RollAvg_TeamA  Overtime Win %_RollAvg_TeamA  \\\n",
       "0                         0.000                           0.0   \n",
       "1                         0.000                           0.0   \n",
       "2                         0.125                           0.0   \n",
       "3                         0.500                           0.0   \n",
       "4                         0.000                           0.0   \n",
       "\n",
       "   First Blood %_RollAvg_TeamA  Headshot %_RollAvg_TeamA  \\\n",
       "0                          0.0                      0.00   \n",
       "1                          0.0                      0.00   \n",
       "2                          0.5                      0.25   \n",
       "3                          0.5                      0.19   \n",
       "4                          0.0                      0.00   \n",
       "\n",
       "   Clutches_RollAvg_TeamA  Econ_RollAvg_TeamA  Recent Win %_TeamA  KDA_TeamB  \\\n",
       "0                     0.0            0.000000                 0.0   1.683333   \n",
       "1                     0.0            0.000000                 0.0   1.078947   \n",
       "2                     0.0           53.517956                 0.0   2.071429   \n",
       "3                     0.0           53.517956                 1.0   1.024691   \n",
       "4                     0.0            0.000000                 0.0   2.250000   \n",
       "\n",
       "   Round Win %_TeamB  First Blood %_TeamB  Clutches_TeamB  \\\n",
       "0           0.650000             0.500000             0.0   \n",
       "1           0.350000             0.500000             0.0   \n",
       "2           0.650000             0.500000             0.0   \n",
       "3           0.350000             0.500000             0.0   \n",
       "4           0.928571             0.571429             0.0   \n",
       "\n",
       "   Attacker Win %_TeamB  Defender Win %_TeamB  Overtime Win %_TeamB  \\\n",
       "0              0.875000              0.500000                   0.0   \n",
       "1              0.500000              0.125000                   0.0   \n",
       "2              0.750000              0.583333                   0.0   \n",
       "3              0.416667              0.250000                   0.0   \n",
       "4              1.000000              0.916667                   0.0   \n",
       "\n",
       "   Rating_RollAvg_TeamB  Average Combat Score_RollAvg_TeamB  \\\n",
       "0              0.000000                                 0.0   \n",
       "1              0.000000                                 0.0   \n",
       "2              0.990134                               218.4   \n",
       "3              0.990134                               186.0   \n",
       "4              0.000000                                 0.0   \n",
       "\n",
       "   Average Damage Per Round_RollAvg_TeamB  KDA_RollAvg_TeamB  \\\n",
       "0                                     0.0           0.000000   \n",
       "1                                     0.0           0.000000   \n",
       "2                                   132.8           1.683333   \n",
       "3                                   119.6           1.078947   \n",
       "4                                     0.0           0.000000   \n",
       "\n",
       "   Kill, Assist, Trade, Survive %_RollAvg_TeamB  Round Win %_RollAvg_TeamB  \\\n",
       "0                                      0.000000                       0.00   \n",
       "1                                      0.000000                       0.00   \n",
       "2                                      0.699858                       0.65   \n",
       "3                                      0.699858                       0.35   \n",
       "4                                      0.000000                       0.00   \n",
       "\n",
       "   Attacker Win %_RollAvg_TeamB  Defender Win %_RollAvg_TeamB  \\\n",
       "0                         0.000                         0.000   \n",
       "1                         0.000                         0.000   \n",
       "2                         0.875                         0.500   \n",
       "3                         0.500                         0.125   \n",
       "4                         0.000                         0.000   \n",
       "\n",
       "   Overtime Win %_RollAvg_TeamB  First Blood %_RollAvg_TeamB  \\\n",
       "0                           0.0                          0.0   \n",
       "1                           0.0                          0.0   \n",
       "2                           0.0                          0.5   \n",
       "3                           0.0                          0.5   \n",
       "4                           0.0                          0.0   \n",
       "\n",
       "   Headshot %_RollAvg_TeamB  Clutches_RollAvg_TeamB  Econ_RollAvg_TeamB  \\\n",
       "0                      0.00                     0.0             0.00000   \n",
       "1                      0.00                     0.0             0.00000   \n",
       "2                      0.19                     0.0            53.51867   \n",
       "3                      0.25                     0.0            53.51867   \n",
       "4                      0.00                     0.0             0.00000   \n",
       "\n",
       "   Recent Win %_TeamB  Team A Tournament Win %  Team A Map Win %  \\\n",
       "0                 0.0                      0.0               0.0   \n",
       "1                 0.0                      0.0               0.0   \n",
       "2                 0.0                      0.0               0.0   \n",
       "3                 1.0                      1.0               0.0   \n",
       "4                 0.0                      0.0               0.0   \n",
       "\n",
       "   Team A H2H Win %  Team B Tournament Win %  Team B Map Win %  \\\n",
       "0               0.0                      0.0               0.0   \n",
       "1               0.0                      0.0               0.0   \n",
       "2               0.0                      1.0               0.0   \n",
       "3               1.0                      0.0               0.0   \n",
       "4               0.0                      0.0               0.0   \n",
       "\n",
       "   Team B H2H Win %  Map_Abyss  Map_Ascent  Map_Bind  Map_Breeze  \\\n",
       "0               0.0        0.0         1.0       0.0         0.0   \n",
       "1               0.0        0.0         1.0       0.0         0.0   \n",
       "2               1.0        0.0         0.0       1.0         0.0   \n",
       "3               0.0        0.0         0.0       1.0         0.0   \n",
       "4               0.0        0.0         0.0       1.0         0.0   \n",
       "\n",
       "   Map_Fracture  Map_Haven  Map_Icebox  Map_Lotus  Map_Pearl  Map_Split  \\\n",
       "0           0.0        0.0         0.0        0.0        0.0        0.0   \n",
       "1           0.0        0.0         0.0        0.0        0.0        0.0   \n",
       "2           0.0        0.0         0.0        0.0        0.0        0.0   \n",
       "3           0.0        0.0         0.0        0.0        0.0        0.0   \n",
       "4           0.0        0.0         0.0        0.0        0.0        0.0   \n",
       "\n",
       "   Map_Sunset  Team A_Encoded  Team B_Encoded  Winner  \n",
       "0         0.0        0.559545        0.534095       0  \n",
       "1         0.0        0.465905        0.440455       1  \n",
       "2         0.0        0.559545        0.534095       0  \n",
       "3         0.0        0.465905        0.440455       1  \n",
       "4         0.0        0.000000        0.313396       0  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"vct_data/train_preprocessed.csv\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tournament</th>\n",
       "      <th>Stage</th>\n",
       "      <th>Match Type</th>\n",
       "      <th>Match Name</th>\n",
       "      <th>Map</th>\n",
       "      <th>Team A</th>\n",
       "      <th>Team A Score</th>\n",
       "      <th>Team A Attacker Score</th>\n",
       "      <th>Team A Defender Score</th>\n",
       "      <th>Team A Overtime Score</th>\n",
       "      <th>Team B</th>\n",
       "      <th>Team B Score</th>\n",
       "      <th>Team B Attacker Score</th>\n",
       "      <th>Team B Defender Score</th>\n",
       "      <th>Team B Overtime Score</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Rating_TeamA</th>\n",
       "      <th>Average Combat Score_TeamA</th>\n",
       "      <th>Kills_TeamA</th>\n",
       "      <th>Deaths_TeamA</th>\n",
       "      <th>Assists_TeamA</th>\n",
       "      <th>Kills - Deaths (KD)_TeamA</th>\n",
       "      <th>Kill, Assist, Trade, Survive %_TeamA</th>\n",
       "      <th>Average Damage Per Round_TeamA</th>\n",
       "      <th>Headshot %_TeamA</th>\n",
       "      <th>First Kills_TeamA</th>\n",
       "      <th>First Deaths_TeamA</th>\n",
       "      <th>Kills - Deaths (FKD)_TeamA</th>\n",
       "      <th>Rating_TeamB</th>\n",
       "      <th>Average Combat Score_TeamB</th>\n",
       "      <th>Kills_TeamB</th>\n",
       "      <th>Deaths_TeamB</th>\n",
       "      <th>Assists_TeamB</th>\n",
       "      <th>Kills - Deaths (KD)_TeamB</th>\n",
       "      <th>Kill, Assist, Trade, Survive %_TeamB</th>\n",
       "      <th>Average Damage Per Round_TeamB</th>\n",
       "      <th>Headshot %_TeamB</th>\n",
       "      <th>First Kills_TeamB</th>\n",
       "      <th>First Deaths_TeamB</th>\n",
       "      <th>Kills - Deaths (FKD)_TeamB</th>\n",
       "      <th>Loadout Value_TeamA</th>\n",
       "      <th>Remaining Credits_TeamA</th>\n",
       "      <th>Type_TeamA</th>\n",
       "      <th>Loadout Value_TeamB</th>\n",
       "      <th>Remaining Credits_TeamB</th>\n",
       "      <th>Type_TeamB</th>\n",
       "      <th>2k_TeamA</th>\n",
       "      <th>3k_TeamA</th>\n",
       "      <th>4k_TeamA</th>\n",
       "      <th>5k_TeamA</th>\n",
       "      <th>1v1_TeamA</th>\n",
       "      <th>1v2_TeamA</th>\n",
       "      <th>1v3_TeamA</th>\n",
       "      <th>1v4_TeamA</th>\n",
       "      <th>1v5_TeamA</th>\n",
       "      <th>Econ_TeamA</th>\n",
       "      <th>Spike Plants_TeamA</th>\n",
       "      <th>Spike Defuses_TeamA</th>\n",
       "      <th>2k_TeamB</th>\n",
       "      <th>3k_TeamB</th>\n",
       "      <th>4k_TeamB</th>\n",
       "      <th>5k_TeamB</th>\n",
       "      <th>1v1_TeamB</th>\n",
       "      <th>1v2_TeamB</th>\n",
       "      <th>1v3_TeamB</th>\n",
       "      <th>1v4_TeamB</th>\n",
       "      <th>1v5_TeamB</th>\n",
       "      <th>Econ_TeamB</th>\n",
       "      <th>Spike Plants_TeamB</th>\n",
       "      <th>Spike Defuses_TeamB</th>\n",
       "      <th>Elimination_TeamA</th>\n",
       "      <th>Detonated_TeamA</th>\n",
       "      <th>Defused_TeamA</th>\n",
       "      <th>Time Expiry (No Plant)_TeamA</th>\n",
       "      <th>Eliminated_TeamA</th>\n",
       "      <th>Defused Failed_TeamA</th>\n",
       "      <th>Detonation Denied_TeamA</th>\n",
       "      <th>Time Expiry (Failed to Plant)_TeamA</th>\n",
       "      <th>Elimination_TeamB</th>\n",
       "      <th>Detonated_TeamB</th>\n",
       "      <th>Defused_TeamB</th>\n",
       "      <th>Time Expiry (No Plant)_TeamB</th>\n",
       "      <th>Eliminated_TeamB</th>\n",
       "      <th>Defused Failed_TeamB</th>\n",
       "      <th>Detonation Denied_TeamB</th>\n",
       "      <th>Time Expiry (Failed to Plant)_TeamB</th>\n",
       "      <th>KDA_TeamA</th>\n",
       "      <th>Round Win %_TeamA</th>\n",
       "      <th>First Blood %_TeamA</th>\n",
       "      <th>Clutches_TeamA</th>\n",
       "      <th>Attacker Win %_TeamA</th>\n",
       "      <th>Defender Win %_TeamA</th>\n",
       "      <th>Overtime Win %_TeamA</th>\n",
       "      <th>Rating_RollAvg_TeamA</th>\n",
       "      <th>Average Combat Score_RollAvg_TeamA</th>\n",
       "      <th>Average Damage Per Round_RollAvg_TeamA</th>\n",
       "      <th>KDA_RollAvg_TeamA</th>\n",
       "      <th>Kill, Assist, Trade, Survive %_RollAvg_TeamA</th>\n",
       "      <th>Round Win %_RollAvg_TeamA</th>\n",
       "      <th>Attacker Win %_RollAvg_TeamA</th>\n",
       "      <th>Defender Win %_RollAvg_TeamA</th>\n",
       "      <th>Overtime Win %_RollAvg_TeamA</th>\n",
       "      <th>First Blood %_RollAvg_TeamA</th>\n",
       "      <th>Headshot %_RollAvg_TeamA</th>\n",
       "      <th>Clutches_RollAvg_TeamA</th>\n",
       "      <th>Econ_RollAvg_TeamA</th>\n",
       "      <th>Recent Win %_TeamA</th>\n",
       "      <th>KDA_TeamB</th>\n",
       "      <th>Round Win %_TeamB</th>\n",
       "      <th>First Blood %_TeamB</th>\n",
       "      <th>Clutches_TeamB</th>\n",
       "      <th>Attacker Win %_TeamB</th>\n",
       "      <th>Defender Win %_TeamB</th>\n",
       "      <th>Overtime Win %_TeamB</th>\n",
       "      <th>Rating_RollAvg_TeamB</th>\n",
       "      <th>Average Combat Score_RollAvg_TeamB</th>\n",
       "      <th>Average Damage Per Round_RollAvg_TeamB</th>\n",
       "      <th>KDA_RollAvg_TeamB</th>\n",
       "      <th>Kill, Assist, Trade, Survive %_RollAvg_TeamB</th>\n",
       "      <th>Round Win %_RollAvg_TeamB</th>\n",
       "      <th>Attacker Win %_RollAvg_TeamB</th>\n",
       "      <th>Defender Win %_RollAvg_TeamB</th>\n",
       "      <th>Overtime Win %_RollAvg_TeamB</th>\n",
       "      <th>First Blood %_RollAvg_TeamB</th>\n",
       "      <th>Headshot %_RollAvg_TeamB</th>\n",
       "      <th>Clutches_RollAvg_TeamB</th>\n",
       "      <th>Econ_RollAvg_TeamB</th>\n",
       "      <th>Recent Win %_TeamB</th>\n",
       "      <th>Team A Tournament Win %</th>\n",
       "      <th>Team A Map Win %</th>\n",
       "      <th>Team A H2H Win %</th>\n",
       "      <th>Team B Tournament Win %</th>\n",
       "      <th>Team B Map Win %</th>\n",
       "      <th>Team B H2H Win %</th>\n",
       "      <th>Map_Abyss</th>\n",
       "      <th>Map_Ascent</th>\n",
       "      <th>Map_Bind</th>\n",
       "      <th>Map_Breeze</th>\n",
       "      <th>Map_Fracture</th>\n",
       "      <th>Map_Haven</th>\n",
       "      <th>Map_Icebox</th>\n",
       "      <th>Map_Lotus</th>\n",
       "      <th>Map_Pearl</th>\n",
       "      <th>Map_Split</th>\n",
       "      <th>Map_Sunset</th>\n",
       "      <th>Team A_Encoded</th>\n",
       "      <th>Team B_Encoded</th>\n",
       "      <th>Winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Champions Tour Malaysia &amp; Singapore Stage 2: C...</td>\n",
       "      <td>Group Stage</td>\n",
       "      <td>Day 7</td>\n",
       "      <td>BLEED vs Galaxy Esports</td>\n",
       "      <td>Icebox</td>\n",
       "      <td>Galaxy Esports</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BLEED</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.333333</td>\n",
       "      <td>1.164</td>\n",
       "      <td>222.2</td>\n",
       "      <td>82.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.730</td>\n",
       "      <td>145.6</td>\n",
       "      <td>0.226</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.806</td>\n",
       "      <td>179.2</td>\n",
       "      <td>60.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>0.630</td>\n",
       "      <td>119.2</td>\n",
       "      <td>0.240</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>19605.000000</td>\n",
       "      <td>10715.000000</td>\n",
       "      <td>Full buy: 20k+</td>\n",
       "      <td>15860.000000</td>\n",
       "      <td>4590.000000</td>\n",
       "      <td>Semi-buy: 10-20k</td>\n",
       "      <td>14.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9240</td>\n",
       "      <td>194.40</td>\n",
       "      <td>125.38</td>\n",
       "      <td>1.301095</td>\n",
       "      <td>0.7012</td>\n",
       "      <td>0.440863</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.463308</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.513037</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>1.6</td>\n",
       "      <td>50.04</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.024390</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9710</td>\n",
       "      <td>197.86</td>\n",
       "      <td>129.62</td>\n",
       "      <td>1.379461</td>\n",
       "      <td>0.7036</td>\n",
       "      <td>0.489425</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.436111</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.475159</td>\n",
       "      <td>0.2452</td>\n",
       "      <td>1.8</td>\n",
       "      <td>52.34</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.447334</td>\n",
       "      <td>0.414839</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Champions Tour Malaysia &amp; Singapore Stage 2: C...</td>\n",
       "      <td>Group Stage</td>\n",
       "      <td>Day 8</td>\n",
       "      <td>BLEED vs KPMOONIIBLM9</td>\n",
       "      <td>Ascent</td>\n",
       "      <td>BLEED</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>KPMOONIIBLM9</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.366667</td>\n",
       "      <td>0.920</td>\n",
       "      <td>196.2</td>\n",
       "      <td>80.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>0.684</td>\n",
       "      <td>131.0</td>\n",
       "      <td>0.230</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>1.128</td>\n",
       "      <td>205.8</td>\n",
       "      <td>86.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.726</td>\n",
       "      <td>143.2</td>\n",
       "      <td>0.290</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>17050.000000</td>\n",
       "      <td>8370.833333</td>\n",
       "      <td>Full buy: 20k+</td>\n",
       "      <td>18195.833333</td>\n",
       "      <td>11104.166667</td>\n",
       "      <td>Full buy: 20k+</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.337209</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9364</td>\n",
       "      <td>194.06</td>\n",
       "      <td>127.78</td>\n",
       "      <td>1.312059</td>\n",
       "      <td>0.6876</td>\n",
       "      <td>0.459425</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.436111</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.460159</td>\n",
       "      <td>0.2482</td>\n",
       "      <td>1.8</td>\n",
       "      <td>51.30</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.592593</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0512</td>\n",
       "      <td>211.96</td>\n",
       "      <td>136.70</td>\n",
       "      <td>1.607471</td>\n",
       "      <td>0.7350</td>\n",
       "      <td>0.524396</td>\n",
       "      <td>0.545014</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.550017</td>\n",
       "      <td>0.2510</td>\n",
       "      <td>1.4</td>\n",
       "      <td>57.50</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.572950</td>\n",
       "      <td>0.371567</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Champions Tour Malaysia &amp; Singapore Stage 2: C...</td>\n",
       "      <td>Group Stage</td>\n",
       "      <td>Day 8</td>\n",
       "      <td>BLEED vs KPMOONIIBLM9</td>\n",
       "      <td>Ascent</td>\n",
       "      <td>KPMOONIIBLM9</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BLEED</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.366667</td>\n",
       "      <td>1.128</td>\n",
       "      <td>205.8</td>\n",
       "      <td>86.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.726</td>\n",
       "      <td>143.2</td>\n",
       "      <td>0.290</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.920</td>\n",
       "      <td>196.2</td>\n",
       "      <td>80.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>0.684</td>\n",
       "      <td>131.0</td>\n",
       "      <td>0.230</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>18195.833333</td>\n",
       "      <td>11104.166667</td>\n",
       "      <td>Full buy: 20k+</td>\n",
       "      <td>17050.000000</td>\n",
       "      <td>8370.833333</td>\n",
       "      <td>Full buy: 20k+</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.592593</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0512</td>\n",
       "      <td>211.96</td>\n",
       "      <td>136.70</td>\n",
       "      <td>1.607471</td>\n",
       "      <td>0.7350</td>\n",
       "      <td>0.524396</td>\n",
       "      <td>0.545014</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.550017</td>\n",
       "      <td>0.2510</td>\n",
       "      <td>1.4</td>\n",
       "      <td>57.50</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.337209</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9364</td>\n",
       "      <td>194.06</td>\n",
       "      <td>127.78</td>\n",
       "      <td>1.312059</td>\n",
       "      <td>0.6876</td>\n",
       "      <td>0.459425</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.436111</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.460159</td>\n",
       "      <td>0.2482</td>\n",
       "      <td>1.8</td>\n",
       "      <td>51.30</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.628433</td>\n",
       "      <td>0.414839</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Champions Tour Malaysia &amp; Singapore Stage 2: C...</td>\n",
       "      <td>Group Stage</td>\n",
       "      <td>Day 8</td>\n",
       "      <td>BLEED vs KPMOONIIBLM9</td>\n",
       "      <td>Icebox</td>\n",
       "      <td>BLEED</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>KPMOONIIBLM9</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.700000</td>\n",
       "      <td>0.898</td>\n",
       "      <td>199.4</td>\n",
       "      <td>79.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>0.680</td>\n",
       "      <td>131.4</td>\n",
       "      <td>0.244</td>\n",
       "      <td>16.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.054</td>\n",
       "      <td>208.4</td>\n",
       "      <td>86.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.672</td>\n",
       "      <td>134.6</td>\n",
       "      <td>0.246</td>\n",
       "      <td>7.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>17465.217391</td>\n",
       "      <td>5791.304348</td>\n",
       "      <td>Full buy: 20k+</td>\n",
       "      <td>17930.434783</td>\n",
       "      <td>9091.304348</td>\n",
       "      <td>Full buy: 20k+</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.4</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.8</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.232558</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9648</td>\n",
       "      <td>198.04</td>\n",
       "      <td>130.76</td>\n",
       "      <td>1.367839</td>\n",
       "      <td>0.6984</td>\n",
       "      <td>0.486508</td>\n",
       "      <td>0.491667</td>\n",
       "      <td>0.477778</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.472659</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>1.9</td>\n",
       "      <td>52.70</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.443038</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0178</td>\n",
       "      <td>207.98</td>\n",
       "      <td>134.68</td>\n",
       "      <td>1.434472</td>\n",
       "      <td>0.7212</td>\n",
       "      <td>0.497312</td>\n",
       "      <td>0.520014</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.531267</td>\n",
       "      <td>0.2582</td>\n",
       "      <td>1.4</td>\n",
       "      <td>54.70</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.572950</td>\n",
       "      <td>0.371567</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Champions Tour Malaysia &amp; Singapore Stage 2: C...</td>\n",
       "      <td>Group Stage</td>\n",
       "      <td>Day 8</td>\n",
       "      <td>BLEED vs KPMOONIIBLM9</td>\n",
       "      <td>Icebox</td>\n",
       "      <td>KPMOONIIBLM9</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BLEED</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.700000</td>\n",
       "      <td>1.054</td>\n",
       "      <td>208.4</td>\n",
       "      <td>86.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.672</td>\n",
       "      <td>134.6</td>\n",
       "      <td>0.246</td>\n",
       "      <td>7.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>0.898</td>\n",
       "      <td>199.4</td>\n",
       "      <td>79.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>0.680</td>\n",
       "      <td>131.4</td>\n",
       "      <td>0.244</td>\n",
       "      <td>16.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17930.434783</td>\n",
       "      <td>9091.304348</td>\n",
       "      <td>Full buy: 20k+</td>\n",
       "      <td>17465.217391</td>\n",
       "      <td>5791.304348</td>\n",
       "      <td>Full buy: 20k+</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.8</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.4</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.443038</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0178</td>\n",
       "      <td>207.98</td>\n",
       "      <td>134.68</td>\n",
       "      <td>1.434472</td>\n",
       "      <td>0.7212</td>\n",
       "      <td>0.497312</td>\n",
       "      <td>0.520014</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.531267</td>\n",
       "      <td>0.2582</td>\n",
       "      <td>1.4</td>\n",
       "      <td>54.70</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.232558</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9648</td>\n",
       "      <td>198.04</td>\n",
       "      <td>130.76</td>\n",
       "      <td>1.367839</td>\n",
       "      <td>0.6984</td>\n",
       "      <td>0.486508</td>\n",
       "      <td>0.491667</td>\n",
       "      <td>0.477778</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.472659</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>1.9</td>\n",
       "      <td>52.70</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.628433</td>\n",
       "      <td>0.414839</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Tournament        Stage Match Type  \\\n",
       "0  Champions Tour Malaysia & Singapore Stage 2: C...  Group Stage      Day 7   \n",
       "1  Champions Tour Malaysia & Singapore Stage 2: C...  Group Stage      Day 8   \n",
       "2  Champions Tour Malaysia & Singapore Stage 2: C...  Group Stage      Day 8   \n",
       "3  Champions Tour Malaysia & Singapore Stage 2: C...  Group Stage      Day 8   \n",
       "4  Champions Tour Malaysia & Singapore Stage 2: C...  Group Stage      Day 8   \n",
       "\n",
       "                Match Name     Map          Team A  Team A Score  \\\n",
       "0  BLEED vs Galaxy Esports  Icebox  Galaxy Esports            13   \n",
       "1    BLEED vs KPMOONIIBLM9  Ascent           BLEED            11   \n",
       "2    BLEED vs KPMOONIIBLM9  Ascent    KPMOONIIBLM9            13   \n",
       "3    BLEED vs KPMOONIIBLM9  Icebox           BLEED            10   \n",
       "4    BLEED vs KPMOONIIBLM9  Icebox    KPMOONIIBLM9            13   \n",
       "\n",
       "   Team A Attacker Score  Team A Defender Score  Team A Overtime Score  \\\n",
       "0                      4                    9.0                    0.0   \n",
       "1                      5                    6.0                    0.0   \n",
       "2                      6                    7.0                    0.0   \n",
       "3                      5                    5.0                    0.0   \n",
       "4                      6                    7.0                    0.0   \n",
       "\n",
       "         Team B  Team B Score  Team B Attacker Score  Team B Defender Score  \\\n",
       "0         BLEED             7                      3                    4.0   \n",
       "1  KPMOONIIBLM9            13                      6                    7.0   \n",
       "2         BLEED            11                      5                    6.0   \n",
       "3  KPMOONIIBLM9            13                      6                    7.0   \n",
       "4         BLEED            10                      5                    5.0   \n",
       "\n",
       "   Team B Overtime Score   Duration  Rating_TeamA  Average Combat Score_TeamA  \\\n",
       "0                    0.0  43.333333         1.164                       222.2   \n",
       "1                    0.0  46.366667         0.920                       196.2   \n",
       "2                    0.0  46.366667         1.128                       205.8   \n",
       "3                    0.0  47.700000         0.898                       199.4   \n",
       "4                    0.0  47.700000         1.054                       208.4   \n",
       "\n",
       "   Kills_TeamA  Deaths_TeamA  Assists_TeamA  Kills - Deaths (KD)_TeamA  \\\n",
       "0         82.0          60.0           18.0                       22.0   \n",
       "1         80.0          86.0           35.0                       -6.0   \n",
       "2         86.0          81.0           43.0                        5.0   \n",
       "3         79.0          86.0           27.0                       -7.0   \n",
       "4         86.0          79.0           28.0                        7.0   \n",
       "\n",
       "   Kill, Assist, Trade, Survive %_TeamA  Average Damage Per Round_TeamA  \\\n",
       "0                                 0.730                           145.6   \n",
       "1                                 0.684                           131.0   \n",
       "2                                 0.726                           143.2   \n",
       "3                                 0.680                           131.4   \n",
       "4                                 0.672                           134.6   \n",
       "\n",
       "   Headshot %_TeamA  First Kills_TeamA  First Deaths_TeamA  \\\n",
       "0             0.226               11.0                 9.0   \n",
       "1             0.230                9.0                15.0   \n",
       "2             0.290               15.0                 9.0   \n",
       "3             0.244               16.0                 7.0   \n",
       "4             0.246                7.0                16.0   \n",
       "\n",
       "   Kills - Deaths (FKD)_TeamA  Rating_TeamB  Average Combat Score_TeamB  \\\n",
       "0                         2.0         0.806                       179.2   \n",
       "1                        -6.0         1.128                       205.8   \n",
       "2                         6.0         0.920                       196.2   \n",
       "3                         9.0         1.054                       208.4   \n",
       "4                        -9.0         0.898                       199.4   \n",
       "\n",
       "   Kills_TeamB  Deaths_TeamB  Assists_TeamB  Kills - Deaths (KD)_TeamB  \\\n",
       "0         60.0          82.0           24.0                      -22.0   \n",
       "1         86.0          81.0           43.0                        5.0   \n",
       "2         80.0          86.0           35.0                       -6.0   \n",
       "3         86.0          79.0           28.0                        7.0   \n",
       "4         79.0          86.0           27.0                       -7.0   \n",
       "\n",
       "   Kill, Assist, Trade, Survive %_TeamB  Average Damage Per Round_TeamB  \\\n",
       "0                                 0.630                           119.2   \n",
       "1                                 0.726                           143.2   \n",
       "2                                 0.684                           131.0   \n",
       "3                                 0.672                           134.6   \n",
       "4                                 0.680                           131.4   \n",
       "\n",
       "   Headshot %_TeamB  First Kills_TeamB  First Deaths_TeamB  \\\n",
       "0             0.240                9.0                11.0   \n",
       "1             0.290               15.0                 9.0   \n",
       "2             0.230                9.0                15.0   \n",
       "3             0.246                7.0                16.0   \n",
       "4             0.244               16.0                 7.0   \n",
       "\n",
       "   Kills - Deaths (FKD)_TeamB  Loadout Value_TeamA  Remaining Credits_TeamA  \\\n",
       "0                        -2.0         19605.000000             10715.000000   \n",
       "1                         6.0         17050.000000              8370.833333   \n",
       "2                        -6.0         18195.833333             11104.166667   \n",
       "3                        -9.0         17465.217391              5791.304348   \n",
       "4                         9.0         17930.434783              9091.304348   \n",
       "\n",
       "       Type_TeamA  Loadout Value_TeamB  Remaining Credits_TeamB  \\\n",
       "0  Full buy: 20k+         15860.000000              4590.000000   \n",
       "1  Full buy: 20k+         18195.833333             11104.166667   \n",
       "2  Full buy: 20k+         17050.000000              8370.833333   \n",
       "3  Full buy: 20k+         17930.434783              9091.304348   \n",
       "4  Full buy: 20k+         17465.217391              5791.304348   \n",
       "\n",
       "         Type_TeamB  2k_TeamA  3k_TeamA  4k_TeamA  5k_TeamA  1v1_TeamA  \\\n",
       "0  Semi-buy: 10-20k      14.0       7.0       0.0       1.0        0.0   \n",
       "1    Full buy: 20k+      12.0       5.0       1.0       0.0        0.0   \n",
       "2    Full buy: 20k+      17.0       4.0       3.0       0.0        1.0   \n",
       "3    Full buy: 20k+      12.0       3.0       2.0       1.0        2.0   \n",
       "4    Full buy: 20k+      10.0      10.0       1.0       0.0        1.0   \n",
       "\n",
       "   1v2_TeamA  1v3_TeamA  1v4_TeamA  1v5_TeamA  Econ_TeamA  Spike Plants_TeamA  \\\n",
       "0        1.0        0.0        0.0        0.0        67.2                 5.0   \n",
       "1        1.0        0.0        0.0        0.0        54.2                 6.0   \n",
       "2        0.0        0.0        0.0        0.0        59.2                 7.0   \n",
       "3        2.0        0.0        0.0        0.0        52.4                 9.0   \n",
       "4        1.0        0.0        0.0        0.0        52.8                 7.0   \n",
       "\n",
       "   Spike Defuses_TeamA  2k_TeamB  3k_TeamB  4k_TeamB  5k_TeamB  1v1_TeamB  \\\n",
       "0                  2.0      10.0       2.0       0.0       0.0        2.0   \n",
       "1                  2.0      17.0       4.0       3.0       0.0        1.0   \n",
       "2                  3.0      12.0       5.0       1.0       0.0        0.0   \n",
       "3                  0.0      10.0      10.0       1.0       0.0        1.0   \n",
       "4                  4.0      12.0       3.0       2.0       1.0        2.0   \n",
       "\n",
       "   1v2_TeamB  1v3_TeamB  1v4_TeamB  1v5_TeamB  Econ_TeamB  Spike Plants_TeamB  \\\n",
       "0        1.0        0.0        0.0        0.0        46.2                 5.0   \n",
       "1        0.0        0.0        0.0        0.0        59.2                 7.0   \n",
       "2        1.0        0.0        0.0        0.0        54.2                 6.0   \n",
       "3        1.0        0.0        0.0        0.0        52.8                 7.0   \n",
       "4        2.0        0.0        0.0        0.0        52.4                 9.0   \n",
       "\n",
       "   Spike Defuses_TeamB  Elimination_TeamA  Detonated_TeamA  Defused_TeamA  \\\n",
       "0                  0.0               10.0              1.0            2.0   \n",
       "1                  3.0                8.0              1.0            2.0   \n",
       "2                  2.0               10.0              0.0            3.0   \n",
       "3                  4.0                8.0              1.0            0.0   \n",
       "4                  0.0                8.0              1.0            4.0   \n",
       "\n",
       "   Time Expiry (No Plant)_TeamA  Eliminated_TeamA  Defused Failed_TeamA  \\\n",
       "0                           0.0               4.0                   2.0   \n",
       "1                           0.0              10.0                   0.0   \n",
       "2                           0.0               8.0                   1.0   \n",
       "3                           1.0               8.0                   1.0   \n",
       "4                           0.0               8.0                   1.0   \n",
       "\n",
       "   Detonation Denied_TeamA  Time Expiry (Failed to Plant)_TeamA  \\\n",
       "0                      0.0                                  1.0   \n",
       "1                      3.0                                  0.0   \n",
       "2                      2.0                                  0.0   \n",
       "3                      4.0                                  0.0   \n",
       "4                      0.0                                  1.0   \n",
       "\n",
       "   Elimination_TeamB  Detonated_TeamB  Defused_TeamB  \\\n",
       "0                4.0              2.0            0.0   \n",
       "1               10.0              0.0            3.0   \n",
       "2                8.0              1.0            2.0   \n",
       "3                8.0              1.0            4.0   \n",
       "4                8.0              1.0            0.0   \n",
       "\n",
       "   Time Expiry (No Plant)_TeamB  Eliminated_TeamB  Defused Failed_TeamB  \\\n",
       "0                           1.0              10.0                   1.0   \n",
       "1                           0.0               8.0                   1.0   \n",
       "2                           0.0              10.0                   0.0   \n",
       "3                           0.0               8.0                   1.0   \n",
       "4                           1.0               8.0                   1.0   \n",
       "\n",
       "   Detonation Denied_TeamB  Time Expiry (Failed to Plant)_TeamB  KDA_TeamA  \\\n",
       "0                      2.0                                  0.0   1.666667   \n",
       "1                      2.0                                  0.0   1.337209   \n",
       "2                      3.0                                  0.0   1.592593   \n",
       "3                      0.0                                  1.0   1.232558   \n",
       "4                      4.0                                  0.0   1.443038   \n",
       "\n",
       "   Round Win %_TeamA  First Blood %_TeamA  Clutches_TeamA  \\\n",
       "0           0.650000             0.550000             1.0   \n",
       "1           0.458333             0.375000             1.0   \n",
       "2           0.541667             0.625000             1.0   \n",
       "3           0.434783             0.695652             4.0   \n",
       "4           0.565217             0.304348             2.0   \n",
       "\n",
       "   Attacker Win %_TeamA  Defender Win %_TeamA  Overtime Win %_TeamA  \\\n",
       "0              0.500000              0.750000                   0.0   \n",
       "1              0.416667              0.500000                   0.0   \n",
       "2              0.500000              0.583333                   0.0   \n",
       "3              0.416667              0.454545                   0.0   \n",
       "4              0.545455              0.583333                   0.0   \n",
       "\n",
       "   Rating_RollAvg_TeamA  Average Combat Score_RollAvg_TeamA  \\\n",
       "0                0.9240                              194.40   \n",
       "1                0.9364                              194.06   \n",
       "2                1.0512                              211.96   \n",
       "3                0.9648                              198.04   \n",
       "4                1.0178                              207.98   \n",
       "\n",
       "   Average Damage Per Round_RollAvg_TeamA  KDA_RollAvg_TeamA  \\\n",
       "0                                  125.38           1.301095   \n",
       "1                                  127.78           1.312059   \n",
       "2                                  136.70           1.607471   \n",
       "3                                  130.76           1.367839   \n",
       "4                                  134.68           1.434472   \n",
       "\n",
       "   Kill, Assist, Trade, Survive %_RollAvg_TeamA  Round Win %_RollAvg_TeamA  \\\n",
       "0                                        0.7012                   0.440863   \n",
       "1                                        0.6876                   0.459425   \n",
       "2                                        0.7350                   0.524396   \n",
       "3                                        0.6984                   0.486508   \n",
       "4                                        0.7212                   0.497312   \n",
       "\n",
       "   Attacker Win %_RollAvg_TeamA  Defender Win %_RollAvg_TeamA  \\\n",
       "0                      0.450000                      0.463308   \n",
       "1                      0.500000                      0.436111   \n",
       "2                      0.545014                      0.516667   \n",
       "3                      0.491667                      0.477778   \n",
       "4                      0.520014                      0.475000   \n",
       "\n",
       "   Overtime Win %_RollAvg_TeamA  First Blood %_RollAvg_TeamA  \\\n",
       "0                         0.000                     0.513037   \n",
       "1                         0.025                     0.460159   \n",
       "2                         0.000                     0.550017   \n",
       "3                         0.025                     0.472659   \n",
       "4                         0.000                     0.531267   \n",
       "\n",
       "   Headshot %_RollAvg_TeamA  Clutches_RollAvg_TeamA  Econ_RollAvg_TeamA  \\\n",
       "0                    0.2098                     1.6               50.04   \n",
       "1                    0.2482                     1.8               51.30   \n",
       "2                    0.2510                     1.4               57.50   \n",
       "3                    0.2430                     1.9               52.70   \n",
       "4                    0.2582                     1.4               54.70   \n",
       "\n",
       "   Recent Win %_TeamA  KDA_TeamB  Round Win %_TeamB  First Blood %_TeamB  \\\n",
       "0                 0.4   1.024390           0.350000             0.450000   \n",
       "1                 0.3   1.592593           0.541667             0.625000   \n",
       "2                 0.6   1.337209           0.458333             0.375000   \n",
       "3                 0.3   1.443038           0.565217             0.304348   \n",
       "4                 0.6   1.232558           0.434783             0.695652   \n",
       "\n",
       "   Clutches_TeamB  Attacker Win %_TeamB  Defender Win %_TeamB  \\\n",
       "0             3.0              0.250000              0.500000   \n",
       "1             1.0              0.500000              0.583333   \n",
       "2             1.0              0.416667              0.500000   \n",
       "3             2.0              0.545455              0.583333   \n",
       "4             4.0              0.416667              0.454545   \n",
       "\n",
       "   Overtime Win %_TeamB  Rating_RollAvg_TeamB  \\\n",
       "0                   0.0                0.9710   \n",
       "1                   0.0                1.0512   \n",
       "2                   0.0                0.9364   \n",
       "3                   0.0                1.0178   \n",
       "4                   0.0                0.9648   \n",
       "\n",
       "   Average Combat Score_RollAvg_TeamB  Average Damage Per Round_RollAvg_TeamB  \\\n",
       "0                              197.86                                  129.62   \n",
       "1                              211.96                                  136.70   \n",
       "2                              194.06                                  127.78   \n",
       "3                              207.98                                  134.68   \n",
       "4                              198.04                                  130.76   \n",
       "\n",
       "   KDA_RollAvg_TeamB  Kill, Assist, Trade, Survive %_RollAvg_TeamB  \\\n",
       "0           1.379461                                        0.7036   \n",
       "1           1.607471                                        0.7350   \n",
       "2           1.312059                                        0.6876   \n",
       "3           1.434472                                        0.7212   \n",
       "4           1.367839                                        0.6984   \n",
       "\n",
       "   Round Win %_RollAvg_TeamB  Attacker Win %_RollAvg_TeamB  \\\n",
       "0                   0.489425                      0.562500   \n",
       "1                   0.524396                      0.545014   \n",
       "2                   0.459425                      0.500000   \n",
       "3                   0.497312                      0.520014   \n",
       "4                   0.486508                      0.491667   \n",
       "\n",
       "   Defender Win %_RollAvg_TeamB  Overtime Win %_RollAvg_TeamB  \\\n",
       "0                      0.436111                         0.025   \n",
       "1                      0.516667                         0.000   \n",
       "2                      0.436111                         0.025   \n",
       "3                      0.475000                         0.000   \n",
       "4                      0.477778                         0.025   \n",
       "\n",
       "   First Blood %_RollAvg_TeamB  Headshot %_RollAvg_TeamB  \\\n",
       "0                     0.475159                    0.2452   \n",
       "1                     0.550017                    0.2510   \n",
       "2                     0.460159                    0.2482   \n",
       "3                     0.531267                    0.2582   \n",
       "4                     0.472659                    0.2430   \n",
       "\n",
       "   Clutches_RollAvg_TeamB  Econ_RollAvg_TeamB  Recent Win %_TeamB  \\\n",
       "0                     1.8               52.34                 0.6   \n",
       "1                     1.4               57.50                 0.4   \n",
       "2                     1.8               51.30                 0.7   \n",
       "3                     1.4               54.70                 0.4   \n",
       "4                     1.9               52.70                 0.7   \n",
       "\n",
       "   Team A Tournament Win %  Team A Map Win %  Team A H2H Win %  \\\n",
       "0                 0.500000          0.200000               0.5   \n",
       "1                 0.533333          0.666667               1.0   \n",
       "2                 0.680000          0.666667               0.0   \n",
       "3                 0.500000          0.600000               0.5   \n",
       "4                 0.692308          0.700000               0.5   \n",
       "\n",
       "   Team B Tournament Win %  Team B Map Win %  Team B H2H Win %  Map_Abyss  \\\n",
       "0                 0.571429          0.666667               0.5        0.0   \n",
       "1                 0.680000          0.666667               0.0        0.0   \n",
       "2                 0.533333          0.666667               1.0        0.0   \n",
       "3                 0.692308          0.700000               0.5        0.0   \n",
       "4                 0.500000          0.600000               0.5        0.0   \n",
       "\n",
       "   Map_Ascent  Map_Bind  Map_Breeze  Map_Fracture  Map_Haven  Map_Icebox  \\\n",
       "0         0.0       0.0         0.0           0.0        0.0         1.0   \n",
       "1         1.0       0.0         0.0           0.0        0.0         0.0   \n",
       "2         1.0       0.0         0.0           0.0        0.0         0.0   \n",
       "3         0.0       0.0         0.0           0.0        0.0         1.0   \n",
       "4         0.0       0.0         0.0           0.0        0.0         1.0   \n",
       "\n",
       "   Map_Lotus  Map_Pearl  Map_Split  Map_Sunset  Team A_Encoded  \\\n",
       "0        0.0        0.0        0.0         0.0        0.447334   \n",
       "1        0.0        0.0        0.0         0.0        0.572950   \n",
       "2        0.0        0.0        0.0         0.0        0.628433   \n",
       "3        0.0        0.0        0.0         0.0        0.572950   \n",
       "4        0.0        0.0        0.0         0.0        0.628433   \n",
       "\n",
       "   Team B_Encoded  Winner  \n",
       "0        0.414839       1  \n",
       "1        0.371567       0  \n",
       "2        0.414839       1  \n",
       "3        0.371567       0  \n",
       "4        0.414839       1  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"vct_data/test_preprocessed.csv\")\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection / Dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    \"Team A_Encoded\", \n",
    "    \"Team B_Encoded\",\n",
    "\n",
    "    \"Team A H2H Win %\",\n",
    "    \"Team B H2H Win %\",\n",
    "\n",
    "    \"Team A Tournament Win %\",\n",
    "    \"Team B Tournament Win %\",\n",
    "\n",
    "    \"Recent Win %_TeamA\",\n",
    "    \"Recent Win %_TeamB\",\n",
    "\n",
    "    \"Map_Abyss\",\n",
    "    \"Map_Ascent\",\n",
    "    \"Map_Bind\",\n",
    "    \"Map_Breeze\",\n",
    "    \"Map_Fracture\",\n",
    "    \"Map_Haven\",\n",
    "    \"Map_Icebox\",\n",
    "    \"Map_Lotus\",\n",
    "    \"Map_Pearl\",\n",
    "    \"Map_Split\",\n",
    "    \"Map_Sunset\",\n",
    "\n",
    "    \"Team A Map Win %\",\n",
    "    \"Team B Map Win %\",\n",
    "\n",
    "    \"Round Win %_RollAvg_TeamA\",\n",
    "    \"Round Win %_RollAvg_TeamB\",\n",
    "\n",
    "    \"Attacker Win %_RollAvg_TeamA\",\n",
    "    \"Attacker Win %_RollAvg_TeamB\",\n",
    "\n",
    "    \"Defender Win %_RollAvg_TeamA\",\n",
    "    \"Defender Win %_RollAvg_TeamB\",\n",
    "\n",
    "    \"Overtime Win %_RollAvg_TeamA\",\n",
    "    \"Overtime Win %_RollAvg_TeamB\",\n",
    "\n",
    "    \"Rating_RollAvg_TeamA\",\n",
    "    \"Rating_RollAvg_TeamB\",\n",
    "\n",
    "    \"Average Combat Score_RollAvg_TeamA\",\n",
    "    \"Average Combat Score_RollAvg_TeamB\", \n",
    "\n",
    "    \"Average Damage Per Round_RollAvg_TeamA\",\n",
    "    \"Average Damage Per Round_RollAvg_TeamB\",\n",
    "\n",
    "    \"KDA_RollAvg_TeamA\",\n",
    "    \"KDA_RollAvg_TeamB\",\n",
    "\n",
    "    \"Kill, Assist, Trade, Survive %_RollAvg_TeamA\", \n",
    "    \"Kill, Assist, Trade, Survive %_RollAvg_TeamB\",\n",
    "\n",
    "    \"First Blood %_RollAvg_TeamA\",\n",
    "    \"First Blood %_RollAvg_TeamB\",\n",
    "\n",
    "    \"Headshot %_RollAvg_TeamA\",\n",
    "    \"Headshot %_RollAvg_TeamB\",\n",
    "\n",
    "    \"Clutches_RollAvg_TeamA\",\n",
    "    \"Clutches_RollAvg_TeamB\",\n",
    "\n",
    "    \"Econ_RollAvg_TeamA\",\n",
    "    \"Econ_RollAvg_TeamB\",\n",
    "]\n",
    "\n",
    "X_train = train[features]\n",
    "y_train = train[\"Winner\"]\n",
    "\n",
    "X_test = test[features]\n",
    "y_test = test[\"Winner\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team A_Encoded</th>\n",
       "      <th>Team B_Encoded</th>\n",
       "      <th>Team A H2H Win %</th>\n",
       "      <th>Team B H2H Win %</th>\n",
       "      <th>Recent Win %_TeamA</th>\n",
       "      <th>Recent Win %_TeamB</th>\n",
       "      <th>Map_Abyss</th>\n",
       "      <th>Map_Ascent</th>\n",
       "      <th>Map_Bind</th>\n",
       "      <th>Map_Breeze</th>\n",
       "      <th>Map_Fracture</th>\n",
       "      <th>Map_Haven</th>\n",
       "      <th>Map_Icebox</th>\n",
       "      <th>Map_Lotus</th>\n",
       "      <th>Map_Pearl</th>\n",
       "      <th>Map_Split</th>\n",
       "      <th>Map_Sunset</th>\n",
       "      <th>Team A Map Win %</th>\n",
       "      <th>Team B Map Win %</th>\n",
       "      <th>Attacker Win %_RollAvg_TeamA</th>\n",
       "      <th>Attacker Win %_RollAvg_TeamB</th>\n",
       "      <th>Defender Win %_RollAvg_TeamA</th>\n",
       "      <th>Defender Win %_RollAvg_TeamB</th>\n",
       "      <th>Overtime Win %_RollAvg_TeamA</th>\n",
       "      <th>Overtime Win %_RollAvg_TeamB</th>\n",
       "      <th>Rating_RollAvg_TeamA</th>\n",
       "      <th>Rating_RollAvg_TeamB</th>\n",
       "      <th>Average Combat Score_RollAvg_TeamA</th>\n",
       "      <th>Average Combat Score_RollAvg_TeamB</th>\n",
       "      <th>Average Damage Per Round_RollAvg_TeamA</th>\n",
       "      <th>Average Damage Per Round_RollAvg_TeamB</th>\n",
       "      <th>KDA_RollAvg_TeamA</th>\n",
       "      <th>KDA_RollAvg_TeamB</th>\n",
       "      <th>Kill, Assist, Trade, Survive %_RollAvg_TeamA</th>\n",
       "      <th>Kill, Assist, Trade, Survive %_RollAvg_TeamB</th>\n",
       "      <th>First Blood %_RollAvg_TeamA</th>\n",
       "      <th>First Blood %_RollAvg_TeamB</th>\n",
       "      <th>Headshot %_RollAvg_TeamA</th>\n",
       "      <th>Headshot %_RollAvg_TeamB</th>\n",
       "      <th>Clutches_RollAvg_TeamA</th>\n",
       "      <th>Clutches_RollAvg_TeamB</th>\n",
       "      <th>Econ_RollAvg_TeamA</th>\n",
       "      <th>Econ_RollAvg_TeamB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.559545</td>\n",
       "      <td>0.534094</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.465905</td>\n",
       "      <td>0.440455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.559545</td>\n",
       "      <td>0.534094</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.990122</td>\n",
       "      <td>0.990134</td>\n",
       "      <td>186.0</td>\n",
       "      <td>218.4</td>\n",
       "      <td>119.6</td>\n",
       "      <td>132.8</td>\n",
       "      <td>1.078947</td>\n",
       "      <td>1.683333</td>\n",
       "      <td>0.699855</td>\n",
       "      <td>0.699858</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.517956</td>\n",
       "      <td>53.51867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.465905</td>\n",
       "      <td>0.440455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.990122</td>\n",
       "      <td>0.990134</td>\n",
       "      <td>218.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>132.8</td>\n",
       "      <td>119.6</td>\n",
       "      <td>1.683333</td>\n",
       "      <td>1.078947</td>\n",
       "      <td>0.699855</td>\n",
       "      <td>0.699858</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.517956</td>\n",
       "      <td>53.51867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.313396</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Team A_Encoded  Team B_Encoded  Team A H2H Win %  Team B H2H Win %  \\\n",
       "0        0.559545        0.534094               0.0               0.0   \n",
       "1        0.465905        0.440455               0.0               0.0   \n",
       "2        0.559545        0.534094               0.0               0.0   \n",
       "3        0.465905        0.440455               0.0               0.0   \n",
       "4        0.000000        0.313396               0.0               0.0   \n",
       "\n",
       "   Recent Win %_TeamA  Recent Win %_TeamB  Map_Abyss  Map_Ascent  Map_Bind  \\\n",
       "0                 0.0                 0.0        0.0         1.0       0.0   \n",
       "1                 0.0                 0.0        0.0         1.0       0.0   \n",
       "2                 0.0                 0.0        0.0         0.0       1.0   \n",
       "3                 1.0                 1.0        0.0         0.0       1.0   \n",
       "4                 0.0                 0.0        0.0         0.0       1.0   \n",
       "\n",
       "   Map_Breeze  Map_Fracture  Map_Haven  Map_Icebox  Map_Lotus  Map_Pearl  \\\n",
       "0         0.0           0.0        0.0         0.0        0.0        0.0   \n",
       "1         0.0           0.0        0.0         0.0        0.0        0.0   \n",
       "2         0.0           0.0        0.0         0.0        0.0        0.0   \n",
       "3         0.0           0.0        0.0         0.0        0.0        0.0   \n",
       "4         0.0           0.0        0.0         0.0        0.0        0.0   \n",
       "\n",
       "   Map_Split  Map_Sunset  Team A Map Win %  Team B Map Win %  \\\n",
       "0        0.0         0.0               0.0               0.0   \n",
       "1        0.0         0.0               0.0               0.0   \n",
       "2        0.0         0.0               0.0               0.0   \n",
       "3        0.0         0.0               0.0               0.0   \n",
       "4        0.0         0.0               0.0               0.0   \n",
       "\n",
       "   Attacker Win %_RollAvg_TeamA  Attacker Win %_RollAvg_TeamB  \\\n",
       "0                         0.000                         0.000   \n",
       "1                         0.000                         0.000   \n",
       "2                         0.500                         0.875   \n",
       "3                         0.875                         0.500   \n",
       "4                         0.000                         0.000   \n",
       "\n",
       "   Defender Win %_RollAvg_TeamA  Defender Win %_RollAvg_TeamB  \\\n",
       "0                         0.000                         0.000   \n",
       "1                         0.000                         0.000   \n",
       "2                         0.125                         0.500   \n",
       "3                         0.500                         0.125   \n",
       "4                         0.000                         0.000   \n",
       "\n",
       "   Overtime Win %_RollAvg_TeamA  Overtime Win %_RollAvg_TeamB  \\\n",
       "0                           0.0                           0.0   \n",
       "1                           0.0                           0.0   \n",
       "2                           0.0                           0.0   \n",
       "3                           0.0                           0.0   \n",
       "4                           0.0                           0.0   \n",
       "\n",
       "   Rating_RollAvg_TeamA  Rating_RollAvg_TeamB  \\\n",
       "0              0.000000              0.000000   \n",
       "1              0.000000              0.000000   \n",
       "2              0.990122              0.990134   \n",
       "3              0.990122              0.990134   \n",
       "4              0.000000              0.000000   \n",
       "\n",
       "   Average Combat Score_RollAvg_TeamA  Average Combat Score_RollAvg_TeamB  \\\n",
       "0                                 0.0                                 0.0   \n",
       "1                                 0.0                                 0.0   \n",
       "2                               186.0                               218.4   \n",
       "3                               218.4                               186.0   \n",
       "4                                 0.0                                 0.0   \n",
       "\n",
       "   Average Damage Per Round_RollAvg_TeamA  \\\n",
       "0                                     0.0   \n",
       "1                                     0.0   \n",
       "2                                   119.6   \n",
       "3                                   132.8   \n",
       "4                                     0.0   \n",
       "\n",
       "   Average Damage Per Round_RollAvg_TeamB  KDA_RollAvg_TeamA  \\\n",
       "0                                     0.0           0.000000   \n",
       "1                                     0.0           0.000000   \n",
       "2                                   132.8           1.078947   \n",
       "3                                   119.6           1.683333   \n",
       "4                                     0.0           0.000000   \n",
       "\n",
       "   KDA_RollAvg_TeamB  Kill, Assist, Trade, Survive %_RollAvg_TeamA  \\\n",
       "0           0.000000                                      0.000000   \n",
       "1           0.000000                                      0.000000   \n",
       "2           1.683333                                      0.699855   \n",
       "3           1.078947                                      0.699855   \n",
       "4           0.000000                                      0.000000   \n",
       "\n",
       "   Kill, Assist, Trade, Survive %_RollAvg_TeamB  First Blood %_RollAvg_TeamA  \\\n",
       "0                                      0.000000                          0.0   \n",
       "1                                      0.000000                          0.0   \n",
       "2                                      0.699858                          0.5   \n",
       "3                                      0.699858                          0.5   \n",
       "4                                      0.000000                          0.0   \n",
       "\n",
       "   First Blood %_RollAvg_TeamB  Headshot %_RollAvg_TeamA  \\\n",
       "0                          0.0                      0.00   \n",
       "1                          0.0                      0.00   \n",
       "2                          0.5                      0.25   \n",
       "3                          0.5                      0.19   \n",
       "4                          0.0                      0.00   \n",
       "\n",
       "   Headshot %_RollAvg_TeamB  Clutches_RollAvg_TeamA  Clutches_RollAvg_TeamB  \\\n",
       "0                      0.00                     0.0                     0.0   \n",
       "1                      0.00                     0.0                     0.0   \n",
       "2                      0.19                     0.0                     0.0   \n",
       "3                      0.25                     0.0                     0.0   \n",
       "4                      0.00                     0.0                     0.0   \n",
       "\n",
       "   Econ_RollAvg_TeamA  Econ_RollAvg_TeamB  \n",
       "0            0.000000             0.00000  \n",
       "1            0.000000             0.00000  \n",
       "2           53.517956            53.51867  \n",
       "3           53.517956            53.51867  \n",
       "4            0.000000             0.00000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40497, 43)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team A_Encoded</th>\n",
       "      <th>Team B_Encoded</th>\n",
       "      <th>Team A H2H Win %</th>\n",
       "      <th>Team B H2H Win %</th>\n",
       "      <th>Recent Win %_TeamA</th>\n",
       "      <th>Recent Win %_TeamB</th>\n",
       "      <th>Map_Abyss</th>\n",
       "      <th>Map_Ascent</th>\n",
       "      <th>Map_Bind</th>\n",
       "      <th>Map_Breeze</th>\n",
       "      <th>Map_Fracture</th>\n",
       "      <th>Map_Haven</th>\n",
       "      <th>Map_Icebox</th>\n",
       "      <th>Map_Lotus</th>\n",
       "      <th>Map_Pearl</th>\n",
       "      <th>Map_Split</th>\n",
       "      <th>Map_Sunset</th>\n",
       "      <th>Team A Map Win %</th>\n",
       "      <th>Team B Map Win %</th>\n",
       "      <th>Attacker Win %_RollAvg_TeamA</th>\n",
       "      <th>Attacker Win %_RollAvg_TeamB</th>\n",
       "      <th>Defender Win %_RollAvg_TeamA</th>\n",
       "      <th>Defender Win %_RollAvg_TeamB</th>\n",
       "      <th>Overtime Win %_RollAvg_TeamA</th>\n",
       "      <th>Overtime Win %_RollAvg_TeamB</th>\n",
       "      <th>Rating_RollAvg_TeamA</th>\n",
       "      <th>Rating_RollAvg_TeamB</th>\n",
       "      <th>Average Combat Score_RollAvg_TeamA</th>\n",
       "      <th>Average Combat Score_RollAvg_TeamB</th>\n",
       "      <th>Average Damage Per Round_RollAvg_TeamA</th>\n",
       "      <th>Average Damage Per Round_RollAvg_TeamB</th>\n",
       "      <th>KDA_RollAvg_TeamA</th>\n",
       "      <th>KDA_RollAvg_TeamB</th>\n",
       "      <th>Kill, Assist, Trade, Survive %_RollAvg_TeamA</th>\n",
       "      <th>Kill, Assist, Trade, Survive %_RollAvg_TeamB</th>\n",
       "      <th>First Blood %_RollAvg_TeamA</th>\n",
       "      <th>First Blood %_RollAvg_TeamB</th>\n",
       "      <th>Headshot %_RollAvg_TeamA</th>\n",
       "      <th>Headshot %_RollAvg_TeamB</th>\n",
       "      <th>Clutches_RollAvg_TeamA</th>\n",
       "      <th>Clutches_RollAvg_TeamB</th>\n",
       "      <th>Econ_RollAvg_TeamA</th>\n",
       "      <th>Econ_RollAvg_TeamB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.447334</td>\n",
       "      <td>0.427049</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.463308</td>\n",
       "      <td>0.436111</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.9240</td>\n",
       "      <td>0.9710</td>\n",
       "      <td>194.40</td>\n",
       "      <td>197.86</td>\n",
       "      <td>125.38</td>\n",
       "      <td>129.62</td>\n",
       "      <td>1.301095</td>\n",
       "      <td>1.379461</td>\n",
       "      <td>0.7012</td>\n",
       "      <td>0.7036</td>\n",
       "      <td>0.513037</td>\n",
       "      <td>0.475159</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.2452</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>50.04</td>\n",
       "      <td>52.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.561244</td>\n",
       "      <td>0.371567</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.545014</td>\n",
       "      <td>0.436111</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.9364</td>\n",
       "      <td>1.0512</td>\n",
       "      <td>194.06</td>\n",
       "      <td>211.96</td>\n",
       "      <td>127.78</td>\n",
       "      <td>136.70</td>\n",
       "      <td>1.312059</td>\n",
       "      <td>1.607471</td>\n",
       "      <td>0.6876</td>\n",
       "      <td>0.7350</td>\n",
       "      <td>0.460159</td>\n",
       "      <td>0.550017</td>\n",
       "      <td>0.2482</td>\n",
       "      <td>0.2510</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>51.30</td>\n",
       "      <td>57.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.628433</td>\n",
       "      <td>0.427049</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.545014</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.436111</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.025</td>\n",
       "      <td>1.0512</td>\n",
       "      <td>0.9364</td>\n",
       "      <td>211.96</td>\n",
       "      <td>194.06</td>\n",
       "      <td>136.70</td>\n",
       "      <td>127.78</td>\n",
       "      <td>1.607471</td>\n",
       "      <td>1.312059</td>\n",
       "      <td>0.7350</td>\n",
       "      <td>0.6876</td>\n",
       "      <td>0.550017</td>\n",
       "      <td>0.460159</td>\n",
       "      <td>0.2510</td>\n",
       "      <td>0.2482</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.8</td>\n",
       "      <td>57.50</td>\n",
       "      <td>51.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.561244</td>\n",
       "      <td>0.371567</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.491667</td>\n",
       "      <td>0.520014</td>\n",
       "      <td>0.477778</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.9648</td>\n",
       "      <td>1.0178</td>\n",
       "      <td>198.04</td>\n",
       "      <td>207.98</td>\n",
       "      <td>130.76</td>\n",
       "      <td>134.68</td>\n",
       "      <td>1.367839</td>\n",
       "      <td>1.434472</td>\n",
       "      <td>0.6984</td>\n",
       "      <td>0.7212</td>\n",
       "      <td>0.472659</td>\n",
       "      <td>0.531267</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.2582</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>52.70</td>\n",
       "      <td>54.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.628433</td>\n",
       "      <td>0.427049</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.520014</td>\n",
       "      <td>0.491667</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.477778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.025</td>\n",
       "      <td>1.0178</td>\n",
       "      <td>0.9648</td>\n",
       "      <td>207.98</td>\n",
       "      <td>198.04</td>\n",
       "      <td>134.68</td>\n",
       "      <td>130.76</td>\n",
       "      <td>1.434472</td>\n",
       "      <td>1.367839</td>\n",
       "      <td>0.7212</td>\n",
       "      <td>0.6984</td>\n",
       "      <td>0.531267</td>\n",
       "      <td>0.472659</td>\n",
       "      <td>0.2582</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>54.70</td>\n",
       "      <td>52.70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Team A_Encoded  Team B_Encoded  Team A H2H Win %  Team B H2H Win %  \\\n",
       "0        0.447334        0.427049               0.0               0.0   \n",
       "1        0.561244        0.371567               0.0               0.0   \n",
       "2        0.628433        0.427049               0.0               0.0   \n",
       "3        0.561244        0.371567               0.0               0.0   \n",
       "4        0.628433        0.427049               0.0               0.0   \n",
       "\n",
       "   Recent Win %_TeamA  Recent Win %_TeamB  Map_Abyss  Map_Ascent  Map_Bind  \\\n",
       "0                 0.4                 0.6        0.0         0.0       0.0   \n",
       "1                 0.3                 0.4        0.0         1.0       0.0   \n",
       "2                 0.6                 0.7        0.0         1.0       0.0   \n",
       "3                 0.3                 0.4        0.0         0.0       0.0   \n",
       "4                 0.6                 0.7        0.0         0.0       0.0   \n",
       "\n",
       "   Map_Breeze  Map_Fracture  Map_Haven  Map_Icebox  Map_Lotus  Map_Pearl  \\\n",
       "0         0.0           0.0        0.0         1.0        0.0        0.0   \n",
       "1         0.0           0.0        0.0         0.0        0.0        0.0   \n",
       "2         0.0           0.0        0.0         0.0        0.0        0.0   \n",
       "3         0.0           0.0        0.0         1.0        0.0        0.0   \n",
       "4         0.0           0.0        0.0         1.0        0.0        0.0   \n",
       "\n",
       "   Map_Split  Map_Sunset  Team A Map Win %  Team B Map Win %  \\\n",
       "0        0.0         0.0               0.0               0.0   \n",
       "1        0.0         0.0               0.0               0.0   \n",
       "2        0.0         0.0               0.0               0.0   \n",
       "3        0.0         0.0               0.0               0.0   \n",
       "4        0.0         0.0               0.0               0.0   \n",
       "\n",
       "   Attacker Win %_RollAvg_TeamA  Attacker Win %_RollAvg_TeamB  \\\n",
       "0                      0.450000                      0.562500   \n",
       "1                      0.500000                      0.545014   \n",
       "2                      0.545014                      0.500000   \n",
       "3                      0.491667                      0.520014   \n",
       "4                      0.520014                      0.491667   \n",
       "\n",
       "   Defender Win %_RollAvg_TeamA  Defender Win %_RollAvg_TeamB  \\\n",
       "0                      0.463308                      0.436111   \n",
       "1                      0.436111                      0.516667   \n",
       "2                      0.516667                      0.436111   \n",
       "3                      0.477778                      0.475000   \n",
       "4                      0.475000                      0.477778   \n",
       "\n",
       "   Overtime Win %_RollAvg_TeamA  Overtime Win %_RollAvg_TeamB  \\\n",
       "0                         0.000                         0.025   \n",
       "1                         0.025                         0.000   \n",
       "2                         0.000                         0.025   \n",
       "3                         0.025                         0.000   \n",
       "4                         0.000                         0.025   \n",
       "\n",
       "   Rating_RollAvg_TeamA  Rating_RollAvg_TeamB  \\\n",
       "0                0.9240                0.9710   \n",
       "1                0.9364                1.0512   \n",
       "2                1.0512                0.9364   \n",
       "3                0.9648                1.0178   \n",
       "4                1.0178                0.9648   \n",
       "\n",
       "   Average Combat Score_RollAvg_TeamA  Average Combat Score_RollAvg_TeamB  \\\n",
       "0                              194.40                              197.86   \n",
       "1                              194.06                              211.96   \n",
       "2                              211.96                              194.06   \n",
       "3                              198.04                              207.98   \n",
       "4                              207.98                              198.04   \n",
       "\n",
       "   Average Damage Per Round_RollAvg_TeamA  \\\n",
       "0                                  125.38   \n",
       "1                                  127.78   \n",
       "2                                  136.70   \n",
       "3                                  130.76   \n",
       "4                                  134.68   \n",
       "\n",
       "   Average Damage Per Round_RollAvg_TeamB  KDA_RollAvg_TeamA  \\\n",
       "0                                  129.62           1.301095   \n",
       "1                                  136.70           1.312059   \n",
       "2                                  127.78           1.607471   \n",
       "3                                  134.68           1.367839   \n",
       "4                                  130.76           1.434472   \n",
       "\n",
       "   KDA_RollAvg_TeamB  Kill, Assist, Trade, Survive %_RollAvg_TeamA  \\\n",
       "0           1.379461                                        0.7012   \n",
       "1           1.607471                                        0.6876   \n",
       "2           1.312059                                        0.7350   \n",
       "3           1.434472                                        0.6984   \n",
       "4           1.367839                                        0.7212   \n",
       "\n",
       "   Kill, Assist, Trade, Survive %_RollAvg_TeamB  First Blood %_RollAvg_TeamA  \\\n",
       "0                                        0.7036                     0.513037   \n",
       "1                                        0.7350                     0.460159   \n",
       "2                                        0.6876                     0.550017   \n",
       "3                                        0.7212                     0.472659   \n",
       "4                                        0.6984                     0.531267   \n",
       "\n",
       "   First Blood %_RollAvg_TeamB  Headshot %_RollAvg_TeamA  \\\n",
       "0                     0.475159                    0.2098   \n",
       "1                     0.550017                    0.2482   \n",
       "2                     0.460159                    0.2510   \n",
       "3                     0.531267                    0.2430   \n",
       "4                     0.472659                    0.2582   \n",
       "\n",
       "   Headshot %_RollAvg_TeamB  Clutches_RollAvg_TeamA  Clutches_RollAvg_TeamB  \\\n",
       "0                    0.2452                     1.6                     1.8   \n",
       "1                    0.2510                     1.8                     1.4   \n",
       "2                    0.2482                     1.4                     1.8   \n",
       "3                    0.2582                     1.9                     1.4   \n",
       "4                    0.2430                     1.4                     1.9   \n",
       "\n",
       "   Econ_RollAvg_TeamA  Econ_RollAvg_TeamB  \n",
       "0               50.04               52.34  \n",
       "1               51.30               57.50  \n",
       "2               57.50               51.30  \n",
       "3               52.70               54.70  \n",
       "4               54.70               52.70  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10125, 43)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling features (for Logistic Regression only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection\n",
    "\n",
    "We will be using the following models:\n",
    "- Logistic Regression\n",
    "- Random Forest\n",
    "- XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for cross-validating the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCORING = [\"accuracy\", \"precision\", \"recall\", \"f1\", \"roc_auc\"]\n",
    "\n",
    "def evaluate_model(model, X_train, y_train, cv=5, scoring=SCORING):\n",
    "    tscv = TimeSeriesSplit(n_splits=cv)\n",
    "    scores = cross_validate(model, X_train, y_train, cv=tscv, scoring=scoring)\n",
    "\n",
    "    for metric in SCORING:\n",
    "        print(f\"{metric}: {scores[f'test_{metric}'].mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training baseline models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_base = LogisticRegression(random_state=RANDOM_SEED)\n",
    "rf_base = RandomForestClassifier(random_state=RANDOM_SEED)\n",
    "xgb_base = XGBClassifier(random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Baseline\n",
      "accuracy: 0.6401244628833902\n",
      "precision: 0.6442510573823335\n",
      "recall: 0.6255933609958506\n",
      "f1: 0.6347549979983406\n",
      "roc_auc: 0.6999770796285318\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Logistic Regression Baseline\")\n",
    "evaluate_model(logreg_base, X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Baseline\n",
      "accuracy: 0.6546451326122389\n",
      "precision: 0.6571254593167938\n",
      "recall: 0.6467517969659048\n",
      "f1: 0.6518551835545527\n",
      "roc_auc: 0.724818819293508\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Forest Baseline\")\n",
    "evaluate_model(rf_base, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Baseline\n",
      "accuracy: 0.6421988442732257\n",
      "precision: 0.6402750492669487\n",
      "recall: 0.6492420909350369\n",
      "f1: 0.6445866901474966\n",
      "roc_auc: 0.7057225844694723\n"
     ]
    }
   ],
   "source": [
    "print(\"XGBoost Baseline\")\n",
    "evaluate_model(xgb_base, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensures the splits are in chronological order\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "ITERATIONS = 100\n",
    "\n",
    "# Number of CPU cores to use (-1 means for all cores)\n",
    "N_JOBS = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "logreg_params = {\n",
    "    \"C\": [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    \"penalty\": [\"l1\", \"l2\"],\n",
    "    \"solver\": [\"liblinear\", \"saga\"],\n",
    "    \"max_iter\": [100, 200, 300, 400, 500, 1000]\n",
    "}\n",
    "\n",
    "logreg_random = RandomizedSearchCV(LogisticRegression(random_state=RANDOM_SEED), \n",
    "                                   logreg_params, \n",
    "                                   n_iter=ITERATIONS, \n",
    "                                   cv=tscv, \n",
    "                                   scoring=SCORING,\n",
    "                                   refit=\"accuracy\", \n",
    "                                   random_state=RANDOM_SEED, \n",
    "                                   n_jobs=N_JOBS,\n",
    "                                   error_score=\"raise\")\n",
    "\n",
    "logreg_random.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Logistic Regression Random Tuned\")\n",
    "print(\"Best params:\", logreg_random.best_params_)\n",
    "print(\"Best score (ROC-AUC):\", logreg_random.best_score_)\n",
    "\n",
    "print(\"\\nCross-validation scores:\")\n",
    "evaluate_model(logreg_random.best_estimator_, X_train_scaled, y_train)\n",
    "\n",
    "# Save model\n",
    "joblib.dump(logreg_random.best_estimator_, \"models/logreg_random_v1.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "rf_params = {\n",
    "    \"n_estimators\": [50, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000],\n",
    "    \"max_depth\": [None, 5, 10, 15, 20, 25, 30, 50, 100],\n",
    "    \"min_samples_split\": [2, 5, 10, 15, 20],\n",
    "    \"min_samples_leaf\": [1, 2, 4, 8, 16],\n",
    "    \"max_features\": [\"sqrt\", \"log2\", None],\n",
    "    \"bootstrap\": [True, False]\n",
    "}\n",
    "\n",
    "rf_random = RandomizedSearchCV(RandomForestClassifier(random_state=RANDOM_SEED),\n",
    "                              rf_params,\n",
    "                              n_iter=ITERATIONS,\n",
    "                              cv=tscv,\n",
    "                              scoring=SCORING,\n",
    "                              refit=\"accuracy\",\n",
    "                              random_state=RANDOM_SEED,\n",
    "                              n_jobs=N_JOBS,\n",
    "                              error_score=\"raise\")\n",
    "\n",
    "rf_random.fit(X_train, y_train)\n",
    "\n",
    "print(\"Random Forest Random Tuned\")\n",
    "print(\"Best params:\", rf_random.best_params_)\n",
    "print(\"Best score (ROC-AUC):\", rf_random.best_score_)\n",
    "\n",
    "print(\"\\nCross-validation scores:\")\n",
    "evaluate_model(rf_random.best_estimator_, X_train, y_train)\n",
    "\n",
    "joblib.dump(rf_random.best_estimator_, \"models/rf_random_v1.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "xgb_params = {\n",
    "    \"n_estimators\": [50, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000],\n",
    "    \"learning_rate\": [0.0001, 0.001, 0.01, 0.05, 0.1, 0.2, 0.3],\n",
    "    \"max_depth\": [3, 4, 5, 6, 8, 10, 12, 15],\n",
    "    \"subsample\": [0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    \"colsample_bytree\": [0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    \"gamma\": [0, 0.01, 0.1, 0.5, 1, 1.5, 2, 5, 10],\n",
    "    \"reg_alpha\": [0, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10],\n",
    "    \"reg_lambda\": [0, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10]\n",
    "}\n",
    "\n",
    "xgb_tuned = RandomizedSearchCV(XGBClassifier(random_state=RANDOM_SEED),\n",
    "                               xgb_params,\n",
    "                               n_iter=ITERATIONS,\n",
    "                               cv=tscv,\n",
    "                               scoring=SCORING,\n",
    "                               refit=\"roc_auc\",\n",
    "                               random_state=RANDOM_SEED,\n",
    "                               n_jobs=N_JOBS,\n",
    "                               error_score=\"raise\")\n",
    "\n",
    "xgb_tuned.fit(X_train, y_train)\n",
    "\n",
    "print(\"XGBoost Random Tuned\")\n",
    "print(\"Best params:\", xgb_tuned.best_params_)\n",
    "print(\"Best score (ROC-AUC):\", xgb_tuned.best_score_)\n",
    "\n",
    "print(\"\\nCross-validation scores:\")\n",
    "evaluate_model(xgb_tuned.best_estimator_, X_train, y_train)\n",
    "\n",
    "joblib.dump(xgb_tuned.best_estimator_, \"models/xgb_random_v1.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-22 01:14:03,049] A new study created in memory with name: no-name-de824323-417d-4b42-8d0f-3defc6b41f7a\n",
      "[I 2024-09-22 01:14:25,227] Trial 0 finished with value: 0.6697288487183286 and parameters: {'n_estimators': 707, 'max_depth': 48, 'min_samples_split': 7, 'min_samples_leaf': 16, 'max_features': 'sqrt'}. Best is trial 0 with value: 0.6697288487183286.\n",
      "[I 2024-09-22 01:14:51,718] Trial 1 finished with value: 0.6688990961623944 and parameters: {'n_estimators': 837, 'max_depth': 30, 'min_samples_split': 20, 'min_samples_leaf': 20, 'max_features': 'sqrt'}. Best is trial 0 with value: 0.6697288487183286.\n",
      "[I 2024-09-22 01:17:04,654] Trial 2 finished with value: 0.6532226996592089 and parameters: {'n_estimators': 535, 'max_depth': 32, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': None}. Best is trial 0 with value: 0.6697288487183286.\n",
      "[I 2024-09-22 01:17:10,432] Trial 3 finished with value: 0.6670617869313972 and parameters: {'n_estimators': 167, 'max_depth': 48, 'min_samples_split': 7, 'min_samples_leaf': 14, 'max_features': 'sqrt'}. Best is trial 0 with value: 0.6697288487183286.\n",
      "[I 2024-09-22 01:17:23,821] Trial 4 finished with value: 0.6678026374277671 and parameters: {'n_estimators': 492, 'max_depth': 15, 'min_samples_split': 26, 'min_samples_leaf': 9, 'max_features': 'log2'}. Best is trial 0 with value: 0.6697288487183286.\n",
      "[I 2024-09-22 01:18:39,601] Trial 5 finished with value: 0.6651948436805452 and parameters: {'n_estimators': 475, 'max_depth': 21, 'min_samples_split': 7, 'min_samples_leaf': 22, 'max_features': None}. Best is trial 0 with value: 0.6697288487183286.\n",
      "[I 2024-09-22 01:18:42,539] Trial 6 finished with value: 0.6686620240035561 and parameters: {'n_estimators': 101, 'max_depth': 40, 'min_samples_split': 32, 'min_samples_leaf': 28, 'max_features': 'sqrt'}. Best is trial 0 with value: 0.6697288487183286.\n",
      "[I 2024-09-22 01:18:54,859] Trial 7 finished with value: 0.6686027559638466 and parameters: {'n_estimators': 538, 'max_depth': 34, 'min_samples_split': 22, 'min_samples_leaf': 31, 'max_features': 'log2'}. Best is trial 0 with value: 0.6697288487183286.\n",
      "[I 2024-09-22 01:19:22,766] Trial 8 finished with value: 0.6691658023410876 and parameters: {'n_estimators': 979, 'max_depth': 43, 'min_samples_split': 31, 'min_samples_leaf': 21, 'max_features': 'sqrt'}. Best is trial 0 with value: 0.6697288487183286.\n",
      "[I 2024-09-22 01:19:49,814] Trial 9 finished with value: 0.6685138539042821 and parameters: {'n_estimators': 940, 'max_depth': 19, 'min_samples_split': 30, 'min_samples_leaf': 9, 'max_features': 'log2'}. Best is trial 0 with value: 0.6697288487183286.\n",
      "[I 2024-09-22 01:20:07,204] Trial 10 finished with value: 0.6686620240035561 and parameters: {'n_estimators': 731, 'max_depth': 9, 'min_samples_split': 14, 'min_samples_leaf': 13, 'max_features': 'sqrt'}. Best is trial 0 with value: 0.6697288487183286.\n",
      "[I 2024-09-22 01:20:35,300] Trial 11 finished with value: 0.6697881167580383 and parameters: {'n_estimators': 984, 'max_depth': 50, 'min_samples_split': 13, 'min_samples_leaf': 23, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.6697881167580383.\n",
      "[I 2024-09-22 01:20:55,384] Trial 12 finished with value: 0.6694621425396354 and parameters: {'n_estimators': 717, 'max_depth': 49, 'min_samples_split': 13, 'min_samples_leaf': 26, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.6697881167580383.\n",
      "[I 2024-09-22 01:21:04,939] Trial 13 finished with value: 0.6684545858645725 and parameters: {'n_estimators': 321, 'max_depth': 40, 'min_samples_split': 11, 'min_samples_leaf': 18, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.6697881167580383.\n",
      "[I 2024-09-22 01:21:24,914] Trial 14 finished with value: 0.668543487924137 and parameters: {'n_estimators': 689, 'max_depth': 45, 'min_samples_split': 3, 'min_samples_leaf': 25, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.6697881167580383.\n",
      "[I 2024-09-22 01:23:43,903] Trial 15 finished with value: 0.6640094828863535 and parameters: {'n_estimators': 824, 'max_depth': 50, 'min_samples_split': 17, 'min_samples_leaf': 15, 'max_features': None}. Best is trial 11 with value: 0.6697881167580383.\n",
      "[I 2024-09-22 01:24:14,712] Trial 16 finished with value: 0.6677433693880575 and parameters: {'n_estimators': 824, 'max_depth': 38, 'min_samples_split': 9, 'min_samples_leaf': 8, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.6697881167580383.\n",
      "[I 2024-09-22 01:24:26,176] Trial 17 finished with value: 0.6686027559638466 and parameters: {'n_estimators': 358, 'max_depth': 26, 'min_samples_split': 17, 'min_samples_leaf': 31, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.6697881167580383.\n",
      "[I 2024-09-22 01:24:42,718] Trial 18 finished with value: 0.6694621425396355 and parameters: {'n_estimators': 639, 'max_depth': 37, 'min_samples_split': 2, 'min_samples_leaf': 24, 'max_features': 'log2'}. Best is trial 11 with value: 0.6697881167580383.\n",
      "[I 2024-09-22 01:27:13,429] Trial 19 finished with value: 0.6652837457401096 and parameters: {'n_estimators': 923, 'max_depth': 44, 'min_samples_split': 13, 'min_samples_leaf': 18, 'max_features': None}. Best is trial 11 with value: 0.6697881167580383.\n",
      "[I 2024-09-22 01:27:35,918] Trial 20 finished with value: 0.664809601422433 and parameters: {'n_estimators': 616, 'max_depth': 27, 'min_samples_split': 9, 'min_samples_leaf': 4, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.6697881167580383.\n",
      "[I 2024-09-22 01:27:49,950] Trial 21 finished with value: 0.6691065343013779 and parameters: {'n_estimators': 604, 'max_depth': 36, 'min_samples_split': 2, 'min_samples_leaf': 24, 'max_features': 'log2'}. Best is trial 11 with value: 0.6697881167580383.\n",
      "[I 2024-09-22 01:27:58,885] Trial 22 finished with value: 0.6691954363609425 and parameters: {'n_estimators': 386, 'max_depth': 43, 'min_samples_split': 5, 'min_samples_leaf': 28, 'max_features': 'log2'}. Best is trial 11 with value: 0.6697881167580383.\n",
      "[I 2024-09-22 01:28:17,162] Trial 23 finished with value: 0.6688694621425396 and parameters: {'n_estimators': 768, 'max_depth': 46, 'min_samples_split': 6, 'min_samples_leaf': 23, 'max_features': 'log2'}. Best is trial 11 with value: 0.6697881167580383.\n",
      "[I 2024-09-22 01:28:33,257] Trial 24 finished with value: 0.6691658023410876 and parameters: {'n_estimators': 610, 'max_depth': 40, 'min_samples_split': 10, 'min_samples_leaf': 17, 'max_features': 'log2'}. Best is trial 11 with value: 0.6697881167580383.\n",
      "[I 2024-09-22 01:28:55,615] Trial 25 finished with value: 0.6687212920432657 and parameters: {'n_estimators': 905, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 20, 'max_features': 'log2'}. Best is trial 11 with value: 0.6697881167580383.\n",
      "[I 2024-09-22 01:29:16,936] Trial 26 finished with value: 0.667950807527041 and parameters: {'n_estimators': 661, 'max_depth': 36, 'min_samples_split': 15, 'min_samples_leaf': 11, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.6697881167580383.\n",
      "[I 2024-09-22 01:29:39,744] Trial 27 finished with value: 0.6694325085197808 and parameters: {'n_estimators': 860, 'max_depth': 46, 'min_samples_split': 8, 'min_samples_leaf': 27, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.6697881167580383.\n",
      "[I 2024-09-22 01:31:37,658] Trial 28 finished with value: 0.6652244777004 and parameters: {'n_estimators': 765, 'max_depth': 41, 'min_samples_split': 12, 'min_samples_leaf': 20, 'max_features': None}. Best is trial 11 with value: 0.6697881167580383.\n",
      "[I 2024-09-22 01:31:45,204] Trial 29 finished with value: 0.6683656838050082 and parameters: {'n_estimators': 272, 'max_depth': 30, 'min_samples_split': 19, 'min_samples_leaf': 16, 'max_features': 'log2'}. Best is trial 11 with value: 0.6697881167580383.\n",
      "[I 2024-09-22 01:31:57,685] Trial 30 finished with value: 0.6694325085197808 and parameters: {'n_estimators': 421, 'max_depth': 47, 'min_samples_split': 5, 'min_samples_leaf': 19, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.6697881167580383.\n",
      "[I 2024-09-22 01:32:17,773] Trial 31 finished with value: 0.6690769002815231 and parameters: {'n_estimators': 696, 'max_depth': 49, 'min_samples_split': 15, 'min_samples_leaf': 26, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.6697881167580383.\n",
      "[I 2024-09-22 01:32:36,275] Trial 32 finished with value: 0.6694325085197808 and parameters: {'n_estimators': 639, 'max_depth': 50, 'min_samples_split': 22, 'min_samples_leaf': 30, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.6697881167580383.\n",
      "[I 2024-09-22 01:32:57,806] Trial 33 finished with value: 0.6694325085197808 and parameters: {'n_estimators': 772, 'max_depth': 47, 'min_samples_split': 4, 'min_samples_leaf': 23, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.6697881167580383.\n",
      "[I 2024-09-22 01:33:14,241] Trial 34 finished with value: 0.6693436064602164 and parameters: {'n_estimators': 585, 'max_depth': 33, 'min_samples_split': 12, 'min_samples_leaf': 25, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.6697881167580383.\n",
      "[I 2024-09-22 01:33:27,500] Trial 35 finished with value: 0.6700844569565862 and parameters: {'n_estimators': 499, 'max_depth': 43, 'min_samples_split': 7, 'min_samples_leaf': 29, 'max_features': 'sqrt'}. Best is trial 35 with value: 0.6700844569565862.\n",
      "[I 2024-09-22 01:34:36,220] Trial 36 finished with value: 0.6655800859386576 and parameters: {'n_estimators': 464, 'max_depth': 42, 'min_samples_split': 7, 'min_samples_leaf': 29, 'max_features': None}. Best is trial 35 with value: 0.6700844569565862.\n",
      "[I 2024-09-22 01:34:50,633] Trial 37 finished with value: 0.6687805600829753 and parameters: {'n_estimators': 546, 'max_depth': 30, 'min_samples_split': 4, 'min_samples_leaf': 32, 'max_features': 'sqrt'}. Best is trial 35 with value: 0.6700844569565862.\n",
      "[I 2024-09-22 01:35:03,162] Trial 38 finished with value: 0.6694621425396354 and parameters: {'n_estimators': 487, 'max_depth': 37, 'min_samples_split': 6, 'min_samples_leaf': 22, 'max_features': 'log2'}. Best is trial 35 with value: 0.6700844569565862.\n",
      "[I 2024-09-22 01:35:10,803] Trial 39 finished with value: 0.6676841013483479 and parameters: {'n_estimators': 252, 'max_depth': 24, 'min_samples_split': 10, 'min_samples_leaf': 14, 'max_features': 'sqrt'}. Best is trial 35 with value: 0.6700844569565862.\n",
      "[I 2024-09-22 01:35:26,672] Trial 40 finished with value: 0.665817158097496 and parameters: {'n_estimators': 973, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 12, 'max_features': 'log2'}. Best is trial 35 with value: 0.6700844569565862.\n",
      "[I 2024-09-22 01:35:47,899] Trial 41 finished with value: 0.6691954363609424 and parameters: {'n_estimators': 717, 'max_depth': 48, 'min_samples_split': 14, 'min_samples_leaf': 27, 'max_features': 'sqrt'}. Best is trial 35 with value: 0.6700844569565862.\n",
      "[I 2024-09-22 01:36:05,216] Trial 42 finished with value: 0.6698770188176026 and parameters: {'n_estimators': 571, 'max_depth': 44, 'min_samples_split': 11, 'min_samples_leaf': 29, 'max_features': 'sqrt'}. Best is trial 35 with value: 0.6700844569565862.\n",
      "[I 2024-09-22 01:36:20,156] Trial 43 finished with value: 0.6702326270558602 and parameters: {'n_estimators': 509, 'max_depth': 44, 'min_samples_split': 11, 'min_samples_leaf': 29, 'max_features': 'sqrt'}. Best is trial 43 with value: 0.6702326270558602.\n",
      "[I 2024-09-22 01:36:33,305] Trial 44 finished with value: 0.6706475033338272 and parameters: {'n_estimators': 447, 'max_depth': 44, 'min_samples_split': 11, 'min_samples_leaf': 29, 'max_features': 'sqrt'}. Best is trial 44 with value: 0.6706475033338272.\n",
      "[I 2024-09-22 01:36:46,265] Trial 45 finished with value: 0.6687509260631205 and parameters: {'n_estimators': 439, 'max_depth': 44, 'min_samples_split': 11, 'min_samples_leaf': 30, 'max_features': 'sqrt'}. Best is trial 44 with value: 0.6706475033338272.\n",
      "[I 2024-09-22 01:37:04,606] Trial 46 finished with value: 0.6695510445991999 and parameters: {'n_estimators': 528, 'max_depth': 14, 'min_samples_split': 15, 'min_samples_leaf': 32, 'max_features': 'sqrt'}. Best is trial 44 with value: 0.6706475033338272.\n",
      "[I 2024-09-22 01:37:19,732] Trial 47 finished with value: 0.670262261075715 and parameters: {'n_estimators': 504, 'max_depth': 45, 'min_samples_split': 19, 'min_samples_leaf': 29, 'max_features': 'sqrt'}. Best is trial 44 with value: 0.6706475033338272.\n",
      "[I 2024-09-22 01:37:35,478] Trial 48 finished with value: 0.6702326270558602 and parameters: {'n_estimators': 509, 'max_depth': 39, 'min_samples_split': 19, 'min_samples_leaf': 29, 'max_features': 'sqrt'}. Best is trial 44 with value: 0.6706475033338272.\n",
      "[I 2024-09-22 01:37:49,905] Trial 49 finished with value: 0.6683656838050082 and parameters: {'n_estimators': 502, 'max_depth': 39, 'min_samples_split': 26, 'min_samples_leaf': 30, 'max_features': 'sqrt'}. Best is trial 44 with value: 0.6706475033338272.\n",
      "[I 2024-09-22 01:38:01,739] Trial 50 finished with value: 0.6685138539042821 and parameters: {'n_estimators': 408, 'max_depth': 42, 'min_samples_split': 21, 'min_samples_leaf': 28, 'max_features': 'sqrt'}. Best is trial 44 with value: 0.6706475033338272.\n",
      "[I 2024-09-22 01:38:17,946] Trial 51 finished with value: 0.6698770188176028 and parameters: {'n_estimators': 564, 'max_depth': 45, 'min_samples_split': 18, 'min_samples_leaf': 29, 'max_features': 'sqrt'}. Best is trial 44 with value: 0.6706475033338272.\n",
      "[I 2024-09-22 01:38:31,678] Trial 52 finished with value: 0.6690472662616684 and parameters: {'n_estimators': 510, 'max_depth': 45, 'min_samples_split': 19, 'min_samples_leaf': 27, 'max_features': 'sqrt'}. Best is trial 44 with value: 0.6706475033338272.\n",
      "[I 2024-09-22 01:38:41,115] Trial 53 finished with value: 0.6687805600829753 and parameters: {'n_estimators': 335, 'max_depth': 41, 'min_samples_split': 23, 'min_samples_leaf': 31, 'max_features': 'sqrt'}. Best is trial 44 with value: 0.6706475033338272.\n",
      "[I 2024-09-22 01:38:53,278] Trial 54 finished with value: 0.6706475033338272 and parameters: {'n_estimators': 447, 'max_depth': 39, 'min_samples_split': 18, 'min_samples_leaf': 29, 'max_features': 'sqrt'}. Best is trial 44 with value: 0.6706475033338272.\n",
      "[I 2024-09-22 01:39:07,469] Trial 55 finished with value: 0.6691361683212328 and parameters: {'n_estimators': 457, 'max_depth': 39, 'min_samples_split': 24, 'min_samples_leaf': 26, 'max_features': 'sqrt'}. Best is trial 44 with value: 0.6706475033338272.\n",
      "[I 2024-09-22 01:39:18,169] Trial 56 finished with value: 0.6688990961623944 and parameters: {'n_estimators': 384, 'max_depth': 33, 'min_samples_split': 19, 'min_samples_leaf': 32, 'max_features': 'sqrt'}. Best is trial 44 with value: 0.6706475033338272.\n",
      "[I 2024-09-22 01:40:26,426] Trial 57 finished with value: 0.6652837457401097 and parameters: {'n_estimators': 467, 'max_depth': 42, 'min_samples_split': 16, 'min_samples_leaf': 28, 'max_features': None}. Best is trial 44 with value: 0.6706475033338272.\n",
      "[I 2024-09-22 01:40:35,032] Trial 58 finished with value: 0.6699362868573122 and parameters: {'n_estimators': 290, 'max_depth': 34, 'min_samples_split': 17, 'min_samples_leaf': 25, 'max_features': 'sqrt'}. Best is trial 44 with value: 0.6706475033338272.\n",
      "[I 2024-09-22 01:40:50,037] Trial 59 finished with value: 0.6693436064602163 and parameters: {'n_estimators': 527, 'max_depth': 38, 'min_samples_split': 20, 'min_samples_leaf': 31, 'max_features': 'sqrt'}. Best is trial 44 with value: 0.6706475033338272.\n",
      "[I 2024-09-22 01:41:00,842] Trial 60 finished with value: 0.6703807971551341 and parameters: {'n_estimators': 373, 'max_depth': 43, 'min_samples_split': 18, 'min_samples_leaf': 29, 'max_features': 'sqrt'}. Best is trial 44 with value: 0.6706475033338272.\n",
      "[I 2024-09-22 01:41:11,776] Trial 61 finished with value: 0.670528967254408 and parameters: {'n_estimators': 367, 'max_depth': 47, 'min_samples_split': 21, 'min_samples_leaf': 29, 'max_features': 'sqrt'}. Best is trial 44 with value: 0.6706475033338272.\n",
      "[I 2024-09-22 01:41:18,082] Trial 62 finished with value: 0.6681878796858794 and parameters: {'n_estimators': 193, 'max_depth': 47, 'min_samples_split': 21, 'min_samples_leaf': 30, 'max_features': 'sqrt'}. Best is trial 44 with value: 0.6706475033338272.\n",
      "[I 2024-09-22 01:41:28,866] Trial 63 finished with value: 0.6685434879241369 and parameters: {'n_estimators': 369, 'max_depth': 48, 'min_samples_split': 25, 'min_samples_leaf': 27, 'max_features': 'sqrt'}. Best is trial 44 with value: 0.6706475033338272.\n",
      "[I 2024-09-22 01:41:40,471] Trial 64 finished with value: 0.6691361683212328 and parameters: {'n_estimators': 420, 'max_depth': 40, 'min_samples_split': 18, 'min_samples_leaf': 31, 'max_features': 'sqrt'}. Best is trial 44 with value: 0.6706475033338272.\n",
      "[I 2024-09-22 01:41:53,619] Trial 65 finished with value: 0.6672988590902355 and parameters: {'n_estimators': 339, 'max_depth': 45, 'min_samples_split': 29, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 44 with value: 0.6706475033338272.\n",
      "[I 2024-09-22 01:42:03,084] Trial 66 finished with value: 0.670262261075715 and parameters: {'n_estimators': 304, 'max_depth': 36, 'min_samples_split': 21, 'min_samples_leaf': 29, 'max_features': 'sqrt'}. Best is trial 44 with value: 0.6706475033338272.\n",
      "[I 2024-09-22 01:42:39,198] Trial 67 finished with value: 0.6647503333827234 and parameters: {'n_estimators': 230, 'max_depth': 36, 'min_samples_split': 21, 'min_samples_leaf': 26, 'max_features': None}. Best is trial 44 with value: 0.6706475033338272.\n",
      "[I 2024-09-22 01:42:47,982] Trial 68 finished with value: 0.669521410579345 and parameters: {'n_estimators': 314, 'max_depth': 43, 'min_samples_split': 22, 'min_samples_leaf': 28, 'max_features': 'sqrt'}. Best is trial 44 with value: 0.6706475033338272.\n",
      "[I 2024-09-22 01:42:58,754] Trial 69 finished with value: 0.6693732404800711 and parameters: {'n_estimators': 392, 'max_depth': 41, 'min_samples_split': 16, 'min_samples_leaf': 24, 'max_features': 'sqrt'}. Best is trial 44 with value: 0.6706475033338272.\n",
      "[I 2024-09-22 01:43:11,225] Trial 70 finished with value: 0.6686323899837013 and parameters: {'n_estimators': 442, 'max_depth': 35, 'min_samples_split': 20, 'min_samples_leaf': 30, 'max_features': 'sqrt'}. Best is trial 44 with value: 0.6706475033338272.\n",
      "[I 2024-09-22 01:43:15,323] Trial 71 finished with value: 0.668691658023411 and parameters: {'n_estimators': 131, 'max_depth': 38, 'min_samples_split': 18, 'min_samples_leaf': 29, 'max_features': 'sqrt'}. Best is trial 44 with value: 0.6706475033338272.\n",
      "[I 2024-09-22 01:43:25,690] Trial 72 finished with value: 0.6693139724403616 and parameters: {'n_estimators': 354, 'max_depth': 46, 'min_samples_split': 20, 'min_samples_leaf': 28, 'max_features': 'sqrt'}. Best is trial 44 with value: 0.6706475033338272.\n",
      "[I 2024-09-22 01:43:33,989] Trial 73 finished with value: 0.6689287301822493 and parameters: {'n_estimators': 314, 'max_depth': 31, 'min_samples_split': 17, 'min_samples_leaf': 27, 'max_features': 'sqrt'}. Best is trial 44 with value: 0.6706475033338272.\n",
      "[I 2024-09-22 01:43:44,848] Trial 74 finished with value: 0.6684842198844273 and parameters: {'n_estimators': 401, 'max_depth': 43, 'min_samples_split': 19, 'min_samples_leaf': 32, 'max_features': 'sqrt'}. Best is trial 44 with value: 0.6706475033338272.\n",
      "[I 2024-09-22 01:43:56,973] Trial 75 finished with value: 0.6706771373536821 and parameters: {'n_estimators': 439, 'max_depth': 41, 'min_samples_split': 23, 'min_samples_leaf': 29, 'max_features': 'sqrt'}. Best is trial 75 with value: 0.6706771373536821.\n",
      "[I 2024-09-22 01:44:09,407] Trial 76 finished with value: 0.6694917765594903 and parameters: {'n_estimators': 441, 'max_depth': 49, 'min_samples_split': 23, 'min_samples_leaf': 26, 'max_features': 'sqrt'}. Best is trial 75 with value: 0.6706771373536821.\n",
      "[I 2024-09-22 01:44:17,660] Trial 77 finished with value: 0.668543487924137 and parameters: {'n_estimators': 294, 'max_depth': 46, 'min_samples_split': 27, 'min_samples_leaf': 31, 'max_features': 'sqrt'}. Best is trial 75 with value: 0.6706771373536821.\n",
      "[I 2024-09-22 01:45:32,895] Trial 78 finished with value: 0.6648688694621425 and parameters: {'n_estimators': 481, 'max_depth': 44, 'min_samples_split': 22, 'min_samples_leaf': 25, 'max_features': None}. Best is trial 75 with value: 0.6706771373536821.\n",
      "[I 2024-09-22 01:45:43,288] Trial 79 finished with value: 0.6687212920432657 and parameters: {'n_estimators': 372, 'max_depth': 42, 'min_samples_split': 23, 'min_samples_leaf': 30, 'max_features': 'sqrt'}. Best is trial 75 with value: 0.6706771373536821.\n",
      "[I 2024-09-22 01:46:00,546] Trial 80 finished with value: 0.6664987405541561 and parameters: {'n_estimators': 421, 'max_depth': 47, 'min_samples_split': 14, 'min_samples_leaf': 8, 'max_features': 'sqrt'}. Best is trial 75 with value: 0.6706771373536821.\n",
      "[I 2024-09-22 01:46:15,317] Trial 81 finished with value: 0.6698177507778931 and parameters: {'n_estimators': 517, 'max_depth': 40, 'min_samples_split': 21, 'min_samples_leaf': 29, 'max_features': 'sqrt'}. Best is trial 75 with value: 0.6706771373536821.\n",
      "[I 2024-09-22 01:46:31,819] Trial 82 finished with value: 0.6685434879241369 and parameters: {'n_estimators': 551, 'max_depth': 39, 'min_samples_split': 18, 'min_samples_leaf': 28, 'max_features': 'sqrt'}. Best is trial 75 with value: 0.6706771373536821.\n",
      "[I 2024-09-22 01:46:44,864] Trial 83 finished with value: 0.6702918950955696 and parameters: {'n_estimators': 480, 'max_depth': 37, 'min_samples_split': 24, 'min_samples_leaf': 29, 'max_features': 'sqrt'}. Best is trial 75 with value: 0.6706771373536821.\n",
      "[I 2024-09-22 01:46:56,626] Trial 84 finished with value: 0.6691065343013779 and parameters: {'n_estimators': 449, 'max_depth': 37, 'min_samples_split': 24, 'min_samples_leaf': 27, 'max_features': 'sqrt'}. Best is trial 75 with value: 0.6706771373536821.\n",
      "[I 2024-09-22 01:47:09,092] Trial 85 finished with value: 0.6685138539042821 and parameters: {'n_estimators': 482, 'max_depth': 35, 'min_samples_split': 24, 'min_samples_leaf': 30, 'max_features': 'sqrt'}. Best is trial 75 with value: 0.6706771373536821.\n",
      "[I 2024-09-22 01:47:20,451] Trial 86 finished with value: 0.6686027559638466 and parameters: {'n_estimators': 426, 'max_depth': 41, 'min_samples_split': 27, 'min_samples_leaf': 28, 'max_features': 'sqrt'}. Best is trial 75 with value: 0.6706771373536821.\n",
      "[I 2024-09-22 01:47:30,335] Trial 87 finished with value: 0.6681286116461698 and parameters: {'n_estimators': 350, 'max_depth': 28, 'min_samples_split': 16, 'min_samples_leaf': 31, 'max_features': 'sqrt'}. Best is trial 75 with value: 0.6706771373536821.\n",
      "[I 2024-09-22 01:47:44,212] Trial 88 finished with value: 0.6689879982219589 and parameters: {'n_estimators': 464, 'max_depth': 44, 'min_samples_split': 22, 'min_samples_leaf': 32, 'max_features': 'sqrt'}. Best is trial 75 with value: 0.6706771373536821.\n",
      "[I 2024-09-22 01:47:51,251] Trial 89 finished with value: 0.6699362868573122 and parameters: {'n_estimators': 239, 'max_depth': 48, 'min_samples_split': 25, 'min_samples_leaf': 29, 'max_features': 'sqrt'}. Best is trial 75 with value: 0.6706771373536821.\n",
      "[I 2024-09-22 01:48:08,544] Trial 90 finished with value: 0.6697584827381835 and parameters: {'n_estimators': 586, 'max_depth': 45, 'min_samples_split': 20, 'min_samples_leaf': 26, 'max_features': 'sqrt'}. Best is trial 75 with value: 0.6706771373536821.\n",
      "[I 2024-09-22 01:48:22,427] Trial 91 finished with value: 0.6702622610757148 and parameters: {'n_estimators': 497, 'max_depth': 39, 'min_samples_split': 19, 'min_samples_leaf': 29, 'max_features': 'sqrt'}. Best is trial 75 with value: 0.6706771373536821.\n",
      "[I 2024-09-22 01:48:37,517] Trial 92 finished with value: 0.6686027559638466 and parameters: {'n_estimators': 537, 'max_depth': 37, 'min_samples_split': 17, 'min_samples_leaf': 28, 'max_features': 'sqrt'}. Best is trial 75 with value: 0.6706771373536821.\n",
      "[I 2024-09-22 01:48:51,450] Trial 93 finished with value: 0.6686620240035561 and parameters: {'n_estimators': 491, 'max_depth': 42, 'min_samples_split': 20, 'min_samples_leaf': 30, 'max_features': 'sqrt'}. Best is trial 75 with value: 0.6706771373536821.\n",
      "[I 2024-09-22 01:49:02,018] Trial 94 finished with value: 0.6702326270558602 and parameters: {'n_estimators': 376, 'max_depth': 40, 'min_samples_split': 23, 'min_samples_leaf': 29, 'max_features': 'sqrt'}. Best is trial 75 with value: 0.6706771373536821.\n",
      "[I 2024-09-22 01:49:11,583] Trial 95 finished with value: 0.667950807527041 and parameters: {'n_estimators': 394, 'max_depth': 21, 'min_samples_split': 10, 'min_samples_leaf': 27, 'max_features': 'log2'}. Best is trial 75 with value: 0.6706771373536821.\n",
      "[I 2024-09-22 01:49:23,192] Trial 96 finished with value: 0.6693436064602163 and parameters: {'n_estimators': 414, 'max_depth': 38, 'min_samples_split': 21, 'min_samples_leaf': 31, 'max_features': 'sqrt'}. Best is trial 75 with value: 0.6706771373536821.\n",
      "[I 2024-09-22 01:49:36,773] Trial 97 finished with value: 0.6684545858645725 and parameters: {'n_estimators': 470, 'max_depth': 46, 'min_samples_split': 12, 'min_samples_leaf': 30, 'max_features': 'sqrt'}. Best is trial 75 with value: 0.6706771373536821.\n",
      "[I 2024-09-22 01:51:04,712] Trial 98 finished with value: 0.6654022818195289 and parameters: {'n_estimators': 556, 'max_depth': 41, 'min_samples_split': 18, 'min_samples_leaf': 25, 'max_features': None}. Best is trial 75 with value: 0.6706771373536821.\n",
      "[I 2024-09-22 01:51:14,681] Trial 99 finished with value: 0.668365683805008 and parameters: {'n_estimators': 328, 'max_depth': 43, 'min_samples_split': 16, 'min_samples_leaf': 27, 'max_features': 'sqrt'}. Best is trial 75 with value: 0.6706771373536821.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest Optuna Tuned\n",
      "Best params: {'n_estimators': 439, 'max_depth': 41, 'min_samples_split': 23, 'min_samples_leaf': 29, 'max_features': 'sqrt'}\n",
      "Best score: 0.6706771373536821\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Tuning\n",
    "def tune_rf(X_train, y_train, tscv, scoring, random_state, n_iter=100):\n",
    "    \n",
    "    def rf_objective(trial):\n",
    "        rf_params = {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 1000),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 5, 50),\n",
    "            \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 32),\n",
    "            \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 32),\n",
    "            \"max_features\": trial.suggest_categorical(\"max_features\", [\"sqrt\", \"log2\", None]),\n",
    "        }\n",
    "\n",
    "        rf = RandomForestClassifier(random_state=random_state, n_jobs=-1, bootstrap=True, **rf_params)\n",
    "        scores = cross_val_score(rf, X_train, y_train, cv=tscv, scoring=scoring)\n",
    "        return scores.mean()\n",
    "    \n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(rf_objective, n_trials=n_iter)\n",
    "    return study.best_params, study.best_value\n",
    "\n",
    "\n",
    "# Tune model\n",
    "rf_params_optuna, rf_score_optuna = tune_rf(X_train, y_train, tscv, \"accuracy\", RANDOM_SEED)\n",
    "\n",
    "# Display results\n",
    "print(\"\\nRandom Forest Optuna Tuned\")\n",
    "print(\"Best params:\", rf_params_optuna)\n",
    "print(\"Best score:\", rf_score_optuna)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Optuna Tuned\n",
      "accuracy: 0.6706771373536821\n",
      "precision: 0.6697207573064079\n",
      "recall: 0.6743712661090254\n",
      "f1: 0.6718755463153838\n",
      "roc_auc: 0.7388560714834573\n"
     ]
    }
   ],
   "source": [
    "rf_tuned_optuna = RandomForestClassifier(random_state=RANDOM_SEED, n_jobs=-1, **rf_params_optuna)\n",
    "\n",
    "print(\"Random Forest Optuna Tuned\")\n",
    "evaluate_model(rf_tuned_optuna, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained and saved\n"
     ]
    }
   ],
   "source": [
    "# Save model\n",
    "rf_tuned_optuna.fit(X_train, y_train)\n",
    "joblib.dump(rf_tuned_optuna, \"models/rf_optuna_v2.pkl\")\n",
    "print(\"Model trained and saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-22 01:51:28,265] A new study created in memory with name: no-name-ccb5db23-1f76-431c-94c1-7ab1531682d9\n",
      "[I 2024-09-22 01:51:38,452] Trial 0 finished with value: 0.6589124314713292 and parameters: {'n_estimators': 181, 'learning_rate': 0.0025269173189151947, 'max_depth': 9, 'subsample': 0.8172076896954834, 'colsample_bytree': 0.9165033704318796, 'gamma': 2.3283971753848127, 'reg_alpha': 0.0005270653200605051, 'reg_lambda': 7.951326833969146e-05}. Best is trial 0 with value: 0.6589124314713292.\n",
      "[I 2024-09-22 01:51:47,481] Trial 1 finished with value: 0.6679804415468957 and parameters: {'n_estimators': 920, 'learning_rate': 0.007476610487055094, 'max_depth': 6, 'subsample': 0.9114002113464024, 'colsample_bytree': 0.8405211650749881, 'gamma': 3.048068938978585, 'reg_alpha': 8.638091353493817, 'reg_lambda': 0.0007502825765550572}. Best is trial 1 with value: 0.6679804415468957.\n",
      "[I 2024-09-22 01:51:53,627] Trial 2 finished with value: 0.6517409986664692 and parameters: {'n_estimators': 696, 'learning_rate': 0.06903290744521012, 'max_depth': 14, 'subsample': 0.7298010410920426, 'colsample_bytree': 0.5179590715054567, 'gamma': 3.4609813207591844, 'reg_alpha': 0.0024126095302397592, 'reg_lambda': 3.4212011759818465e-05}. Best is trial 1 with value: 0.6679804415468957.\n",
      "[I 2024-09-22 01:52:00,467] Trial 3 finished with value: 0.6624388798340496 and parameters: {'n_estimators': 881, 'learning_rate': 0.029428693506968834, 'max_depth': 8, 'subsample': 0.6602642553747602, 'colsample_bytree': 0.7905129044605881, 'gamma': 4.320101796718733, 'reg_alpha': 0.8437008722272722, 'reg_lambda': 0.16310698568135593}. Best is trial 1 with value: 0.6679804415468957.\n",
      "[I 2024-09-22 01:52:16,046] Trial 4 finished with value: 0.660631204622907 and parameters: {'n_estimators': 828, 'learning_rate': 0.00859684887194595, 'max_depth': 8, 'subsample': 0.5692375660868745, 'colsample_bytree': 0.6047570969714522, 'gamma': 2.986647861360278, 'reg_alpha': 0.0006537397751993015, 'reg_lambda': 0.06377883113783886}. Best is trial 1 with value: 0.6679804415468957.\n",
      "[I 2024-09-22 01:52:22,650] Trial 5 finished with value: 0.6519484368054527 and parameters: {'n_estimators': 777, 'learning_rate': 0.07839042857248747, 'max_depth': 12, 'subsample': 0.7139125479224322, 'colsample_bytree': 0.8120096601992197, 'gamma': 2.812722690122586, 'reg_alpha': 0.001054620337713556, 'reg_lambda': 0.11715188985137409}. Best is trial 1 with value: 0.6679804415468957.\n",
      "[I 2024-09-22 01:52:25,460] Trial 6 finished with value: 0.6653430137798193 and parameters: {'n_estimators': 624, 'learning_rate': 0.08365767982182963, 'max_depth': 11, 'subsample': 0.8599873851854827, 'colsample_bytree': 0.43091251461189317, 'gamma': 3.5952047725869103, 'reg_alpha': 5.406583923459763, 'reg_lambda': 0.10263548820377574}. Best is trial 1 with value: 0.6679804415468957.\n",
      "[I 2024-09-22 01:54:47,771] Trial 7 finished with value: 0.658497555193362 and parameters: {'n_estimators': 819, 'learning_rate': 0.0010280416864495766, 'max_depth': 15, 'subsample': 0.846160156520237, 'colsample_bytree': 0.9380763851212021, 'gamma': 1.704472376790351, 'reg_alpha': 0.000837250228955345, 'reg_lambda': 2.014574503638159}. Best is trial 1 with value: 0.6679804415468957.\n",
      "[I 2024-09-22 01:55:08,330] Trial 8 finished with value: 0.656926952141058 and parameters: {'n_estimators': 780, 'learning_rate': 0.023058300808627766, 'max_depth': 14, 'subsample': 0.9361304953379178, 'colsample_bytree': 0.7534752911589644, 'gamma': 1.7865844718944883, 'reg_alpha': 0.2594422580041545, 'reg_lambda': 0.0008656540863072965}. Best is trial 1 with value: 0.6679804415468957.\n",
      "[I 2024-09-22 01:55:15,197] Trial 9 finished with value: 0.6657875240776411 and parameters: {'n_estimators': 557, 'learning_rate': 0.0030937951630883487, 'max_depth': 6, 'subsample': 0.5130632613464076, 'colsample_bytree': 0.7448583945253966, 'gamma': 3.6332096094434814, 'reg_alpha': 6.135772168166997e-05, 'reg_lambda': 0.00010420954581444879}. Best is trial 1 with value: 0.6679804415468957.\n",
      "[I 2024-09-22 01:57:20,699] Trial 10 finished with value: 0.6532523336790635 and parameters: {'n_estimators': 330, 'learning_rate': 0.008547180226907569, 'max_depth': 20, 'subsample': 0.9796566576563304, 'colsample_bytree': 0.6367019390621352, 'gamma': 0.10221415247685162, 'reg_alpha': 0.058723777547862496, 'reg_lambda': 0.0018633045408692293}. Best is trial 1 with value: 0.6679804415468957.\n",
      "[I 2024-09-22 01:57:23,475] Trial 11 finished with value: 0.6632093643502742 and parameters: {'n_estimators': 462, 'learning_rate': 0.003640511373024279, 'max_depth': 3, 'subsample': 0.6186564305890981, 'colsample_bytree': 0.8547772484669384, 'gamma': 4.893252290523095, 'reg_alpha': 1.4477966929128503e-05, 'reg_lambda': 0.0002458380704570675}. Best is trial 1 with value: 0.6679804415468957.\n",
      "[I 2024-09-22 01:57:28,920] Trial 12 finished with value: 0.6648688694621425 and parameters: {'n_estimators': 994, 'learning_rate': 0.0035650761417260705, 'max_depth': 3, 'subsample': 0.5343418544587792, 'colsample_bytree': 0.6690347942347095, 'gamma': 3.8471942793870877, 'reg_alpha': 1.2292025871173949e-05, 'reg_lambda': 0.0025146484943500058}. Best is trial 1 with value: 0.6679804415468957.\n",
      "[I 2024-09-22 01:57:34,229] Trial 13 finished with value: 0.658645725292636 and parameters: {'n_estimators': 482, 'learning_rate': 0.0013831242434945862, 'max_depth': 5, 'subsample': 0.9008581403872357, 'colsample_bytree': 0.9838962812548251, 'gamma': 1.3000246845157746, 'reg_alpha': 0.017059871154860212, 'reg_lambda': 1.08781206540886e-05}. Best is trial 1 with value: 0.6679804415468957.\n",
      "[I 2024-09-22 01:57:35,883] Trial 14 finished with value: 0.6664098384945918 and parameters: {'n_estimators': 130, 'learning_rate': 0.015474024009698866, 'max_depth': 6, 'subsample': 0.8074996231609676, 'colsample_bytree': 0.7334626515117557, 'gamma': 4.2360771820243235, 'reg_alpha': 9.475117856726015, 'reg_lambda': 0.00031500007916709856}. Best is trial 1 with value: 0.6679804415468957.\n",
      "[I 2024-09-22 01:57:37,407] Trial 15 finished with value: 0.6657282560379315 and parameters: {'n_estimators': 122, 'learning_rate': 0.01842677209841196, 'max_depth': 6, 'subsample': 0.7812952420554374, 'colsample_bytree': 0.8780989045391352, 'gamma': 4.953184841228637, 'reg_alpha': 9.430109069445802, 'reg_lambda': 0.010388940021282584}. Best is trial 1 with value: 0.6679804415468957.\n",
      "[I 2024-09-22 01:57:44,195] Trial 16 finished with value: 0.6632982664098386 and parameters: {'n_estimators': 315, 'learning_rate': 0.013190194074008064, 'max_depth': 10, 'subsample': 0.9944523625408747, 'colsample_bytree': 0.7069447358469052, 'gamma': 4.1740147258298705, 'reg_alpha': 1.3414700185450201, 'reg_lambda': 0.0003689120161176682}. Best is trial 1 with value: 0.6679804415468957.\n",
      "[I 2024-09-22 01:57:52,308] Trial 17 finished with value: 0.6639205808267892 and parameters: {'n_estimators': 987, 'learning_rate': 0.006104360764488693, 'max_depth': 5, 'subsample': 0.9072473559012719, 'colsample_bytree': 0.585748747540241, 'gamma': 2.3679071910709872, 'reg_alpha': 0.17059538752991035, 'reg_lambda': 0.008404499714235633}. Best is trial 1 with value: 0.6679804415468957.\n",
      "[I 2024-09-22 01:57:57,581] Trial 18 finished with value: 0.6629130241517263 and parameters: {'n_estimators': 291, 'learning_rate': 0.04267616006851543, 'max_depth': 18, 'subsample': 0.7948134934281006, 'colsample_bytree': 0.7967241219809595, 'gamma': 3.165584158750625, 'reg_alpha': 2.053985877721402, 'reg_lambda': 1.0138425396379284e-05}. Best is trial 1 with value: 0.6679804415468957.\n",
      "[I 2024-09-22 01:58:02,544] Trial 19 finished with value: 0.6664691065343014 and parameters: {'n_estimators': 412, 'learning_rate': 0.01370080522778942, 'max_depth': 7, 'subsample': 0.8638979487672482, 'colsample_bytree': 0.5121764110197398, 'gamma': 4.317881141842028, 'reg_alpha': 0.3576673635713402, 'reg_lambda': 0.009756648337571968}. Best is trial 1 with value: 0.6679804415468957.\n",
      "[I 2024-09-22 01:58:08,424] Trial 20 finished with value: 0.6684249518447178 and parameters: {'n_estimators': 477, 'learning_rate': 0.005737865051907942, 'max_depth': 8, 'subsample': 0.9509311532693815, 'colsample_bytree': 0.4070476982574669, 'gamma': 4.526564590042664, 'reg_alpha': 0.4367641200764983, 'reg_lambda': 9.418406991027338}. Best is trial 20 with value: 0.6684249518447178.\n",
      "[I 2024-09-22 01:58:13,983] Trial 21 finished with value: 0.6678322714476219 and parameters: {'n_estimators': 412, 'learning_rate': 0.005884904346203142, 'max_depth': 8, 'subsample': 0.9355087424628091, 'colsample_bytree': 0.4130053976997911, 'gamma': 4.5201065832911755, 'reg_alpha': 0.2475066839038644, 'reg_lambda': 5.851991012157979}. Best is trial 20 with value: 0.6684249518447178.\n",
      "[I 2024-09-22 01:58:22,355] Trial 22 finished with value: 0.668395317824863 and parameters: {'n_estimators': 583, 'learning_rate': 0.005759170574980082, 'max_depth': 10, 'subsample': 0.934000416860003, 'colsample_bytree': 0.4097939662854915, 'gamma': 4.509101278695482, 'reg_alpha': 0.04456819255411341, 'reg_lambda': 9.93274929844108}. Best is trial 20 with value: 0.6684249518447178.\n",
      "[I 2024-09-22 01:59:33,545] Trial 23 finished with value: 0.6610757149207289 and parameters: {'n_estimators': 596, 'learning_rate': 0.005712968432300446, 'max_depth': 12, 'subsample': 0.956735341967654, 'colsample_bytree': 0.4779076582551961, 'gamma': 0.49815502076277207, 'reg_alpha': 0.034651865933705894, 'reg_lambda': 0.9402049289203119}. Best is trial 20 with value: 0.6684249518447178.\n",
      "[I 2024-09-22 01:59:47,881] Trial 24 finished with value: 0.6676841013483479 and parameters: {'n_estimators': 679, 'learning_rate': 0.004850896716921601, 'max_depth': 10, 'subsample': 0.9074249354370162, 'colsample_bytree': 0.4637443603801416, 'gamma': 4.723265597344909, 'reg_alpha': 0.08029409018116385, 'reg_lambda': 3.1625855422452576}. Best is trial 20 with value: 0.6684249518447178.\n",
      "[I 2024-09-22 01:59:52,640] Trial 25 finished with value: 0.6647799674025783 and parameters: {'n_estimators': 523, 'learning_rate': 0.002077883499569373, 'max_depth': 4, 'subsample': 0.8828041522829554, 'colsample_bytree': 0.5379640480052101, 'gamma': 3.886960543112674, 'reg_alpha': 0.01250854118928803, 'reg_lambda': 0.4705540870070799}. Best is trial 20 with value: 0.6684249518447178.\n",
      "[I 2024-09-22 02:00:11,299] Trial 26 finished with value: 0.6646910653430138 and parameters: {'n_estimators': 906, 'learning_rate': 0.009974904062485121, 'max_depth': 10, 'subsample': 0.9945667557853273, 'colsample_bytree': 0.41108966277733794, 'gamma': 3.1738522497816386, 'reg_alpha': 0.004856671046073022, 'reg_lambda': 4.708888563566149}. Best is trial 20 with value: 0.6684249518447178.\n",
      "[I 2024-09-22 02:00:32,397] Trial 27 finished with value: 0.664661431323159 and parameters: {'n_estimators': 691, 'learning_rate': 0.008138609984890589, 'max_depth': 13, 'subsample': 0.943221051819627, 'colsample_bytree': 0.5650919761698586, 'gamma': 2.6335990897729307, 'reg_alpha': 2.9857376338191024, 'reg_lambda': 0.5184127399496294}. Best is trial 20 with value: 0.6684249518447178.\n",
      "[I 2024-09-22 02:00:50,364] Trial 28 finished with value: 0.664809601422433 and parameters: {'n_estimators': 242, 'learning_rate': 0.00211544114225699, 'max_depth': 16, 'subsample': 0.8304368413074086, 'colsample_bytree': 0.47836295805804485, 'gamma': 3.915743449917957, 'reg_alpha': 0.558650432316363, 'reg_lambda': 0.03581676059469014}. Best is trial 20 with value: 0.6684249518447178.\n",
      "[I 2024-09-22 02:01:03,428] Trial 29 finished with value: 0.6677730034079123 and parameters: {'n_estimators': 395, 'learning_rate': 0.004783228792384339, 'max_depth': 9, 'subsample': 0.7623899556341117, 'colsample_bytree': 0.6497300043679518, 'gamma': 2.043461558195096, 'reg_alpha': 0.00015466323350395256, 'reg_lambda': 9.60366335781802}. Best is trial 20 with value: 0.6684249518447178.\n",
      "[I 2024-09-22 02:01:29,524] Trial 30 finished with value: 0.6613127870795673 and parameters: {'n_estimators': 516, 'learning_rate': 0.0016177022987855696, 'max_depth': 9, 'subsample': 0.9694364823422779, 'colsample_bytree': 0.9178602437973394, 'gamma': 1.1362227175205633, 'reg_alpha': 2.376649220095608, 'reg_lambda': 1.7859775021408237}. Best is trial 20 with value: 0.6684249518447178.\n",
      "[I 2024-09-22 02:01:35,507] Trial 31 finished with value: 0.6678619054674766 and parameters: {'n_estimators': 390, 'learning_rate': 0.00676036538280574, 'max_depth': 8, 'subsample': 0.9345977968159106, 'colsample_bytree': 0.4043570531643209, 'gamma': 4.5418704263513465, 'reg_alpha': 0.10030177228796563, 'reg_lambda': 7.8133459447368}. Best is trial 20 with value: 0.6684249518447178.\n",
      "[I 2024-09-22 02:01:41,440] Trial 32 finished with value: 0.6685731219439918 and parameters: {'n_estimators': 365, 'learning_rate': 0.00726510441802491, 'max_depth': 7, 'subsample': 0.9266614267365465, 'colsample_bytree': 0.4468033590896723, 'gamma': 4.696077672386675, 'reg_alpha': 0.11320403893735745, 'reg_lambda': 7.522362853421573}. Best is trial 32 with value: 0.6685731219439918.\n",
      "[I 2024-09-22 02:01:46,434] Trial 33 finished with value: 0.6656986220180767 and parameters: {'n_estimators': 198, 'learning_rate': 0.0040845686979577595, 'max_depth': 7, 'subsample': 0.8992673253388114, 'colsample_bytree': 0.45757627819215674, 'gamma': 4.5934895562948945, 'reg_alpha': 0.03406707854978552, 'reg_lambda': 1.0019019356449679}. Best is trial 32 with value: 0.6685731219439918.\n",
      "[I 2024-09-22 02:01:56,309] Trial 34 finished with value: 0.6634464365091124 and parameters: {'n_estimators': 650, 'learning_rate': 0.011983990793244968, 'max_depth': 7, 'subsample': 0.8717316593500244, 'colsample_bytree': 0.5157408023163399, 'gamma': 3.3148436551819054, 'reg_alpha': 0.6584816926283393, 'reg_lambda': 0.34144680069833816}. Best is trial 32 with value: 0.6685731219439918.\n",
      "[I 2024-09-22 02:02:13,660] Trial 35 finished with value: 0.6672692250703808 and parameters: {'n_estimators': 583, 'learning_rate': 0.0028625389098294375, 'max_depth': 11, 'subsample': 0.6910157147660476, 'colsample_bytree': 0.4974934818837231, 'gamma': 4.083190318056254, 'reg_alpha': 0.004799744411876687, 'reg_lambda': 2.753365818164451}. Best is trial 32 with value: 0.6685731219439918.\n",
      "[I 2024-09-22 02:02:20,702] Trial 36 finished with value: 0.6679804415468958 and parameters: {'n_estimators': 907, 'learning_rate': 0.007621982770047216, 'max_depth': 5, 'subsample': 0.8326370992142788, 'colsample_bytree': 0.4412884197119843, 'gamma': 4.952955100859162, 'reg_alpha': 1.0562634819270171, 'reg_lambda': 0.025980161374150938}. Best is trial 32 with value: 0.6685731219439918.\n",
      "[I 2024-09-22 02:02:24,706] Trial 37 finished with value: 0.6683656838050082 and parameters: {'n_estimators': 451, 'learning_rate': 0.009555303513130987, 'max_depth': 5, 'subsample': 0.8323177630088671, 'colsample_bytree': 0.4483950978285808, 'gamma': 4.981978350942924, 'reg_alpha': 0.026300278945322348, 'reg_lambda': 1.1879621430725091}. Best is trial 32 with value: 0.6685731219439918.\n",
      "[I 2024-09-22 02:02:28,373] Trial 38 finished with value: 0.6678026374277671 and parameters: {'n_estimators': 467, 'learning_rate': 0.010109604828510293, 'max_depth': 4, 'subsample': 0.7508517303855563, 'colsample_bytree': 0.5568778726915258, 'gamma': 4.683278068442697, 'reg_alpha': 0.02836636093261488, 'reg_lambda': 1.1783241631024504}. Best is trial 32 with value: 0.6685731219439918.\n",
      "[I 2024-09-22 02:02:32,203] Trial 39 finished with value: 0.6641280189657726 and parameters: {'n_estimators': 379, 'learning_rate': 0.03300999793705622, 'max_depth': 8, 'subsample': 0.9569357220589882, 'colsample_bytree': 0.44596473310299806, 'gamma': 4.43562163746542, 'reg_alpha': 0.00488892788282893, 'reg_lambda': 0.20746276124428834}. Best is trial 32 with value: 0.6685731219439918.\n",
      "[I 2024-09-22 02:02:41,828] Trial 40 finished with value: 0.6642761890650467 and parameters: {'n_estimators': 731, 'learning_rate': 0.011140595521659538, 'max_depth': 9, 'subsample': 0.9227226165465489, 'colsample_bytree': 0.4003287242441786, 'gamma': 3.5864520590642743, 'reg_alpha': 0.14018512627306381, 'reg_lambda': 4.560875169405255}. Best is trial 32 with value: 0.6685731219439918.\n",
      "[I 2024-09-22 02:02:45,917] Trial 41 finished with value: 0.6680100755667506 and parameters: {'n_estimators': 447, 'learning_rate': 0.0048220290530603055, 'max_depth': 5, 'subsample': 0.8253661139826175, 'colsample_bytree': 0.44475500421773895, 'gamma': 4.962588474458738, 'reg_alpha': 0.06019872893269713, 'reg_lambda': 9.750627518191056}. Best is trial 32 with value: 0.6685731219439918.\n",
      "[I 2024-09-22 02:02:49,259] Trial 42 finished with value: 0.6666172766335754 and parameters: {'n_estimators': 443, 'learning_rate': 0.004095509574090377, 'max_depth': 4, 'subsample': 0.8453184101157486, 'colsample_bytree': 0.43770042681310334, 'gamma': 4.981544829580901, 'reg_alpha': 0.0017005445209316644, 'reg_lambda': 7.882717929772815}. Best is trial 32 with value: 0.6685731219439918.\n",
      "[I 2024-09-22 02:02:56,930] Trial 43 finished with value: 0.6668247147725589 and parameters: {'n_estimators': 519, 'learning_rate': 0.004991913828649739, 'max_depth': 7, 'subsample': 0.8836530756228748, 'colsample_bytree': 0.49282597055704147, 'gamma': 4.681630187516371, 'reg_alpha': 0.05130111368354746, 'reg_lambda': 1.5621085145926572}. Best is trial 32 with value: 0.6685731219439918.\n",
      "[I 2024-09-22 02:03:00,036] Trial 44 finished with value: 0.6678915394873314 and parameters: {'n_estimators': 259, 'learning_rate': 0.007044222495705825, 'max_depth': 6, 'subsample': 0.7183969114007853, 'colsample_bytree': 0.4304335840960695, 'gamma': 4.05124929706163, 'reg_alpha': 0.009209663175035793, 'reg_lambda': 2.949733428398385}. Best is trial 32 with value: 0.6685731219439918.\n",
      "[I 2024-09-22 02:03:03,060] Trial 45 finished with value: 0.6667061786931396 and parameters: {'n_estimators': 360, 'learning_rate': 0.018876655400625695, 'max_depth': 5, 'subsample': 0.8177501827065544, 'colsample_bytree': 0.5271510001611953, 'gamma': 4.387149792922719, 'reg_alpha': 0.020698455460514138, 'reg_lambda': 4.079482664436979}. Best is trial 32 with value: 0.6685731219439918.\n",
      "[I 2024-09-22 02:03:06,500] Trial 46 finished with value: 0.6671210549711069 and parameters: {'n_estimators': 559, 'learning_rate': 0.009432881240208196, 'max_depth': 3, 'subsample': 0.7773232639997845, 'colsample_bytree': 0.5981237288577166, 'gamma': 4.800731959834354, 'reg_alpha': 0.36149742150563446, 'reg_lambda': 9.47129247286767}. Best is trial 32 with value: 0.6685731219439918.\n",
      "[I 2024-09-22 02:03:14,432] Trial 47 finished with value: 0.6659653281967699 and parameters: {'n_estimators': 496, 'learning_rate': 0.0031361024153362563, 'max_depth': 7, 'subsample': 0.8563190051320261, 'colsample_bytree': 0.47210372001260303, 'gamma': 3.671151864443336, 'reg_alpha': 0.1157257885239817, 'reg_lambda': 0.740304062789551}. Best is trial 32 with value: 0.6685731219439918.\n",
      "[I 2024-09-22 02:03:25,037] Trial 48 finished with value: 0.6667950807527041 and parameters: {'n_estimators': 436, 'learning_rate': 0.0023398813105637226, 'max_depth': 9, 'subsample': 0.9772113836614634, 'colsample_bytree': 0.42515143856226956, 'gamma': 4.32131403460227, 'reg_alpha': 0.05319193969031332, 'reg_lambda': 2.239654972504247}. Best is trial 32 with value: 0.6685731219439918.\n",
      "[I 2024-09-22 02:03:36,030] Trial 49 finished with value: 0.6668839828122685 and parameters: {'n_estimators': 345, 'learning_rate': 0.004384665260026978, 'max_depth': 11, 'subsample': 0.6317359968738329, 'colsample_bytree': 0.5512391409680885, 'gamma': 4.789602967771689, 'reg_alpha': 0.008242182543755569, 'reg_lambda': 0.25704773883685483}. Best is trial 32 with value: 0.6685731219439918.\n",
      "[I 2024-09-22 02:03:41,531] Trial 50 finished with value: 0.6642465550451918 and parameters: {'n_estimators': 616, 'learning_rate': 0.017160444726667598, 'max_depth': 6, 'subsample': 0.8886149936155748, 'colsample_bytree': 0.4537640050579501, 'gamma': 2.8960898835014626, 'reg_alpha': 0.17133334980683657, 'reg_lambda': 4.742291231786022}. Best is trial 32 with value: 0.6685731219439918.\n",
      "[I 2024-09-22 02:03:48,179] Trial 51 finished with value: 0.6677730034079123 and parameters: {'n_estimators': 840, 'learning_rate': 0.007592108697635343, 'max_depth': 5, 'subsample': 0.8334773347020644, 'colsample_bytree': 0.43833571953915, 'gamma': 4.94093152572744, 'reg_alpha': 1.1838215632111275, 'reg_lambda': 0.04883729015445435}. Best is trial 32 with value: 0.6685731219439918.\n",
      "[I 2024-09-22 02:03:54,961] Trial 52 finished with value: 0.6688398281226848 and parameters: {'n_estimators': 751, 'learning_rate': 0.005680192012705636, 'max_depth': 5, 'subsample': 0.8151647423696865, 'colsample_bytree': 0.5030689262209809, 'gamma': 4.942987109325593, 'reg_alpha': 0.38708739097840483, 'reg_lambda': 0.024831092495378796}. Best is trial 52 with value: 0.6688398281226848.\n",
      "[I 2024-09-22 02:03:57,806] Trial 53 finished with value: 0.6663505704548822 and parameters: {'n_estimators': 302, 'learning_rate': 0.00577659524449814, 'max_depth': 4, 'subsample': 0.7861835100229321, 'colsample_bytree': 0.5014638270859084, 'gamma': 4.66857236323399, 'reg_alpha': 0.24983377960834355, 'reg_lambda': 1.8869398169025668}. Best is trial 52 with value: 0.6688398281226848.\n",
      "[I 2024-09-22 02:04:09,261] Trial 54 finished with value: 0.6673581271299451 and parameters: {'n_estimators': 795, 'learning_rate': 0.003559692990721034, 'max_depth': 6, 'subsample': 0.9217125541015082, 'colsample_bytree': 0.4841598069955054, 'gamma': 4.460443265657245, 'reg_alpha': 0.48142400351971204, 'reg_lambda': 0.08297991937708549}. Best is trial 52 with value: 0.6688398281226848.\n",
      "[I 2024-09-22 02:04:12,817] Trial 55 finished with value: 0.6664691065343014 and parameters: {'n_estimators': 556, 'learning_rate': 0.005364255136324806, 'max_depth': 3, 'subsample': 0.8054333323491009, 'colsample_bytree': 0.4242671706207727, 'gamma': 4.052051105861388, 'reg_alpha': 0.06840703582797411, 'reg_lambda': 0.003833178212950098}. Best is trial 52 with value: 0.6688398281226848.\n",
      "[I 2024-09-22 02:04:16,212] Trial 56 finished with value: 0.6656986220180767 and parameters: {'n_estimators': 732, 'learning_rate': 0.09997624284637849, 'max_depth': 8, 'subsample': 0.9593567493067876, 'colsample_bytree': 0.4008949327583546, 'gamma': 4.203294069300739, 'reg_alpha': 0.022627972738426275, 'reg_lambda': 5.816667108099164}. Best is trial 52 with value: 0.6688398281226848.\n",
      "[I 2024-09-22 02:04:20,665] Trial 57 finished with value: 0.6691065343013779 and parameters: {'n_estimators': 432, 'learning_rate': 0.009022517189272765, 'max_depth': 5, 'subsample': 0.7374489876020374, 'colsample_bytree': 0.46777893419149885, 'gamma': 4.989909751803841, 'reg_alpha': 0.192225431594183, 'reg_lambda': 2.972243601243543}. Best is trial 57 with value: 0.6691065343013779.\n",
      "[I 2024-09-22 02:04:25,533] Trial 58 finished with value: 0.667950807527041 and parameters: {'n_estimators': 657, 'learning_rate': 0.008844407873482417, 'max_depth': 4, 'subsample': 0.686858418706969, 'colsample_bytree': 0.46519588571106124, 'gamma': 4.574334657004132, 'reg_alpha': 0.19577018120097567, 'reg_lambda': 1.3198679956225317}. Best is trial 57 with value: 0.6691065343013779.\n",
      "[I 2024-09-22 02:04:38,764] Trial 59 finished with value: 0.6657282560379315 and parameters: {'n_estimators': 478, 'learning_rate': 0.0067374885286795375, 'max_depth': 10, 'subsample': 0.7703694191719245, 'colsample_bytree': 0.5361811925439638, 'gamma': 4.332194678512676, 'reg_alpha': 0.4777864888023563, 'reg_lambda': 4.104085723178909e-05}. Best is trial 57 with value: 0.6691065343013779.\n",
      "[I 2024-09-22 02:04:43,475] Trial 60 finished with value: 0.6664394725144467 and parameters: {'n_estimators': 730, 'learning_rate': 0.021886903447946998, 'max_depth': 7, 'subsample': 0.7307468367013974, 'colsample_bytree': 0.6145303369989763, 'gamma': 4.725055458532377, 'reg_alpha': 4.113072604618906, 'reg_lambda': 0.699662794330229}. Best is trial 57 with value: 0.6691065343013779.\n",
      "[I 2024-09-22 02:04:47,261] Trial 61 finished with value: 0.6675062972292192 and parameters: {'n_estimators': 458, 'learning_rate': 0.01366002532543066, 'max_depth': 5, 'subsample': 0.8047916685834099, 'colsample_bytree': 0.4623158440574849, 'gamma': 4.829110434787023, 'reg_alpha': 0.046949930356171544, 'reg_lambda': 9.740045428977128}. Best is trial 57 with value: 0.6691065343013779.\n",
      "[I 2024-09-22 02:04:52,057] Trial 62 finished with value: 0.6690472662616684 and parameters: {'n_estimators': 442, 'learning_rate': 0.006159599124447579, 'max_depth': 6, 'subsample': 0.7361512728609332, 'colsample_bytree': 0.5085953873097966, 'gamma': 4.86869937279497, 'reg_alpha': 0.11192110321200922, 'reg_lambda': 3.9404686814521086}. Best is trial 57 with value: 0.6691065343013779.\n",
      "[I 2024-09-22 02:04:57,126] Trial 63 finished with value: 0.668098977626315 and parameters: {'n_estimators': 408, 'learning_rate': 0.011230942845002291, 'max_depth': 6, 'subsample': 0.7325259964837129, 'colsample_bytree': 0.5777571961399972, 'gamma': 4.528117835156051, 'reg_alpha': 0.11065476104084518, 'reg_lambda': 3.1243465251448543}. Best is trial 57 with value: 0.6691065343013779.\n",
      "[I 2024-09-22 02:05:03,583] Trial 64 finished with value: 0.6688398281226849 and parameters: {'n_estimators': 350, 'learning_rate': 0.006511990203083455, 'max_depth': 8, 'subsample': 0.6949710088065068, 'colsample_bytree': 0.4891792118342284, 'gamma': 4.993532029342089, 'reg_alpha': 0.30007852853014233, 'reg_lambda': 5.140964446361024}. Best is trial 57 with value: 0.6691065343013779.\n",
      "[I 2024-09-22 02:05:13,809] Trial 65 finished with value: 0.6669432508519781 and parameters: {'n_estimators': 360, 'learning_rate': 0.006355697759089864, 'max_depth': 8, 'subsample': 0.6629269586076533, 'colsample_bytree': 0.5099554852942958, 'gamma': 4.79820929409299, 'reg_alpha': 0.29861914798368705, 'reg_lambda': 0.13456881998716827}. Best is trial 57 with value: 0.6691065343013779.\n",
      "[I 2024-09-22 02:05:25,200] Trial 66 finished with value: 0.669521410579345 and parameters: {'n_estimators': 279, 'learning_rate': 0.00804210815880431, 'max_depth': 9, 'subsample': 0.7016342803624044, 'colsample_bytree': 0.4809894955932661, 'gamma': 3.862525199223897, 'reg_alpha': 0.7653156447707654, 'reg_lambda': 5.940053230183238}. Best is trial 66 with value: 0.669521410579345.\n",
      "[I 2024-09-22 02:05:34,232] Trial 67 finished with value: 0.66881019410283 and parameters: {'n_estimators': 254, 'learning_rate': 0.008571695709392748, 'max_depth': 9, 'subsample': 0.6954889389805052, 'colsample_bytree': 0.4901235736862044, 'gamma': 4.23073489582412, 'reg_alpha': 1.5047730984941465, 'reg_lambda': 5.568461909888423}. Best is trial 66 with value: 0.669521410579345.\n",
      "[I 2024-09-22 02:05:38,523] Trial 68 finished with value: 0.6685138539042821 and parameters: {'n_estimators': 171, 'learning_rate': 0.00831421789470067, 'max_depth': 9, 'subsample': 0.6898665932052609, 'colsample_bytree': 0.5357581124935042, 'gamma': 3.7608766074918654, 'reg_alpha': 6.30870528433221, 'reg_lambda': 0.000620484513273561}. Best is trial 66 with value: 0.669521410579345.\n",
      "[I 2024-09-22 02:05:45,174] Trial 69 finished with value: 0.666943250851978 and parameters: {'n_estimators': 264, 'learning_rate': 0.014383749718501378, 'max_depth': 12, 'subsample': 0.648465341881143, 'colsample_bytree': 0.49021444498541206, 'gamma': 4.15327132597006, 'reg_alpha': 1.506151633824646, 'reg_lambda': 0.01782580424235144}. Best is trial 66 with value: 0.669521410579345.\n",
      "[I 2024-09-22 02:05:52,490] Trial 70 finished with value: 0.6685434879241369 and parameters: {'n_estimators': 321, 'learning_rate': 0.011929823460975288, 'max_depth': 6, 'subsample': 0.6991835813198416, 'colsample_bytree': 0.6970900529980627, 'gamma': 4.241581494644682, 'reg_alpha': 0.6916564556659879, 'reg_lambda': 3.892253855520517}. Best is trial 66 with value: 0.669521410579345.\n",
      "[I 2024-09-22 02:05:56,587] Trial 71 finished with value: 0.6677730034079122 and parameters: {'n_estimators': 317, 'learning_rate': 0.01216745889053192, 'max_depth': 6, 'subsample': 0.7087201093409384, 'colsample_bytree': 0.7008232506962322, 'gamma': 3.413362487635271, 'reg_alpha': 0.9881521489804937, 'reg_lambda': 5.387749687751673}. Best is trial 66 with value: 0.669521410579345.\n",
      "[I 2024-09-22 02:06:01,540] Trial 72 finished with value: 0.6651948436805453 and parameters: {'n_estimators': 219, 'learning_rate': 0.007098344337570796, 'max_depth': 7, 'subsample': 0.6053417969912266, 'colsample_bytree': 0.9906146734703088, 'gamma': 3.9439760039036758, 'reg_alpha': 0.6510250431444654, 'reg_lambda': 3.5787860001594205}. Best is trial 66 with value: 0.669521410579345.\n",
      "[I 2024-09-22 02:06:06,497] Trial 73 finished with value: 0.6676248333086383 and parameters: {'n_estimators': 171, 'learning_rate': 0.008250807338682517, 'max_depth': 7, 'subsample': 0.6747620642547535, 'colsample_bytree': 0.7309926856301312, 'gamma': 4.2861084244816166, 'reg_alpha': 1.8639385295524091, 'reg_lambda': 5.410506011319645}. Best is trial 66 with value: 0.669521410579345.\n",
      "[I 2024-09-22 02:06:12,927] Trial 74 finished with value: 0.6681286116461698 and parameters: {'n_estimators': 336, 'learning_rate': 0.009884825547965055, 'max_depth': 6, 'subsample': 0.7068787172627293, 'colsample_bytree': 0.8237784445856158, 'gamma': 4.841751298966012, 'reg_alpha': 2.504826738742422, 'reg_lambda': 2.4634523143473706}. Best is trial 66 with value: 0.669521410579345.\n",
      "[I 2024-09-22 02:06:24,615] Trial 75 finished with value: 0.6651948436805453 and parameters: {'n_estimators': 290, 'learning_rate': 0.015716018016620027, 'max_depth': 20, 'subsample': 0.7555087593100996, 'colsample_bytree': 0.8676681179323834, 'gamma': 4.644295022439518, 'reg_alpha': 0.7425487502577314, 'reg_lambda': 1.7103987986267508}. Best is trial 66 with value: 0.669521410579345.\n",
      "[I 2024-09-22 02:06:34,113] Trial 76 finished with value: 0.6693732404800712 and parameters: {'n_estimators': 271, 'learning_rate': 0.006516233863403875, 'max_depth': 9, 'subsample': 0.7219524467633983, 'colsample_bytree': 0.6788185970089793, 'gamma': 4.436405460429599, 'reg_alpha': 0.20301047765465757, 'reg_lambda': 6.15343258676132}. Best is trial 66 with value: 0.669521410579345.\n",
      "[I 2024-09-22 02:06:41,531] Trial 77 finished with value: 0.6684249518447177 and parameters: {'n_estimators': 268, 'learning_rate': 0.006456085754682852, 'max_depth': 8, 'subsample': 0.73259954233204, 'colsample_bytree': 0.5088355588741832, 'gamma': 4.409687738703342, 'reg_alpha': 0.20426398044913163, 'reg_lambda': 6.573892920209179}. Best is trial 66 with value: 0.669521410579345.\n",
      "[I 2024-09-22 02:06:45,987] Trial 78 finished with value: 0.667091420951252 and parameters: {'n_estimators': 106, 'learning_rate': 0.005280679916440941, 'max_depth': 9, 'subsample': 0.739549259535374, 'colsample_bytree': 0.5233366815652957, 'gamma': 4.8234226693763125, 'reg_alpha': 0.3100153756631327, 'reg_lambda': 0.4513616284994883}. Best is trial 66 with value: 0.669521410579345.\n",
      "[I 2024-09-22 02:07:08,595] Trial 79 finished with value: 0.6659356941769151 and parameters: {'n_estimators': 425, 'learning_rate': 0.004393449157871976, 'max_depth': 10, 'subsample': 0.6626770164497469, 'colsample_bytree': 0.4791290126364471, 'gamma': 4.575461158152435, 'reg_alpha': 0.14126309737327897, 'reg_lambda': 0.00020388285541440273}. Best is trial 66 with value: 0.669521410579345.\n",
      "[I 2024-09-22 02:07:15,476] Trial 80 finished with value: 0.6686027559638466 and parameters: {'n_estimators': 211, 'learning_rate': 0.0037686360359297896, 'max_depth': 9, 'subsample': 0.7169235870021974, 'colsample_bytree': 0.5531884539954596, 'gamma': 4.998922999207341, 'reg_alpha': 0.3927008918774629, 'reg_lambda': 2.3176266993440784}. Best is trial 66 with value: 0.669521410579345.\n",
      "[I 2024-09-22 02:07:22,616] Trial 81 finished with value: 0.6678915394873315 and parameters: {'n_estimators': 225, 'learning_rate': 0.0038069338159146273, 'max_depth': 9, 'subsample': 0.716604904522522, 'colsample_bytree': 0.5548627725601349, 'gamma': 4.856325746373475, 'reg_alpha': 0.3964648317725434, 'reg_lambda': 2.6359408891163865}. Best is trial 66 with value: 0.669521410579345.\n",
      "[I 2024-09-22 02:07:29,843] Trial 82 finished with value: 0.6677137353682027 and parameters: {'n_estimators': 283, 'learning_rate': 0.003295862977094742, 'max_depth': 8, 'subsample': 0.7466563531293732, 'colsample_bytree': 0.573159764724315, 'gamma': 4.974286284200536, 'reg_alpha': 0.09377498101801555, 'reg_lambda': 6.565275524013169}. Best is trial 66 with value: 0.669521410579345.\n",
      "[I 2024-09-22 02:07:35,637] Trial 83 finished with value: 0.6684249518447178 and parameters: {'n_estimators': 198, 'learning_rate': 0.002763139061800016, 'max_depth': 11, 'subsample': 0.6740380861919062, 'colsample_bytree': 0.6419125158490088, 'gamma': 4.997212097350056, 'reg_alpha': 3.4687385960024, 'reg_lambda': 0.8642299620649816}. Best is trial 66 with value: 0.669521410579345.\n",
      "[I 2024-09-22 02:07:44,475] Trial 84 finished with value: 0.6681878796858793 and parameters: {'n_estimators': 370, 'learning_rate': 0.008112947139871091, 'max_depth': 10, 'subsample': 0.7199503771177503, 'colsample_bytree': 0.6232460818063957, 'gamma': 4.679001759633962, 'reg_alpha': 1.0005814433123568, 'reg_lambda': 2.1624869044321304}. Best is trial 66 with value: 0.669521410579345.\n",
      "[I 2024-09-22 02:08:03,780] Trial 85 finished with value: 0.6662913024151725 and parameters: {'n_estimators': 242, 'learning_rate': 0.005985462029124956, 'max_depth': 13, 'subsample': 0.6993468466375568, 'colsample_bytree': 0.7700097551803168, 'gamma': 2.055284816563936, 'reg_alpha': 1.4814534808995183, 'reg_lambda': 3.745783171037572}. Best is trial 66 with value: 0.669521410579345.\n",
      "[I 2024-09-22 02:08:08,056] Trial 86 finished with value: 0.6670914209512521 and parameters: {'n_estimators': 153, 'learning_rate': 0.00720496174648164, 'max_depth': 8, 'subsample': 0.6428235141355664, 'colsample_bytree': 0.59595060845136, 'gamma': 4.448596168277718, 'reg_alpha': 0.24346052838568275, 'reg_lambda': 1.3937437175886038}. Best is trial 66 with value: 0.669521410579345.\n",
      "[I 2024-09-22 02:08:17,468] Trial 87 finished with value: 0.6686323899837012 and parameters: {'n_estimators': 343, 'learning_rate': 0.004447422716543798, 'max_depth': 9, 'subsample': 0.7634312373587973, 'colsample_bytree': 0.49970132622828217, 'gamma': 4.7423186128540475, 'reg_alpha': 0.08053887766757749, 'reg_lambda': 6.666922587994354}. Best is trial 66 with value: 0.669521410579345.\n",
      "[I 2024-09-22 02:08:40,084] Trial 88 finished with value: 0.6659949622166247 and parameters: {'n_estimators': 946, 'learning_rate': 0.004443050737915688, 'max_depth': 9, 'subsample': 0.761598455419509, 'colsample_bytree': 0.5459786922898143, 'gamma': 4.752231414218352, 'reg_alpha': 0.3464191070419443, 'reg_lambda': 0.001343658373479466}. Best is trial 66 with value: 0.669521410579345.\n",
      "[I 2024-09-22 02:08:59,329] Trial 89 finished with value: 0.6684842198844274 and parameters: {'n_estimators': 340, 'learning_rate': 0.005129113931183464, 'max_depth': 11, 'subsample': 0.7932734564368535, 'colsample_bytree': 0.5243884855860855, 'gamma': 2.6115352189759276, 'reg_alpha': 0.18818998817397056, 'reg_lambda': 6.854403123337717}. Best is trial 66 with value: 0.669521410579345.\n",
      "[I 2024-09-22 02:09:09,219] Trial 90 finished with value: 0.6671210549711069 and parameters: {'n_estimators': 238, 'learning_rate': 0.0037365952824593945, 'max_depth': 10, 'subsample': 0.6792462285341019, 'colsample_bytree': 0.6683781827410105, 'gamma': 3.9635280645283033, 'reg_alpha': 0.5247218553817757, 'reg_lambda': 0.6076497927779698}. Best is trial 66 with value: 0.669521410579345.\n",
      "[I 2024-09-22 02:09:14,773] Trial 91 finished with value: 0.6676248333086383 and parameters: {'n_estimators': 397, 'learning_rate': 0.010416992678491529, 'max_depth': 7, 'subsample': 0.7414373140270067, 'colsample_bytree': 0.48733007127755396, 'gamma': 4.6092619999336755, 'reg_alpha': 0.1314061298103787, 'reg_lambda': 3.8650097996768076}. Best is trial 66 with value: 0.669521410579345.\n",
      "[I 2024-09-22 02:09:20,674] Trial 92 finished with value: 0.6693732404800712 and parameters: {'n_estimators': 303, 'learning_rate': 0.008903098490487843, 'max_depth': 19, 'subsample': 0.7720162203717025, 'colsample_bytree': 0.4987530079266938, 'gamma': 4.883388256936129, 'reg_alpha': 0.09369241392956651, 'reg_lambda': 7.134920463572276}. Best is trial 66 with value: 0.669521410579345.\n",
      "[I 2024-09-22 02:09:32,146] Trial 93 finished with value: 0.6640687509260632 and parameters: {'n_estimators': 305, 'learning_rate': 0.008628251714735316, 'max_depth': 19, 'subsample': 0.7656934974581945, 'colsample_bytree': 0.5006461909095768, 'gamma': 4.834763616769548, 'reg_alpha': 0.08527050639568738, 'reg_lambda': 0.004313707016043081}. Best is trial 66 with value: 0.669521410579345.\n",
      "[I 2024-09-22 02:10:06,751] Trial 94 finished with value: 0.6652244777004 and parameters: {'n_estimators': 216, 'learning_rate': 0.005550839883404065, 'max_depth': 17, 'subsample': 0.7796962263125082, 'colsample_bytree': 0.46957738107340274, 'gamma': 1.04330291963376, 'reg_alpha': 0.0002831619339773481, 'reg_lambda': 4.852462674158684}. Best is trial 66 with value: 0.669521410579345.\n",
      "[I 2024-09-22 02:10:16,067] Trial 95 finished with value: 0.6673284931100903 and parameters: {'n_estimators': 277, 'learning_rate': 0.006278651709765652, 'max_depth': 15, 'subsample': 0.7512507660058154, 'colsample_bytree': 0.5051781192763855, 'gamma': 4.913699489489734, 'reg_alpha': 0.03683855762153124, 'reg_lambda': 2.4997642271297056}. Best is trial 66 with value: 0.669521410579345.\n",
      "[I 2024-09-22 02:10:18,827] Trial 96 finished with value: 0.663357534449548 and parameters: {'n_estimators': 252, 'learning_rate': 0.06304426962050756, 'max_depth': 9, 'subsample': 0.7038007997207804, 'colsample_bytree': 0.5160105744517516, 'gamma': 4.396762909162208, 'reg_alpha': 0.014924351598315705, 'reg_lambda': 6.919023453089647}. Best is trial 66 with value: 0.669521410579345.\n",
      "[I 2024-09-22 02:10:25,108] Trial 97 finished with value: 0.667091420951252 and parameters: {'n_estimators': 202, 'learning_rate': 0.009332869234377377, 'max_depth': 10, 'subsample': 0.7927507612418895, 'colsample_bytree': 0.5640552181447905, 'gamma': 4.5435036915593265, 'reg_alpha': 1.8779455253929526e-05, 'reg_lambda': 1.7531891184423372}. Best is trial 66 with value: 0.669521410579345.\n",
      "[I 2024-09-22 02:10:30,985] Trial 98 finished with value: 0.6673877611498 and parameters: {'n_estimators': 147, 'learning_rate': 0.004644842562249904, 'max_depth': 19, 'subsample': 0.7226501112043903, 'colsample_bytree': 0.536910500021305, 'gamma': 4.740708280095416, 'reg_alpha': 0.2315381198656112, 'reg_lambda': 3.1826415988712724}. Best is trial 66 with value: 0.669521410579345.\n",
      "[I 2024-09-22 02:10:39,107] Trial 99 finished with value: 0.6666172766335753 and parameters: {'n_estimators': 300, 'learning_rate': 0.007326304088763533, 'max_depth': 11, 'subsample': 0.7704862738441589, 'colsample_bytree': 0.4737027254911548, 'gamma': 4.912654671276206, 'reg_alpha': 0.8013291230034324, 'reg_lambda': 1.6165010365462217e-05}. Best is trial 66 with value: 0.669521410579345.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGBoost Optuna Tuned\n",
      "Best params: {'n_estimators': 279, 'learning_rate': 0.00804210815880431, 'max_depth': 9, 'subsample': 0.7016342803624044, 'colsample_bytree': 0.4809894955932661, 'gamma': 3.862525199223897, 'reg_alpha': 0.7653156447707654, 'reg_lambda': 5.940053230183238}\n",
      "Best score: 0.669521410579345\n"
     ]
    }
   ],
   "source": [
    "# XGBoost Tuning\n",
    "def tune_xgb(X_train, y_train, tscv, scoring, random_state, n_iter=100):\n",
    "    \n",
    "    def xgb_objective(trial):\n",
    "        xgb_params = {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 1000),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.001, 0.1, log=True),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 20),\n",
    "            \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "            \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.4, 1.0),\n",
    "            \"gamma\": trial.suggest_float(\"gamma\", 0, 5),\n",
    "            \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-5, 10.0, log=True),\n",
    "            \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-5, 10.0, log=True),\n",
    "        }\n",
    "\n",
    "        xgb = XGBClassifier(random_state=random_state, n_jobs=-1, **xgb_params)\n",
    "        scores = cross_val_score(xgb, X_train, y_train, cv=tscv, scoring=scoring)\n",
    "        return scores.mean()\n",
    "    \n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(xgb_objective, n_trials=n_iter)\n",
    "    return study.best_params, study.best_value\n",
    "\n",
    "# Tune model\n",
    "xgb_params_optuna, xgb_score_optuna = tune_xgb(X_train, y_train, tscv, \"accuracy\", RANDOM_SEED)\n",
    "\n",
    "# Display results\n",
    "print(\"\\nXGBoost Optuna Tuned\")\n",
    "print(\"Best params:\", xgb_params_optuna)\n",
    "print(\"Best score:\", xgb_score_optuna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGBoost Optuna Tuned\n",
      "accuracy: 0.669521410579345\n",
      "precision: 0.6675019523713092\n",
      "recall: 0.6766253660892664\n",
      "f1: 0.671688036354927\n",
      "roc_auc: 0.7391724077367231\n"
     ]
    }
   ],
   "source": [
    "xgb_tuned_optuna = XGBClassifier(random_state=RANDOM_SEED, n_jobs=-1, **xgb_params_optuna)\n",
    "\n",
    "print(\"\\nXGBoost Optuna Tuned\")\n",
    "evaluate_model(xgb_tuned_optuna, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained and saved\n"
     ]
    }
   ],
   "source": [
    "# Save model\n",
    "xgb_tuned_optuna.fit(X_train, y_train)\n",
    "joblib.dump(xgb_tuned_optuna, \"models/xgb_optuna_v2.pkl\")\n",
    "print(\"Model trained and saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-22 02:10:46,497] A new study created in memory with name: no-name-e1dc3ce4-8c1c-4282-bde1-2fca67ed530c\n",
      "[I 2024-09-22 02:10:48,570] Trial 0 finished with value: 0.6401244628833901 and parameters: {'C': 2.24242622950689, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 0 with value: 0.6401244628833901.\n",
      "[I 2024-09-22 02:10:48,949] Trial 1 finished with value: 0.6499925914950363 and parameters: {'C': 0.002681332800100651, 'penalty': 'l1', 'solver': 'liblinear'}. Best is trial 1 with value: 0.6499925914950363.\n",
      "[I 2024-09-22 02:10:49,914] Trial 2 finished with value: 0.6496666172766336 and parameters: {'C': 0.0042025114025820215, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 1 with value: 0.6499925914950363.\n",
      "[I 2024-09-22 02:11:00,155] Trial 3 finished with value: 0.6418136020151134 and parameters: {'C': 0.6405232467370149, 'penalty': 'l1', 'solver': 'liblinear'}. Best is trial 1 with value: 0.6499925914950363.\n",
      "[I 2024-09-22 02:11:01,811] Trial 4 finished with value: 0.6478885760853459 and parameters: {'C': 0.025603943182666285, 'penalty': 'l2', 'solver': 'saga'}. Best is trial 1 with value: 0.6499925914950363.\n",
      "[I 2024-09-22 02:11:02,859] Trial 5 finished with value: 0.6497258853163432 and parameters: {'C': 0.0035290063263303615, 'penalty': 'l2', 'solver': 'saga'}. Best is trial 1 with value: 0.6499925914950363.\n",
      "[I 2024-09-22 02:11:05,240] Trial 6 finished with value: 0.6404504371017928 and parameters: {'C': 19.33076325965132, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 1 with value: 0.6499925914950363.\n",
      "[I 2024-09-22 02:11:08,991] Trial 7 finished with value: 0.6482738183434582 and parameters: {'C': 0.15425097539559762, 'penalty': 'l1', 'solver': 'liblinear'}. Best is trial 1 with value: 0.6499925914950363.\n",
      "[I 2024-09-22 02:11:10,721] Trial 8 finished with value: 0.6495777152170692 and parameters: {'C': 0.06526609881361144, 'penalty': 'l1', 'solver': 'saga'}. Best is trial 1 with value: 0.6499925914950363.\n",
      "[I 2024-09-22 02:11:11,727] Trial 9 finished with value: 0.6496962512964883 and parameters: {'C': 0.00513250233932664, 'penalty': 'l2', 'solver': 'saga'}. Best is trial 1 with value: 0.6499925914950363.\n",
      "[I 2024-09-22 02:11:11,894] Trial 10 finished with value: 0.5000148170099274 and parameters: {'C': 3.791144215166021e-05, 'penalty': 'l1', 'solver': 'liblinear'}. Best is trial 1 with value: 0.6499925914950363.\n",
      "[I 2024-09-22 02:11:12,449] Trial 11 finished with value: 0.5000148170099274 and parameters: {'C': 0.00018595705120560702, 'penalty': 'l1', 'solver': 'saga'}. Best is trial 1 with value: 0.6499925914950363.\n",
      "[I 2024-09-22 02:11:13,861] Trial 12 finished with value: 0.5818343458290116 and parameters: {'C': 0.0006489819136629629, 'penalty': 'l1', 'solver': 'saga'}. Best is trial 1 with value: 0.6499925914950363.\n",
      "[I 2024-09-22 02:11:14,762] Trial 13 finished with value: 0.6512964883686473 and parameters: {'C': 1.4179010308757673e-05, 'penalty': 'l2', 'solver': 'saga'}. Best is trial 13 with value: 0.6512964883686473.\n",
      "[I 2024-09-22 02:11:15,069] Trial 14 finished with value: 0.6514742924877759 and parameters: {'C': 1.0108240518498442e-05, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 14 with value: 0.6514742924877759.\n",
      "[I 2024-09-22 02:11:15,928] Trial 15 finished with value: 0.6511779522892279 and parameters: {'C': 1.1508665942782788e-05, 'penalty': 'l2', 'solver': 'saga'}. Best is trial 14 with value: 0.6514742924877759.\n",
      "[I 2024-09-22 02:11:16,812] Trial 16 finished with value: 0.6516520966069047 and parameters: {'C': 0.0001077226261468762, 'penalty': 'l2', 'solver': 'saga'}. Best is trial 16 with value: 0.6516520966069047.\n",
      "[I 2024-09-22 02:11:17,213] Trial 17 finished with value: 0.651474292487776 and parameters: {'C': 0.00011359863584352324, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 16 with value: 0.6516520966069047.\n",
      "[I 2024-09-22 02:11:17,759] Trial 18 finished with value: 0.6516520966069048 and parameters: {'C': 0.0001438394185453139, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 18 with value: 0.6516520966069048.\n",
      "[I 2024-09-22 02:11:18,746] Trial 19 finished with value: 0.6508519780708253 and parameters: {'C': 0.0005027700758716688, 'penalty': 'l2', 'solver': 'saga'}. Best is trial 18 with value: 0.6516520966069048.\n",
      "[I 2024-09-22 02:11:19,204] Trial 20 finished with value: 0.6515928285671951 and parameters: {'C': 0.00011570525589013435, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 18 with value: 0.6516520966069048.\n",
      "[I 2024-09-22 02:11:19,613] Trial 21 finished with value: 0.6516520966069048 and parameters: {'C': 0.00010135478630271763, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 18 with value: 0.6516520966069048.\n",
      "[I 2024-09-22 02:11:20,161] Trial 22 finished with value: 0.6509408801303896 and parameters: {'C': 0.0006014714199599776, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 18 with value: 0.6516520966069048.\n",
      "[I 2024-09-22 02:11:20,565] Trial 23 finished with value: 0.6516224625870499 and parameters: {'C': 6.0802410950940315e-05, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 18 with value: 0.6516520966069048.\n",
      "[I 2024-09-22 02:11:21,156] Trial 24 finished with value: 0.6515039265076308 and parameters: {'C': 0.00039134401057295523, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 18 with value: 0.6516520966069048.\n",
      "[I 2024-09-22 02:11:22,832] Trial 25 finished with value: 0.6489554008001186 and parameters: {'C': 0.015805125645289488, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 18 with value: 0.6516520966069048.\n",
      "[I 2024-09-22 02:11:23,950] Trial 26 finished with value: 0.650170395614165 and parameters: {'C': 0.0014309424263131234, 'penalty': 'l2', 'solver': 'saga'}. Best is trial 18 with value: 0.6516520966069048.\n",
      "[I 2024-09-22 02:11:24,463] Trial 27 finished with value: 0.6516817306267595 and parameters: {'C': 3.00648114507943e-05, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 27 with value: 0.6516817306267595.\n",
      "[I 2024-09-22 02:11:25,011] Trial 28 finished with value: 0.6512372203289376 and parameters: {'C': 4.008597452510078e-05, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 27 with value: 0.6516817306267595.\n",
      "[I 2024-09-22 02:11:27,035] Trial 29 finished with value: 0.6403022670025189 and parameters: {'C': 17.846920559806136, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 27 with value: 0.6516817306267595.\n",
      "[I 2024-09-22 02:11:29,293] Trial 30 finished with value: 0.6409245814194696 and parameters: {'C': 94.80286557269905, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 27 with value: 0.6516817306267595.\n",
      "[I 2024-09-22 02:11:29,621] Trial 31 finished with value: 0.6513853904282116 and parameters: {'C': 2.653014480486799e-05, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 27 with value: 0.6516817306267595.\n",
      "[I 2024-09-22 02:11:30,051] Trial 32 finished with value: 0.6517113646466143 and parameters: {'C': 0.000170942101207326, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 32 with value: 0.6517113646466143.\n",
      "[I 2024-09-22 02:11:30,579] Trial 33 finished with value: 0.6517409986664691 and parameters: {'C': 0.0002692689671461099, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 33 with value: 0.6517409986664691.\n",
      "[I 2024-09-22 02:11:31,374] Trial 34 finished with value: 0.6499629574751815 and parameters: {'C': 0.0013296085497551896, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 33 with value: 0.6517409986664691.\n",
      "[I 2024-09-22 02:11:32,326] Trial 35 finished with value: 0.649607349236924 and parameters: {'C': 0.009066506314140877, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 33 with value: 0.6517409986664691.\n",
      "[I 2024-09-22 02:11:32,810] Trial 36 finished with value: 0.6518891687657431 and parameters: {'C': 0.0002450045514350495, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 36 with value: 0.6518891687657431.\n",
      "[I 2024-09-22 02:11:33,292] Trial 37 finished with value: 0.6515335605274856 and parameters: {'C': 0.00030971552316237124, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 36 with value: 0.6518891687657431.\n",
      "[I 2024-09-22 02:11:33,710] Trial 38 finished with value: 0.6323603496814343 and parameters: {'C': 0.001315643695462303, 'penalty': 'l1', 'solver': 'liblinear'}. Best is trial 36 with value: 0.6518891687657431.\n",
      "[I 2024-09-22 02:11:35,466] Trial 39 finished with value: 0.6401244628833901 and parameters: {'C': 1.3674727502611124, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 36 with value: 0.6518891687657431.\n",
      "[I 2024-09-22 02:11:36,798] Trial 40 finished with value: 0.6462587049933323 and parameters: {'C': 0.06377857318777512, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 36 with value: 0.6518891687657431.\n",
      "[I 2024-09-22 02:11:37,246] Trial 41 finished with value: 0.6519780708253073 and parameters: {'C': 0.00023955858690719552, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 41 with value: 0.6519780708253073.\n",
      "[I 2024-09-22 02:11:37,706] Trial 42 finished with value: 0.651770632686324 and parameters: {'C': 0.0002695898363362128, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 41 with value: 0.6519780708253073.\n",
      "[I 2024-09-22 02:11:38,412] Trial 43 finished with value: 0.6499925914950364 and parameters: {'C': 0.00251591127124914, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 41 with value: 0.6519780708253073.\n",
      "[I 2024-09-22 02:11:38,559] Trial 44 finished with value: 0.5000148170099274 and parameters: {'C': 0.00028168303333756217, 'penalty': 'l1', 'solver': 'liblinear'}. Best is trial 41 with value: 0.6519780708253073.\n",
      "[I 2024-09-22 02:11:39,221] Trial 45 finished with value: 0.650466735812713 and parameters: {'C': 0.001009035534908541, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 41 with value: 0.6519780708253073.\n",
      "[I 2024-09-22 02:11:39,999] Trial 46 finished with value: 0.6495480811972144 and parameters: {'C': 0.004331723131557603, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 41 with value: 0.6519780708253073.\n",
      "[I 2024-09-22 02:11:40,137] Trial 47 finished with value: 0.5000148170099274 and parameters: {'C': 0.00022211548937682408, 'penalty': 'l1', 'solver': 'liblinear'}. Best is trial 41 with value: 0.6519780708253073.\n",
      "[I 2024-09-22 02:11:41,887] Trial 48 finished with value: 0.6414579937768559 and parameters: {'C': 0.37126746849069975, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 41 with value: 0.6519780708253073.\n",
      "[I 2024-09-22 02:11:42,268] Trial 49 finished with value: 0.6516817306267595 and parameters: {'C': 6.35801213897732e-05, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 41 with value: 0.6519780708253073.\n",
      "[I 2024-09-22 02:11:43,039] Trial 50 finished with value: 0.6501407615943103 and parameters: {'C': 0.0023763633336396704, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 41 with value: 0.6519780708253073.\n",
      "[I 2024-09-22 02:11:43,374] Trial 51 finished with value: 0.651474292487776 and parameters: {'C': 3.335058729793158e-05, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 41 with value: 0.6519780708253073.\n",
      "[I 2024-09-22 02:11:43,646] Trial 52 finished with value: 0.6517113646466143 and parameters: {'C': 2.0378540064447634e-05, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 41 with value: 0.6519780708253073.\n",
      "[I 2024-09-22 02:11:43,921] Trial 53 finished with value: 0.6516817306267596 and parameters: {'C': 1.8338355176372836e-05, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 41 with value: 0.6519780708253073.\n",
      "[I 2024-09-22 02:11:44,275] Trial 54 finished with value: 0.6516817306267596 and parameters: {'C': 6.167082226097612e-05, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 41 with value: 0.6519780708253073.\n",
      "[I 2024-09-22 02:11:44,418] Trial 55 finished with value: 0.5000148170099274 and parameters: {'C': 0.00017807827975200048, 'penalty': 'l1', 'solver': 'liblinear'}. Best is trial 41 with value: 0.6519780708253073.\n",
      "[I 2024-09-22 02:11:44,772] Trial 56 finished with value: 0.6517409986664691 and parameters: {'C': 7.085941555061953e-05, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 41 with value: 0.6519780708253073.\n",
      "[I 2024-09-22 02:11:45,256] Trial 57 finished with value: 0.6503481997332938 and parameters: {'C': 0.0007527593231563929, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 41 with value: 0.6519780708253073.\n",
      "[I 2024-09-22 02:11:46,125] Trial 58 finished with value: 0.6510297821899541 and parameters: {'C': 0.0004942928126617103, 'penalty': 'l2', 'solver': 'saga'}. Best is trial 41 with value: 0.6519780708253073.\n",
      "[I 2024-09-22 02:11:46,490] Trial 59 finished with value: 0.6517409986664691 and parameters: {'C': 7.667646635328618e-05, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 41 with value: 0.6519780708253073.\n",
      "[I 2024-09-22 02:11:46,840] Trial 60 finished with value: 0.6518299007260335 and parameters: {'C': 7.11520471642338e-05, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 41 with value: 0.6519780708253073.\n",
      "[I 2024-09-22 02:11:47,196] Trial 61 finished with value: 0.6519188027855979 and parameters: {'C': 7.944491611999138e-05, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 41 with value: 0.6519780708253073.\n",
      "[I 2024-09-22 02:11:47,556] Trial 62 finished with value: 0.651177952289228 and parameters: {'C': 5.004980398432958e-05, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 41 with value: 0.6519780708253073.\n",
      "[I 2024-09-22 02:11:48,016] Trial 63 finished with value: 0.6518002667061786 and parameters: {'C': 0.00027093186937828743, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 41 with value: 0.6519780708253073.\n",
      "[I 2024-09-22 02:11:48,501] Trial 64 finished with value: 0.6515928285671951 and parameters: {'C': 0.00041131357700046267, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 41 with value: 0.6519780708253073.\n",
      "[I 2024-09-22 02:11:48,889] Trial 65 finished with value: 0.6518002667061787 and parameters: {'C': 0.0001257154525094432, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 41 with value: 0.6519780708253073.\n",
      "[I 2024-09-22 02:11:49,747] Trial 66 finished with value: 0.651770632686324 and parameters: {'C': 0.00011256353751631805, 'penalty': 'l2', 'solver': 'saga'}. Best is trial 41 with value: 0.6519780708253073.\n",
      "[I 2024-09-22 02:11:50,212] Trial 67 finished with value: 0.6516520966069048 and parameters: {'C': 0.00014424920317180937, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 41 with value: 0.6519780708253073.\n",
      "[I 2024-09-22 02:11:50,590] Trial 68 finished with value: 0.6096310564528078 and parameters: {'C': 0.0007983278507933971, 'penalty': 'l1', 'solver': 'liblinear'}. Best is trial 41 with value: 0.6519780708253073.\n",
      "[I 2024-09-22 02:11:50,879] Trial 69 finished with value: 0.6516224625870499 and parameters: {'C': 1.3688336208173591e-05, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 41 with value: 0.6519780708253073.\n",
      "[I 2024-09-22 02:11:51,333] Trial 70 finished with value: 0.6521262409245814 and parameters: {'C': 0.00023433365823034136, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 70 with value: 0.6521262409245814.\n",
      "[I 2024-09-22 02:11:51,796] Trial 71 finished with value: 0.6519780708253073 and parameters: {'C': 0.00023883757111985504, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 70 with value: 0.6521262409245814.\n",
      "[I 2024-09-22 02:11:52,163] Trial 72 finished with value: 0.6515631945473404 and parameters: {'C': 9.405105578173016e-05, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 70 with value: 0.6521262409245814.\n",
      "[I 2024-09-22 02:11:52,512] Trial 73 finished with value: 0.6515631945473404 and parameters: {'C': 4.1991084685220016e-05, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 70 with value: 0.6521262409245814.\n",
      "[I 2024-09-22 02:11:52,933] Trial 74 finished with value: 0.6518299007260334 and parameters: {'C': 0.00017387169966504224, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 70 with value: 0.6521262409245814.\n",
      "[I 2024-09-22 02:11:53,338] Trial 75 finished with value: 0.6516520966069047 and parameters: {'C': 0.00016796784614395055, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 70 with value: 0.6521262409245814.\n",
      "[I 2024-09-22 02:11:54,240] Trial 76 finished with value: 0.6509705141502444 and parameters: {'C': 0.0005473499128354225, 'penalty': 'l2', 'solver': 'saga'}. Best is trial 70 with value: 0.6521262409245814.\n",
      "[I 2024-09-22 02:11:54,566] Trial 77 finished with value: 0.6513853904282115 and parameters: {'C': 2.581413901192667e-05, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 70 with value: 0.6521262409245814.\n",
      "[I 2024-09-22 02:11:55,105] Trial 78 finished with value: 0.6516224625870499 and parameters: {'C': 0.00036518773465454217, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 70 with value: 0.6521262409245814.\n",
      "[I 2024-09-22 02:11:55,682] Trial 79 finished with value: 0.6518002667061786 and parameters: {'C': 0.00013901391184987898, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 70 with value: 0.6521262409245814.\n",
      "[I 2024-09-22 02:11:56,659] Trial 80 finished with value: 0.649607349236924 and parameters: {'C': 0.008896793951527152, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 70 with value: 0.6521262409245814.\n",
      "[I 2024-09-22 02:11:57,112] Trial 81 finished with value: 0.6518002667061786 and parameters: {'C': 0.0002716674033014382, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 70 with value: 0.6521262409245814.\n",
      "[I 2024-09-22 02:11:57,499] Trial 82 finished with value: 0.6519188027855979 and parameters: {'C': 8.413705610136284e-05, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 70 with value: 0.6521262409245814.\n",
      "[I 2024-09-22 02:11:57,861] Trial 83 finished with value: 0.6518002667061786 and parameters: {'C': 8.95176331455222e-05, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 70 with value: 0.6521262409245814.\n",
      "[I 2024-09-22 02:11:58,501] Trial 84 finished with value: 0.6506445399318418 and parameters: {'C': 0.0015461246985402509, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 70 with value: 0.6521262409245814.\n",
      "[I 2024-09-22 02:11:58,852] Trial 85 finished with value: 0.6514446584679211 and parameters: {'C': 4.58405000138776e-05, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 70 with value: 0.6521262409245814.\n",
      "[I 2024-09-22 02:11:58,994] Trial 86 finished with value: 0.5000148170099274 and parameters: {'C': 0.00018316446422241445, 'penalty': 'l1', 'solver': 'liblinear'}. Best is trial 70 with value: 0.6521262409245814.\n",
      "[I 2024-09-22 02:11:59,584] Trial 87 finished with value: 0.650466735812713 and parameters: {'C': 0.0010077057380465286, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 70 with value: 0.6521262409245814.\n",
      "[I 2024-09-22 02:11:59,876] Trial 88 finished with value: 0.6515039265076308 and parameters: {'C': 1.0511973596167589e-05, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 70 with value: 0.6521262409245814.\n",
      "[I 2024-09-22 02:12:00,757] Trial 89 finished with value: 0.6515631945473404 and parameters: {'C': 1.867239398817539e-05, 'penalty': 'l2', 'solver': 'saga'}. Best is trial 70 with value: 0.6521262409245814.\n",
      "[I 2024-09-22 02:12:01,094] Trial 90 finished with value: 0.6516817306267596 and parameters: {'C': 3.064106708097261e-05, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 70 with value: 0.6521262409245814.\n",
      "[I 2024-09-22 02:12:01,552] Trial 91 finished with value: 0.6519484368054527 and parameters: {'C': 0.00024029156978452702, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 70 with value: 0.6521262409245814.\n",
      "[I 2024-09-22 02:12:01,932] Trial 92 finished with value: 0.6516817306267594 and parameters: {'C': 0.00010264449078812919, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 70 with value: 0.6521262409245814.\n",
      "[I 2024-09-22 02:12:02,391] Trial 93 finished with value: 0.6517113646466143 and parameters: {'C': 0.0004241004589187017, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 70 with value: 0.6521262409245814.\n",
      "[I 2024-09-22 02:12:02,854] Trial 94 finished with value: 0.6521262409245814 and parameters: {'C': 0.00023440622377598105, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 70 with value: 0.6521262409245814.\n",
      "[I 2024-09-22 02:12:03,267] Trial 95 finished with value: 0.6520966069047267 and parameters: {'C': 0.00021081720327937662, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 70 with value: 0.6521262409245814.\n",
      "[I 2024-09-22 02:12:03,742] Trial 96 finished with value: 0.6509705141502444 and parameters: {'C': 0.0005563459598390538, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 70 with value: 0.6521262409245814.\n",
      "[I 2024-09-22 02:12:04,104] Trial 97 finished with value: 0.6515631945473402 and parameters: {'C': 5.5079227367635304e-05, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 70 with value: 0.6521262409245814.\n",
      "[I 2024-09-22 02:12:04,538] Trial 98 finished with value: 0.6521262409245814 and parameters: {'C': 0.00023259548801526946, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 70 with value: 0.6521262409245814.\n",
      "[I 2024-09-22 02:12:04,893] Trial 99 finished with value: 0.6452807823381242 and parameters: {'C': 0.00188666643051546, 'penalty': 'l1', 'solver': 'liblinear'}. Best is trial 70 with value: 0.6521262409245814.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Optuna Tuned\n",
      "Best params: {'C': 0.00023433365823034136, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Best score: 0.6521262409245814\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression Tuning\n",
    "def tune_logreg(X_train, y_train, tscv, scoring, random_state, n_iter=100):\n",
    "\n",
    "    def logreg_objective(trial):\n",
    "        logreg_params = {\n",
    "            \"C\": trial.suggest_float(\"C\", 1e-5, 100, log=True),\n",
    "            \"penalty\": trial.suggest_categorical(\"penalty\", [\"l1\", \"l2\"]),\n",
    "            \"solver\": trial.suggest_categorical(\"solver\", [\"liblinear\", \"saga\"]),\n",
    "        }\n",
    "\n",
    "        logreg = LogisticRegression(random_state=random_state, max_iter=2000, **logreg_params)\n",
    "        scores = cross_val_score(logreg, X_train, y_train, cv=tscv, scoring=scoring)\n",
    "        return scores.mean()\n",
    "    \n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(logreg_objective, n_trials=n_iter)\n",
    "    return study.best_params, study.best_value\n",
    "\n",
    "\n",
    "# Tune model\n",
    "logreg_params_optuna, logreg_score_optuna = tune_logreg(X_train_scaled, y_train, tscv, \"accuracy\", RANDOM_SEED)\n",
    "\n",
    "# Display results\n",
    "print(\"Logistic Regression Optuna Tuned\")\n",
    "print(\"Best params:\", logreg_params_optuna)\n",
    "print(\"Best score:\", logreg_score_optuna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Optuna Tuned\n",
      "accuracy: 0.6521262409245814\n",
      "precision: 0.6568037436725922\n",
      "recall: 0.636499488462974\n",
      "f1: 0.6464430693078328\n",
      "roc_auc: 0.712426178401282\n"
     ]
    }
   ],
   "source": [
    "logreg_tuned_optuna = LogisticRegression(random_state=RANDOM_SEED, max_iter=2000, **logreg_params_optuna)\n",
    "\n",
    "print(\"Logistic Regression Optuna Tuned\")\n",
    "evaluate_model(logreg_tuned_optuna, X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM Tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CatBoost Tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM Tuning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Classifier\n",
      "accuracy: 0.6702326270558602\n",
      "precision: 0.6700408107386963\n",
      "recall: 0.6717048277678983\n",
      "f1: 0.670564636958488\n",
      "roc_auc: 0.7395990427890843\n"
     ]
    }
   ],
   "source": [
    "# Level 1 models that train on the train set\n",
    "base_models = [\n",
    "    (\"rf\", rf_tuned_optuna),\n",
    "    (\"xgb\", xgb_tuned_optuna)\n",
    "]\n",
    "\n",
    "# Trains on the predictions of the base models\n",
    "meta_model = LogisticRegression(random_state=RANDOM_SEED, max_iter=2000)\n",
    "# meta_model = RandomForestClassifier(random_state=RANDOM_SEED, n_jobs=-1, **rf_params_optuna)\n",
    "# meta_model = XGBClassifier(random_state=RANDOM_SEED, **xgb_params_optuna)\n",
    "\n",
    "# Leverages the predictions of the base models to improve predictive performance\n",
    "stacking_model = StackingClassifier(estimators=base_models, \n",
    "                                    final_estimator=meta_model,\n",
    "                                    n_jobs=-1)\n",
    "\n",
    "print(\"Stacking Classifier\")\n",
    "evaluate_model(stacking_model, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained and saved\n"
     ]
    }
   ],
   "source": [
    "# Stacked Classifier\n",
    "stacking_model.fit(X_train, y_train)\n",
    "joblib.dump(stacking_model, \"models/stacked_base_rf_xgb_meta_lr_v2.pkl\")\n",
    "print(\"Model trained and saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features: Index(['Team A_Encoded', 'Team B_Encoded', 'Recent Win %_TeamA',\n",
      "       'Attacker Win %_RollAvg_TeamA', 'Attacker Win %_RollAvg_TeamB',\n",
      "       'Defender Win %_RollAvg_TeamA', 'Defender Win %_RollAvg_TeamB',\n",
      "       'Average Combat Score_RollAvg_TeamA',\n",
      "       'Average Combat Score_RollAvg_TeamB',\n",
      "       'Average Damage Per Round_RollAvg_TeamA',\n",
      "       'Average Damage Per Round_RollAvg_TeamB', 'KDA_RollAvg_TeamA',\n",
      "       'KDA_RollAvg_TeamB', 'Kill, Assist, Trade, Survive %_RollAvg_TeamA',\n",
      "       'Kill, Assist, Trade, Survive %_RollAvg_TeamB',\n",
      "       'First Blood %_RollAvg_TeamA', 'First Blood %_RollAvg_TeamB'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "sfm = SelectFromModel(rf_tuned_optuna, threshold=\"mean\")\n",
    "sfm.fit(X_train, y_train)\n",
    "\n",
    "selected_features = X_train.columns[sfm.get_support()]\n",
    "print(f\"Selected Features: {selected_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features: Index(['Team A_Encoded', 'Team B_Encoded', 'Recent Win %_TeamA',\n",
      "       'Recent Win %_TeamB', 'Attacker Win %_RollAvg_TeamA',\n",
      "       'Attacker Win %_RollAvg_TeamB', 'Defender Win %_RollAvg_TeamB',\n",
      "       'Average Combat Score_RollAvg_TeamA',\n",
      "       'Average Combat Score_RollAvg_TeamB',\n",
      "       'Average Damage Per Round_RollAvg_TeamA',\n",
      "       'Average Damage Per Round_RollAvg_TeamB', 'KDA_RollAvg_TeamA',\n",
      "       'KDA_RollAvg_TeamB', 'Kill, Assist, Trade, Survive %_RollAvg_TeamB'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "sfm_xgb = SelectFromModel(xgb_tuned_optuna, threshold=\"mean\")\n",
    "sfm_xgb.fit(X_train, y_train)\n",
    "\n",
    "xgb_selected_features = X_train.columns[sfm_xgb.get_support()]\n",
    "print(f\"Selected Features: {xgb_selected_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(xgb_selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retraining the models and cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=-1,\n",
       "              num_parallel_tree=None, random_state=1, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;XGBClassifier<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=-1,\n",
       "              num_parallel_tree=None, random_state=1, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=-1,\n",
       "              num_parallel_tree=None, random_state=1, ...)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_selected = X_train[selected_features]\n",
    "X_test_selected = X_test[selected_features]\n",
    "\n",
    "rf_reduced_feats = RandomForestClassifier(random_state=RANDOM_SEED, n_jobs=-1)\n",
    "rf_reduced_feats.fit(X_train_selected, y_train)\n",
    "\n",
    "xgb_reduced_feats = XGBClassifier(random_state=RANDOM_SEED, n_jobs=-1) \n",
    "xgb_reduced_feats.fit(X_train_selected, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Reduced Features\n",
      "accuracy: 0.6535486738776115\n",
      "precision: 0.6584465049590867\n",
      "recall: 0.6380979604382093\n",
      "f1: 0.6479024010097757\n",
      "roc_auc: 0.7214904827767897\n",
      "\n",
      "XGBoost Reduced Features\n",
      "accuracy: 0.6405097051415025\n",
      "precision: 0.6388758528488012\n",
      "recall: 0.6465160245010867\n",
      "f1: 0.6426698795914341\n",
      "roc_auc: 0.7062244352236053\n"
     ]
    }
   ],
   "source": [
    "rf_reduced_feats_scores = cross_validate(rf_reduced_feats, X_train_selected, y_train, cv=tscv, scoring=SCORING)\n",
    "xgb_reduced_feats_scores = cross_validate(xgb_reduced_feats, X_train_selected, y_train, cv=tscv, scoring=SCORING)\n",
    "\n",
    "print(\"Random Forest Reduced Features\")\n",
    "for metric in SCORING:\n",
    "    print(f\"{metric}: {rf_reduced_feats_scores[f'test_{metric}'].mean()}\")\n",
    "\n",
    "print(\"\\nXGBoost Reduced Features\")\n",
    "for metric in SCORING:\n",
    "    print(f\"{metric}: {xgb_reduced_feats_scores[f'test_{metric}'].mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Reduced Features Test Set\n",
      "Accuracy: 0.5871604938271605\n",
      "Precision: 0.5880007972892166\n",
      "Recall: 0.5826585028639146\n",
      "F1: 0.5853174603174603\n",
      "ROC-AUC: 0.6275024965950556\n",
      "\n",
      "XGBoost Reduced Features Test Set\n",
      "Accuracy: 0.5820246913580247\n",
      "Precision: 0.5802588371643809\n",
      "Recall: 0.5933241161366779\n",
      "F1: 0.58671875\n",
      "ROC-AUC: 0.6213230092614956\n"
     ]
    }
   ],
   "source": [
    "# Test set evaluation\n",
    "def evaluate_test_set(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "    print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "    print(\"F1:\", f1_score(y_test, y_pred))\n",
    "    print(\"ROC-AUC:\", roc_auc_score(y_test, y_pred_proba))\n",
    "\n",
    "\n",
    "print(\"Random Forest Reduced Features Test Set\")\n",
    "evaluate_test_set(rf_reduced_feats, X_test_selected, y_test)\n",
    "\n",
    "print(\"\\nXGBoost Reduced Features Test Set\")\n",
    "evaluate_test_set(xgb_reduced_feats, X_test_selected, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-22 19:46:27,765] A new study created in memory with name: no-name-403e3571-2c49-4158-941c-216cb2bda141\n",
      "[I 2024-09-22 19:47:42,054] Trial 0 finished with value: 0.6632389983701288 and parameters: {'n_estimators': 636, 'max_depth': 49, 'min_samples_split': 24, 'min_samples_leaf': 24, 'max_features': None}. Best is trial 0 with value: 0.6632389983701288.\n",
      "[I 2024-09-22 19:47:58,767] Trial 1 finished with value: 0.6676841013483479 and parameters: {'n_estimators': 454, 'max_depth': 10, 'min_samples_split': 21, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 1 with value: 0.6676841013483479.\n",
      "[I 2024-09-22 19:49:07,936] Trial 2 finished with value: 0.6652837457401096 and parameters: {'n_estimators': 801, 'max_depth': 7, 'min_samples_split': 25, 'min_samples_leaf': 13, 'max_features': None}. Best is trial 1 with value: 0.6676841013483479.\n",
      "[I 2024-09-22 19:49:52,446] Trial 3 finished with value: 0.6663209364350273 and parameters: {'n_estimators': 879, 'max_depth': 12, 'min_samples_split': 27, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 1 with value: 0.6676841013483479.\n",
      "[I 2024-09-22 19:50:23,194] Trial 4 finished with value: 0.6668839828122686 and parameters: {'n_estimators': 709, 'max_depth': 15, 'min_samples_split': 19, 'min_samples_leaf': 21, 'max_features': 'log2'}. Best is trial 1 with value: 0.6676841013483479.\n",
      "[I 2024-09-22 19:50:45,843] Trial 5 finished with value: 0.6675062972292192 and parameters: {'n_estimators': 520, 'max_depth': 40, 'min_samples_split': 9, 'min_samples_leaf': 21, 'max_features': 'log2'}. Best is trial 1 with value: 0.6676841013483479.\n",
      "[I 2024-09-22 19:50:52,894] Trial 6 finished with value: 0.6679508075270411 and parameters: {'n_estimators': 183, 'max_depth': 16, 'min_samples_split': 8, 'min_samples_leaf': 32, 'max_features': 'log2'}. Best is trial 6 with value: 0.6679508075270411.\n",
      "[I 2024-09-22 19:51:22,153] Trial 7 finished with value: 0.6676248333086383 and parameters: {'n_estimators': 817, 'max_depth': 28, 'min_samples_split': 15, 'min_samples_leaf': 24, 'max_features': 'sqrt'}. Best is trial 6 with value: 0.6679508075270411.\n",
      "[I 2024-09-22 19:51:29,186] Trial 8 finished with value: 0.6670321529115425 and parameters: {'n_estimators': 192, 'max_depth': 49, 'min_samples_split': 3, 'min_samples_leaf': 23, 'max_features': 'log2'}. Best is trial 6 with value: 0.6679508075270411.\n",
      "[I 2024-09-22 19:51:58,374] Trial 9 finished with value: 0.668691658023411 and parameters: {'n_estimators': 870, 'max_depth': 21, 'min_samples_split': 20, 'min_samples_leaf': 30, 'max_features': 'log2'}. Best is trial 9 with value: 0.668691658023411.\n",
      "[I 2024-09-22 19:52:31,114] Trial 10 finished with value: 0.6677730034079123 and parameters: {'n_estimators': 988, 'max_depth': 26, 'min_samples_split': 32, 'min_samples_leaf': 31, 'max_features': 'sqrt'}. Best is trial 9 with value: 0.668691658023411.\n",
      "[I 2024-09-22 19:52:36,498] Trial 11 finished with value: 0.6665876426137205 and parameters: {'n_estimators': 150, 'max_depth': 21, 'min_samples_split': 12, 'min_samples_leaf': 32, 'max_features': 'log2'}. Best is trial 9 with value: 0.668691658023411.\n",
      "[I 2024-09-22 19:52:47,844] Trial 12 finished with value: 0.6669432508519781 and parameters: {'n_estimators': 329, 'max_depth': 21, 'min_samples_split': 6, 'min_samples_leaf': 29, 'max_features': 'log2'}. Best is trial 9 with value: 0.668691658023411.\n",
      "[I 2024-09-22 19:52:59,097] Trial 13 finished with value: 0.6655504519188028 and parameters: {'n_estimators': 296, 'max_depth': 18, 'min_samples_split': 15, 'min_samples_leaf': 14, 'max_features': 'log2'}. Best is trial 9 with value: 0.668691658023411.\n",
      "[I 2024-09-22 19:53:11,727] Trial 14 finished with value: 0.6686323899837013 and parameters: {'n_estimators': 369, 'max_depth': 32, 'min_samples_split': 11, 'min_samples_leaf': 28, 'max_features': 'log2'}. Best is trial 9 with value: 0.668691658023411.\n",
      "[I 2024-09-22 19:53:58,716] Trial 15 finished with value: 0.663238998370129 and parameters: {'n_estimators': 431, 'max_depth': 35, 'min_samples_split': 12, 'min_samples_leaf': 27, 'max_features': None}. Best is trial 9 with value: 0.668691658023411.\n",
      "[I 2024-09-22 19:54:23,564] Trial 16 finished with value: 0.6638909468069343 and parameters: {'n_estimators': 598, 'max_depth': 34, 'min_samples_split': 18, 'min_samples_leaf': 8, 'max_features': 'log2'}. Best is trial 9 with value: 0.668691658023411.\n",
      "[I 2024-09-22 19:54:59,989] Trial 17 finished with value: 0.6671506889909617 and parameters: {'n_estimators': 972, 'max_depth': 28, 'min_samples_split': 2, 'min_samples_leaf': 18, 'max_features': 'log2'}. Best is trial 9 with value: 0.668691658023411.\n",
      "[I 2024-09-22 19:55:37,249] Trial 18 finished with value: 0.6631500963105645 and parameters: {'n_estimators': 337, 'max_depth': 40, 'min_samples_split': 30, 'min_samples_leaf': 27, 'max_features': None}. Best is trial 9 with value: 0.668691658023411.\n",
      "[I 2024-09-22 19:56:03,965] Trial 19 finished with value: 0.6692547044006519 and parameters: {'n_estimators': 700, 'max_depth': 33, 'min_samples_split': 22, 'min_samples_leaf': 27, 'max_features': 'sqrt'}. Best is trial 19 with value: 0.6692547044006519.\n",
      "[I 2024-09-22 19:56:41,708] Trial 20 finished with value: 0.6672692250703809 and parameters: {'n_estimators': 719, 'max_depth': 40, 'min_samples_split': 22, 'min_samples_leaf': 17, 'max_features': 'sqrt'}. Best is trial 19 with value: 0.6692547044006519.\n",
      "[I 2024-09-22 19:57:23,166] Trial 21 finished with value: 0.6689879982219588 and parameters: {'n_estimators': 710, 'max_depth': 33, 'min_samples_split': 15, 'min_samples_leaf': 27, 'max_features': 'sqrt'}. Best is trial 19 with value: 0.6692547044006519.\n",
      "[I 2024-09-22 19:57:51,867] Trial 22 finished with value: 0.6681878796858794 and parameters: {'n_estimators': 702, 'max_depth': 25, 'min_samples_split': 17, 'min_samples_leaf': 26, 'max_features': 'sqrt'}. Best is trial 19 with value: 0.6692547044006519.\n",
      "[I 2024-09-22 19:58:23,646] Trial 23 finished with value: 0.6687509260631205 and parameters: {'n_estimators': 880, 'max_depth': 30, 'min_samples_split': 22, 'min_samples_leaf': 30, 'max_features': 'sqrt'}. Best is trial 19 with value: 0.6692547044006519.\n",
      "[I 2024-09-22 19:58:52,672] Trial 24 finished with value: 0.6675062972292192 and parameters: {'n_estimators': 801, 'max_depth': 37, 'min_samples_split': 27, 'min_samples_leaf': 20, 'max_features': 'sqrt'}. Best is trial 19 with value: 0.6692547044006519.\n",
      "[I 2024-09-22 19:59:14,353] Trial 25 finished with value: 0.667239591050526 and parameters: {'n_estimators': 638, 'max_depth': 31, 'min_samples_split': 22, 'min_samples_leaf': 25, 'max_features': 'sqrt'}. Best is trial 19 with value: 0.6692547044006519.\n",
      "[I 2024-09-22 19:59:45,599] Trial 26 finished with value: 0.6681878796858794 and parameters: {'n_estimators': 924, 'max_depth': 45, 'min_samples_split': 16, 'min_samples_leaf': 29, 'max_features': 'sqrt'}. Best is trial 19 with value: 0.6692547044006519.\n",
      "[I 2024-09-22 20:00:16,649] Trial 27 finished with value: 0.6657578900577864 and parameters: {'n_estimators': 756, 'max_depth': 31, 'min_samples_split': 26, 'min_samples_leaf': 10, 'max_features': 'sqrt'}. Best is trial 19 with value: 0.6692547044006519.\n",
      "[I 2024-09-22 20:00:36,191] Trial 28 finished with value: 0.6691658023410876 and parameters: {'n_estimators': 539, 'max_depth': 43, 'min_samples_split': 23, 'min_samples_leaf': 23, 'max_features': 'sqrt'}. Best is trial 19 with value: 0.6692547044006519.\n",
      "[I 2024-09-22 20:00:55,657] Trial 29 finished with value: 0.6689879982219589 and parameters: {'n_estimators': 549, 'max_depth': 44, 'min_samples_split': 24, 'min_samples_leaf': 23, 'max_features': 'sqrt'}. Best is trial 19 with value: 0.6692547044006519.\n",
      "[I 2024-09-22 20:01:15,475] Trial 30 finished with value: 0.668543487924137 and parameters: {'n_estimators': 558, 'max_depth': 46, 'min_samples_split': 29, 'min_samples_leaf': 23, 'max_features': 'sqrt'}. Best is trial 19 with value: 0.6692547044006519.\n",
      "[I 2024-09-22 20:01:38,628] Trial 31 finished with value: 0.6672099570306712 and parameters: {'n_estimators': 643, 'max_depth': 44, 'min_samples_split': 24, 'min_samples_leaf': 19, 'max_features': 'sqrt'}. Best is trial 19 with value: 0.6692547044006519.\n",
      "[I 2024-09-22 20:01:56,668] Trial 32 finished with value: 0.6670321529115425 and parameters: {'n_estimators': 507, 'max_depth': 50, 'min_samples_split': 24, 'min_samples_leaf': 22, 'max_features': 'sqrt'}. Best is trial 19 with value: 0.6692547044006519.\n",
      "[I 2024-09-22 20:02:12,841] Trial 33 finished with value: 0.6685138539042821 and parameters: {'n_estimators': 456, 'max_depth': 42, 'min_samples_split': 20, 'min_samples_leaf': 25, 'max_features': 'sqrt'}. Best is trial 19 with value: 0.6692547044006519.\n",
      "[I 2024-09-22 20:02:33,626] Trial 34 finished with value: 0.6664098384945919 and parameters: {'n_estimators': 582, 'max_depth': 37, 'min_samples_split': 24, 'min_samples_leaf': 15, 'max_features': 'sqrt'}. Best is trial 19 with value: 0.6692547044006519.\n",
      "[I 2024-09-22 20:03:54,055] Trial 35 finished with value: 0.6635353385686769 and parameters: {'n_estimators': 659, 'max_depth': 38, 'min_samples_split': 28, 'min_samples_leaf': 26, 'max_features': None}. Best is trial 19 with value: 0.6692547044006519.\n",
      "[I 2024-09-22 20:04:16,616] Trial 36 finished with value: 0.6671506889909616 and parameters: {'n_estimators': 503, 'max_depth': 47, 'min_samples_split': 18, 'min_samples_leaf': 22, 'max_features': 'sqrt'}. Best is trial 19 with value: 0.6692547044006519.\n",
      "[I 2024-09-22 20:04:49,821] Trial 37 finished with value: 0.6619943695362276 and parameters: {'n_estimators': 681, 'max_depth': 34, 'min_samples_split': 14, 'min_samples_leaf': 4, 'max_features': 'sqrt'}. Best is trial 19 with value: 0.6692547044006519.\n",
      "[I 2024-09-22 20:05:10,942] Trial 38 finished with value: 0.6681878796858796 and parameters: {'n_estimators': 616, 'max_depth': 43, 'min_samples_split': 21, 'min_samples_leaf': 24, 'max_features': 'sqrt'}. Best is trial 19 with value: 0.6692547044006519.\n",
      "[I 2024-09-22 20:06:34,221] Trial 39 finished with value: 0.6622610757149208 and parameters: {'n_estimators': 752, 'max_depth': 42, 'min_samples_split': 25, 'min_samples_leaf': 20, 'max_features': None}. Best is trial 19 with value: 0.6692547044006519.\n",
      "[I 2024-09-22 20:06:54,134] Trial 40 finished with value: 0.6660245962364794 and parameters: {'n_estimators': 571, 'max_depth': 48, 'min_samples_split': 19, 'min_samples_leaf': 16, 'max_features': 'sqrt'}. Best is trial 19 with value: 0.6692547044006519.\n",
      "[I 2024-09-22 20:07:21,903] Trial 41 finished with value: 0.6686916580234109 and parameters: {'n_estimators': 872, 'max_depth': 30, 'min_samples_split': 23, 'min_samples_leaf': 30, 'max_features': 'sqrt'}. Best is trial 19 with value: 0.6692547044006519.\n",
      "[I 2024-09-22 20:07:51,020] Trial 42 finished with value: 0.6687509260631204 and parameters: {'n_estimators': 821, 'max_depth': 24, 'min_samples_split': 22, 'min_samples_leaf': 28, 'max_features': 'sqrt'}. Best is trial 19 with value: 0.6692547044006519.\n",
      "[I 2024-09-22 20:08:07,568] Trial 43 finished with value: 0.6676544673284931 and parameters: {'n_estimators': 471, 'max_depth': 35, 'min_samples_split': 20, 'min_samples_leaf': 31, 'max_features': 'sqrt'}. Best is trial 19 with value: 0.6692547044006519.\n",
      "[I 2024-09-22 20:08:26,256] Trial 44 finished with value: 0.6672692250703808 and parameters: {'n_estimators': 738, 'max_depth': 6, 'min_samples_split': 26, 'min_samples_leaf': 26, 'max_features': 'sqrt'}. Best is trial 19 with value: 0.6692547044006519.\n",
      "[I 2024-09-22 20:08:40,091] Trial 45 finished with value: 0.6673581271299451 and parameters: {'n_estimators': 401, 'max_depth': 10, 'min_samples_split': 14, 'min_samples_leaf': 29, 'max_features': 'sqrt'}. Best is trial 19 with value: 0.6692547044006519.\n",
      "[I 2024-09-22 20:09:06,832] Trial 46 finished with value: 0.6679508075270412 and parameters: {'n_estimators': 792, 'max_depth': 28, 'min_samples_split': 21, 'min_samples_leaf': 24, 'max_features': 'sqrt'}. Best is trial 19 with value: 0.6692547044006519.\n",
      "[I 2024-09-22 20:09:41,377] Trial 47 finished with value: 0.6687509260631205 and parameters: {'n_estimators': 927, 'max_depth': 39, 'min_samples_split': 31, 'min_samples_leaf': 32, 'max_features': 'sqrt'}. Best is trial 19 with value: 0.6692547044006519.\n",
      "[I 2024-09-22 20:10:02,156] Trial 48 finished with value: 0.6667061786931396 and parameters: {'n_estimators': 514, 'max_depth': 33, 'min_samples_split': 23, 'min_samples_leaf': 22, 'max_features': 'sqrt'}. Best is trial 19 with value: 0.6692547044006519.\n",
      "[I 2024-09-22 20:10:29,915] Trial 49 finished with value: 0.6632389983701288 and parameters: {'n_estimators': 250, 'max_depth': 29, 'min_samples_split': 17, 'min_samples_leaf': 28, 'max_features': None}. Best is trial 19 with value: 0.6692547044006519.\n",
      "[I 2024-09-22 20:11:02,601] Trial 50 finished with value: 0.6685731219439917 and parameters: {'n_estimators': 842, 'max_depth': 42, 'min_samples_split': 26, 'min_samples_leaf': 30, 'max_features': 'sqrt'}. Best is trial 19 with value: 0.6692547044006519.\n",
      "[I 2024-09-22 20:11:28,160] Trial 51 finished with value: 0.6691361683212328 and parameters: {'n_estimators': 773, 'max_depth': 38, 'min_samples_split': 29, 'min_samples_leaf': 27, 'max_features': 'sqrt'}. Best is trial 19 with value: 0.6692547044006519.\n",
      "[I 2024-09-22 20:11:53,907] Trial 52 finished with value: 0.6691361683212328 and parameters: {'n_estimators': 772, 'max_depth': 36, 'min_samples_split': 28, 'min_samples_leaf': 27, 'max_features': 'sqrt'}. Best is trial 19 with value: 0.6692547044006519.\n",
      "[I 2024-09-22 20:12:16,912] Trial 53 finished with value: 0.6691065343013779 and parameters: {'n_estimators': 688, 'max_depth': 36, 'min_samples_split': 29, 'min_samples_leaf': 27, 'max_features': 'sqrt'}. Best is trial 19 with value: 0.6692547044006519.\n",
      "[I 2024-09-22 20:12:43,502] Trial 54 finished with value: 0.6676841013483479 and parameters: {'n_estimators': 781, 'max_depth': 38, 'min_samples_split': 32, 'min_samples_leaf': 25, 'max_features': 'sqrt'}. Best is trial 19 with value: 0.6692547044006519.\n",
      "[I 2024-09-22 20:13:07,047] Trial 55 finished with value: 0.6684842198844272 and parameters: {'n_estimators': 658, 'max_depth': 40, 'min_samples_split': 29, 'min_samples_leaf': 23, 'max_features': 'sqrt'}. Best is trial 19 with value: 0.6692547044006519.\n",
      "[I 2024-09-22 20:13:28,070] Trial 56 finished with value: 0.6687212920432656 and parameters: {'n_estimators': 610, 'max_depth': 36, 'min_samples_split': 28, 'min_samples_leaf': 27, 'max_features': 'sqrt'}. Best is trial 19 with value: 0.6692547044006519.\n",
      "[I 2024-09-22 20:13:48,385] Trial 57 finished with value: 0.6675062972292192 and parameters: {'n_estimators': 541, 'max_depth': 41, 'min_samples_split': 30, 'min_samples_leaf': 21, 'max_features': 'sqrt'}. Best is trial 19 with value: 0.6692547044006519.\n",
      "[I 2024-09-22 20:15:10,025] Trial 58 finished with value: 0.6631500963105645 and parameters: {'n_estimators': 680, 'max_depth': 35, 'min_samples_split': 28, 'min_samples_leaf': 28, 'max_features': None}. Best is trial 19 with value: 0.6692547044006519.\n",
      "[I 2024-09-22 20:15:40,656] Trial 59 finished with value: 0.6682471477255889 and parameters: {'n_estimators': 767, 'max_depth': 45, 'min_samples_split': 27, 'min_samples_leaf': 26, 'max_features': 'log2'}. Best is trial 19 with value: 0.6692547044006519.\n",
      "[I 2024-09-22 20:16:06,494] Trial 60 finished with value: 0.6681582456660247 and parameters: {'n_estimators': 725, 'max_depth': 38, 'min_samples_split': 31, 'min_samples_leaf': 24, 'max_features': 'sqrt'}. Best is trial 19 with value: 0.6692547044006519.\n",
      "[I 2024-09-22 20:16:30,651] Trial 61 finished with value: 0.6691658023410876 and parameters: {'n_estimators': 693, 'max_depth': 33, 'min_samples_split': 25, 'min_samples_leaf': 27, 'max_features': 'sqrt'}. Best is trial 19 with value: 0.6692547044006519.\n",
      "[I 2024-09-22 20:16:55,965] Trial 62 finished with value: 0.6674470291895096 and parameters: {'n_estimators': 693, 'max_depth': 32, 'min_samples_split': 25, 'min_samples_leaf': 25, 'max_features': 'sqrt'}. Best is trial 19 with value: 0.6692547044006519.\n",
      "[I 2024-09-22 20:17:24,327] Trial 63 finished with value: 0.668365683805008 and parameters: {'n_estimators': 837, 'max_depth': 36, 'min_samples_split': 25, 'min_samples_leaf': 29, 'max_features': 'sqrt'}. Best is trial 19 with value: 0.6692547044006519.\n",
      "[I 2024-09-22 20:17:47,171] Trial 64 finished with value: 0.6685731219439918 and parameters: {'n_estimators': 612, 'max_depth': 33, 'min_samples_split': 29, 'min_samples_leaf': 27, 'max_features': 'sqrt'}. Best is trial 19 with value: 0.6692547044006519.\n",
      "[I 2024-09-22 20:18:07,492] Trial 65 finished with value: 0.6672099570306712 and parameters: {'n_estimators': 544, 'max_depth': 39, 'min_samples_split': 27, 'min_samples_leaf': 31, 'max_features': 'sqrt'}. Best is trial 19 with value: 0.6692547044006519.\n",
      "[I 2024-09-22 20:18:28,301] Trial 66 finished with value: 0.6688694621425396 and parameters: {'n_estimators': 475, 'max_depth': 43, 'min_samples_split': 23, 'min_samples_leaf': 23, 'max_features': 'sqrt'}. Best is trial 19 with value: 0.6692547044006519.\n",
      "[I 2024-09-22 20:18:44,031] Trial 67 finished with value: 0.6689879982219589 and parameters: {'n_estimators': 428, 'max_depth': 36, 'min_samples_split': 30, 'min_samples_leaf': 28, 'max_features': 'sqrt'}. Best is trial 19 with value: 0.6692547044006519.\n",
      "[I 2024-09-22 20:19:11,774] Trial 68 finished with value: 0.6666172766335754 and parameters: {'n_estimators': 732, 'max_depth': 27, 'min_samples_split': 26, 'min_samples_leaf': 19, 'max_features': 'log2'}. Best is trial 19 with value: 0.6692547044006519.\n",
      "[I 2024-09-22 20:19:36,203] Trial 69 finished with value: 0.6681582456660247 and parameters: {'n_estimators': 654, 'max_depth': 46, 'min_samples_split': 31, 'min_samples_leaf': 26, 'max_features': 'sqrt'}. Best is trial 19 with value: 0.6692547044006519.\n",
      "[I 2024-09-22 20:19:59,574] Trial 70 finished with value: 0.6640094828863536 and parameters: {'n_estimators': 586, 'max_depth': 41, 'min_samples_split': 27, 'min_samples_leaf': 11, 'max_features': 'sqrt'}. Best is trial 19 with value: 0.6692547044006519.\n",
      "[I 2024-09-22 20:20:16,708] Trial 71 finished with value: 0.6689879982219588 and parameters: {'n_estimators': 446, 'max_depth': 36, 'min_samples_split': 30, 'min_samples_leaf': 28, 'max_features': 'sqrt'}. Best is trial 19 with value: 0.6692547044006519.\n",
      "[I 2024-09-22 20:20:28,555] Trial 72 finished with value: 0.6670321529115425 and parameters: {'n_estimators': 352, 'max_depth': 34, 'min_samples_split': 29, 'min_samples_leaf': 29, 'max_features': 'sqrt'}. Best is trial 19 with value: 0.6692547044006519.\n",
      "[I 2024-09-22 20:20:57,257] Trial 73 finished with value: 0.6676841013483479 and parameters: {'n_estimators': 680, 'max_depth': 37, 'min_samples_split': 32, 'min_samples_leaf': 25, 'max_features': 'sqrt'}. Best is trial 19 with value: 0.6692547044006519.\n",
      "[I 2024-09-22 20:21:21,999] Trial 74 finished with value: 0.6693732404800711 and parameters: {'n_estimators': 631, 'max_depth': 31, 'min_samples_split': 28, 'min_samples_leaf': 27, 'max_features': 'sqrt'}. Best is trial 74 with value: 0.6693732404800711.\n",
      "[I 2024-09-22 20:21:43,537] Trial 75 finished with value: 0.6691361683212327 and parameters: {'n_estimators': 633, 'max_depth': 32, 'min_samples_split': 25, 'min_samples_leaf': 27, 'max_features': 'sqrt'}. Best is trial 74 with value: 0.6693732404800711.\n",
      "[I 2024-09-22 20:22:03,744] Trial 76 finished with value: 0.6691954363609425 and parameters: {'n_estimators': 630, 'max_depth': 31, 'min_samples_split': 25, 'min_samples_leaf': 27, 'max_features': 'sqrt'}. Best is trial 74 with value: 0.6693732404800711.\n",
      "[I 2024-09-22 20:23:18,202] Trial 77 finished with value: 0.6646614313231589 and parameters: {'n_estimators': 638, 'max_depth': 31, 'min_samples_split': 25, 'min_samples_leaf': 31, 'max_features': None}. Best is trial 74 with value: 0.6693732404800711.\n",
      "[I 2024-09-22 20:23:44,270] Trial 78 finished with value: 0.6676544673284931 and parameters: {'n_estimators': 626, 'max_depth': 23, 'min_samples_split': 5, 'min_samples_leaf': 26, 'max_features': 'sqrt'}. Best is trial 74 with value: 0.6693732404800711.\n",
      "[I 2024-09-22 20:24:08,233] Trial 79 finished with value: 0.6690769002815231 and parameters: {'n_estimators': 712, 'max_depth': 30, 'min_samples_split': 23, 'min_samples_leaf': 27, 'max_features': 'sqrt'}. Best is trial 74 with value: 0.6693732404800711.\n",
      "[I 2024-09-22 20:24:34,296] Trial 80 finished with value: 0.6685138539042821 and parameters: {'n_estimators': 761, 'max_depth': 26, 'min_samples_split': 28, 'min_samples_leaf': 30, 'max_features': 'log2'}. Best is trial 74 with value: 0.6693732404800711.\n",
      "[I 2024-09-22 20:24:38,747] Trial 81 finished with value: 0.6671210549711069 and parameters: {'n_estimators': 109, 'max_depth': 32, 'min_samples_split': 26, 'min_samples_leaf': 27, 'max_features': 'sqrt'}. Best is trial 74 with value: 0.6693732404800711.\n",
      "[I 2024-09-22 20:25:01,059] Trial 82 finished with value: 0.668691658023411 and parameters: {'n_estimators': 667, 'max_depth': 29, 'min_samples_split': 28, 'min_samples_leaf': 29, 'max_features': 'sqrt'}. Best is trial 74 with value: 0.6693732404800711.\n",
      "[I 2024-09-22 20:25:24,269] Trial 83 finished with value: 0.6682471477255889 and parameters: {'n_estimators': 705, 'max_depth': 34, 'min_samples_split': 25, 'min_samples_leaf': 26, 'max_features': 'sqrt'}. Best is trial 74 with value: 0.6693732404800711.\n",
      "[I 2024-09-22 20:25:44,831] Trial 84 finished with value: 0.6680100755667506 and parameters: {'n_estimators': 592, 'max_depth': 33, 'min_samples_split': 21, 'min_samples_leaf': 24, 'max_features': 'sqrt'}. Best is trial 74 with value: 0.6693732404800711.\n",
      "[I 2024-09-22 20:26:14,563] Trial 85 finished with value: 0.6688694621425396 and parameters: {'n_estimators': 804, 'max_depth': 31, 'min_samples_split': 27, 'min_samples_leaf': 27, 'max_features': 'sqrt'}. Best is trial 74 with value: 0.6693732404800711.\n",
      "[I 2024-09-22 20:26:41,245] Trial 86 finished with value: 0.6678915394873315 and parameters: {'n_estimators': 734, 'max_depth': 29, 'min_samples_split': 24, 'min_samples_leaf': 25, 'max_features': 'sqrt'}. Best is trial 74 with value: 0.6693732404800711.\n",
      "[I 2024-09-22 20:27:02,483] Trial 87 finished with value: 0.6691954363609425 and parameters: {'n_estimators': 641, 'max_depth': 32, 'min_samples_split': 26, 'min_samples_leaf': 32, 'max_features': 'sqrt'}. Best is trial 74 with value: 0.6693732404800711.\n",
      "[I 2024-09-22 20:27:23,985] Trial 88 finished with value: 0.6684842198844272 and parameters: {'n_estimators': 565, 'max_depth': 32, 'min_samples_split': 24, 'min_samples_leaf': 32, 'max_features': 'sqrt'}. Best is trial 74 with value: 0.6693732404800711.\n",
      "[I 2024-09-22 20:27:45,919] Trial 89 finished with value: 0.6686916580234109 and parameters: {'n_estimators': 628, 'max_depth': 27, 'min_samples_split': 22, 'min_samples_leaf': 30, 'max_features': 'sqrt'}. Best is trial 74 with value: 0.6693732404800711.\n",
      "[I 2024-09-22 20:28:11,731] Trial 90 finished with value: 0.6685434879241369 and parameters: {'n_estimators': 776, 'max_depth': 34, 'min_samples_split': 26, 'min_samples_leaf': 29, 'max_features': 'sqrt'}. Best is trial 74 with value: 0.6693732404800711.\n",
      "[I 2024-09-22 20:28:35,373] Trial 91 finished with value: 0.6693139724403615 and parameters: {'n_estimators': 695, 'max_depth': 30, 'min_samples_split': 28, 'min_samples_leaf': 28, 'max_features': 'sqrt'}. Best is trial 74 with value: 0.6693732404800711.\n",
      "[I 2024-09-22 20:28:59,509] Trial 92 finished with value: 0.6674173951696547 and parameters: {'n_estimators': 749, 'max_depth': 29, 'min_samples_split': 28, 'min_samples_leaf': 31, 'max_features': 'sqrt'}. Best is trial 74 with value: 0.6693732404800711.\n",
      "[I 2024-09-22 20:29:23,302] Trial 93 finished with value: 0.6690176322418135 and parameters: {'n_estimators': 668, 'max_depth': 30, 'min_samples_split': 27, 'min_samples_leaf': 28, 'max_features': 'sqrt'}. Best is trial 74 with value: 0.6693732404800711.\n",
      "[I 2024-09-22 20:29:43,575] Trial 94 finished with value: 0.6677137353682027 and parameters: {'n_estimators': 598, 'max_depth': 33, 'min_samples_split': 25, 'min_samples_leaf': 25, 'max_features': 'sqrt'}. Best is trial 74 with value: 0.6693732404800711.\n",
      "[I 2024-09-22 20:30:04,659] Trial 95 finished with value: 0.6690472662616683 and parameters: {'n_estimators': 639, 'max_depth': 31, 'min_samples_split': 26, 'min_samples_leaf': 28, 'max_features': 'sqrt'}. Best is trial 74 with value: 0.6693732404800711.\n",
      "[I 2024-09-22 20:31:19,167] Trial 96 finished with value: 0.6635649725885316 and parameters: {'n_estimators': 700, 'max_depth': 26, 'min_samples_split': 24, 'min_samples_leaf': 30, 'max_features': None}. Best is trial 74 with value: 0.6693732404800711.\n",
      "[I 2024-09-22 20:31:46,941] Trial 97 finished with value: 0.6647206993628686 and parameters: {'n_estimators': 652, 'max_depth': 35, 'min_samples_split': 23, 'min_samples_leaf': 5, 'max_features': 'sqrt'}. Best is trial 74 with value: 0.6693732404800711.\n",
      "[I 2024-09-22 20:32:04,362] Trial 98 finished with value: 0.6686027559638464 and parameters: {'n_estimators': 529, 'max_depth': 28, 'min_samples_split': 28, 'min_samples_leaf': 26, 'max_features': 'sqrt'}. Best is trial 74 with value: 0.6693732404800711.\n",
      "[I 2024-09-22 20:32:24,180] Trial 99 finished with value: 0.6678619054674767 and parameters: {'n_estimators': 570, 'max_depth': 32, 'min_samples_split': 26, 'min_samples_leaf': 24, 'max_features': 'sqrt'}. Best is trial 74 with value: 0.6693732404800711.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Reduced Features Optuna Tuned\n",
      "Best params: {'n_estimators': 631, 'max_depth': 31, 'min_samples_split': 28, 'min_samples_leaf': 27, 'max_features': 'sqrt'}\n",
      "Best score: 0.6693732404800711\n"
     ]
    }
   ],
   "source": [
    "# Tuning\n",
    "rf_reduced_params, rf_reduced_best_score = tune_rf(X_train_selected, y_train, tscv, \"accuracy\", RANDOM_SEED)\n",
    "\n",
    "print(\"Random Forest Reduced Features Optuna Tuned\")\n",
    "print(\"Best params:\", rf_reduced_params)\n",
    "print(\"Best score:\", rf_reduced_best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Reduced Features Optuna Tuned\n",
      "accuracy: 0.6693732404800711\n",
      "precision: 0.6671145541622379\n",
      "recall: 0.6765644558607213\n",
      "f1: 0.671629370190142\n",
      "roc_auc: 0.7384522075127884\n"
     ]
    }
   ],
   "source": [
    "rf_reduced_tuned = RandomForestClassifier(random_state=RANDOM_SEED, n_jobs=-1, **rf_reduced_params)\n",
    "\n",
    "print(\"Random Forest Reduced Features Optuna Tuned\")\n",
    "rf_reduced_tuned.fit(X_train_selected, y_train)\n",
    "\n",
    "# Cross validation\n",
    "rf_reduced_tuned_scores = cross_validate(rf_reduced_tuned, X_train_selected, y_train, cv=tscv, scoring=SCORING)\n",
    "\n",
    "for metric in SCORING:\n",
    "    print(f\"{metric}: {rf_reduced_tuned_scores[f'test_{metric}'].mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Reduced Features Tuned Test Set\n",
      "Accuracy: 0.5986172839506173\n",
      "Precision: 0.6002810680586228\n",
      "Recall: 0.5905589571400356\n",
      "F1: 0.5953803265631222\n",
      "ROC-AUC: 0.640996712852277\n"
     ]
    }
   ],
   "source": [
    "# Test set evaluation\n",
    "print(\"Random Forest Reduced Features Tuned Test Set\")\n",
    "evaluate_test_set(rf_reduced_tuned, X_test_selected, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-22 20:36:35,027] A new study created in memory with name: no-name-7dd002d7-b2ec-4b0d-8bda-4502802a3ebf\n",
      "[I 2024-09-22 20:37:13,061] Trial 0 finished with value: 0.650466735812713 and parameters: {'n_estimators': 982, 'learning_rate': 0.019921122083847005, 'max_depth': 16, 'subsample': 0.604644832479114, 'colsample_bytree': 0.7020619949126894, 'gamma': 1.2492983189755962, 'reg_alpha': 0.0009213098010957778, 'reg_lambda': 1.4904755384045978}. Best is trial 0 with value: 0.650466735812713.\n",
      "[I 2024-09-22 20:37:22,145] Trial 1 finished with value: 0.6630315602311454 and parameters: {'n_estimators': 260, 'learning_rate': 0.013502952210469868, 'max_depth': 16, 'subsample': 0.8033270116723275, 'colsample_bytree': 0.7276119207689231, 'gamma': 3.803772978577647, 'reg_alpha': 0.17730451060219618, 'reg_lambda': 3.1414577964353056}. Best is trial 1 with value: 0.6630315602311454.\n",
      "[I 2024-09-22 20:37:32,769] Trial 2 finished with value: 0.662231441695066 and parameters: {'n_estimators': 292, 'learning_rate': 0.015153792918016476, 'max_depth': 17, 'subsample': 0.6929464095089721, 'colsample_bytree': 0.7513008620374133, 'gamma': 4.411354674462903, 'reg_alpha': 0.00019356409833735832, 'reg_lambda': 1.358195830973057e-05}. Best is trial 1 with value: 0.6630315602311454.\n",
      "[I 2024-09-22 20:37:42,446] Trial 3 finished with value: 0.6635946066083864 and parameters: {'n_estimators': 887, 'learning_rate': 0.007986992117298843, 'max_depth': 5, 'subsample': 0.9319463710421476, 'colsample_bytree': 0.509314784587674, 'gamma': 0.5262930477948491, 'reg_alpha': 0.8688849523372999, 'reg_lambda': 1.0171805334109039}. Best is trial 3 with value: 0.6635946066083864.\n",
      "[I 2024-09-22 20:38:35,222] Trial 4 finished with value: 0.6553267150688992 and parameters: {'n_estimators': 520, 'learning_rate': 0.0041936499358030685, 'max_depth': 13, 'subsample': 0.9943749389902277, 'colsample_bytree': 0.9334264331592369, 'gamma': 2.3758651712308705, 'reg_alpha': 0.00218940641880716, 'reg_lambda': 1.3787276501590686}. Best is trial 3 with value: 0.6635946066083864.\n",
      "[I 2024-09-22 20:38:40,581] Trial 5 finished with value: 0.6665876426137205 and parameters: {'n_estimators': 682, 'learning_rate': 0.0036658826684779775, 'max_depth': 3, 'subsample': 0.7765830156602674, 'colsample_bytree': 0.40117073778357165, 'gamma': 0.43679388319997126, 'reg_alpha': 0.00010692049961301201, 'reg_lambda': 0.011235379248509647}. Best is trial 5 with value: 0.6665876426137205.\n",
      "[I 2024-09-22 20:39:44,243] Trial 6 finished with value: 0.6632982664098386 and parameters: {'n_estimators': 644, 'learning_rate': 0.0015716596679575122, 'max_depth': 12, 'subsample': 0.6074132751088279, 'colsample_bytree': 0.4954185036632889, 'gamma': 1.0288214905591075, 'reg_alpha': 0.2568378831199201, 'reg_lambda': 0.0011263847543904022}. Best is trial 5 with value: 0.6665876426137205.\n",
      "[I 2024-09-22 20:40:21,551] Trial 7 finished with value: 0.6638316787672248 and parameters: {'n_estimators': 884, 'learning_rate': 0.0010924308932831837, 'max_depth': 10, 'subsample': 0.998836766392572, 'colsample_bytree': 0.5955559392966842, 'gamma': 4.355393198880277, 'reg_alpha': 0.2492330136791201, 'reg_lambda': 0.0002685595032460751}. Best is trial 5 with value: 0.6665876426137205.\n",
      "[I 2024-09-22 20:41:31,524] Trial 8 finished with value: 0.6545265965328196 and parameters: {'n_estimators': 472, 'learning_rate': 0.005268729431522292, 'max_depth': 12, 'subsample': 0.9731551209597216, 'colsample_bytree': 0.5956572324383335, 'gamma': 0.14055426102197288, 'reg_alpha': 2.8670893717005388e-05, 'reg_lambda': 0.025379611210257055}. Best is trial 5 with value: 0.6665876426137205.\n",
      "[I 2024-09-22 20:41:34,965] Trial 9 finished with value: 0.6646910653430137 and parameters: {'n_estimators': 213, 'learning_rate': 0.0038429417787668356, 'max_depth': 6, 'subsample': 0.6640150818358594, 'colsample_bytree': 0.8078197426247198, 'gamma': 1.692121673758048, 'reg_alpha': 8.161500025796851, 'reg_lambda': 5.8645877802949684e-05}. Best is trial 5 with value: 0.6665876426137205.\n",
      "[I 2024-09-22 20:41:39,040] Trial 10 finished with value: 0.6536672099570306 and parameters: {'n_estimators': 698, 'learning_rate': 0.08672139669618005, 'max_depth': 8, 'subsample': 0.8144859447000079, 'colsample_bytree': 0.45158560559491906, 'gamma': 3.0676674775915047, 'reg_alpha': 1.2539671185969796e-05, 'reg_lambda': 0.031999875157689706}. Best is trial 5 with value: 0.6665876426137205.\n",
      "[I 2024-09-22 20:41:40,438] Trial 11 finished with value: 0.6500518595347459 and parameters: {'n_estimators': 132, 'learning_rate': 0.002544178546086259, 'max_depth': 3, 'subsample': 0.5156185358180249, 'colsample_bytree': 0.8668785313043456, 'gamma': 1.9316634967022572, 'reg_alpha': 8.380151100240502, 'reg_lambda': 1.0904031070650978e-05}. Best is trial 5 with value: 0.6665876426137205.\n",
      "[I 2024-09-22 20:41:47,833] Trial 12 finished with value: 0.6651355756408357 and parameters: {'n_estimators': 384, 'learning_rate': 0.002874145959041178, 'max_depth': 6, 'subsample': 0.7317342374657556, 'colsample_bytree': 0.8193980525871746, 'gamma': 1.5497426142692459, 'reg_alpha': 0.012647610368973064, 'reg_lambda': 0.0021052634246451723}. Best is trial 5 with value: 0.6665876426137205.\n",
      "[I 2024-09-22 20:41:51,371] Trial 13 finished with value: 0.6539635501555786 and parameters: {'n_estimators': 396, 'learning_rate': 0.0020572743441740603, 'max_depth': 3, 'subsample': 0.8618961737477943, 'colsample_bytree': 0.9935499397269645, 'gamma': 0.7891671282439792, 'reg_alpha': 0.01312207707235815, 'reg_lambda': 0.0022386919460539137}. Best is trial 5 with value: 0.6665876426137205.\n",
      "[I 2024-09-22 20:42:05,857] Trial 14 finished with value: 0.6489257667802637 and parameters: {'n_estimators': 690, 'learning_rate': 0.035832388093225184, 'max_depth': 7, 'subsample': 0.7485382118727383, 'colsample_bytree': 0.40424695745779515, 'gamma': 0.05025466486258834, 'reg_alpha': 0.023878350123963905, 'reg_lambda': 0.1178163647043844}. Best is trial 5 with value: 0.6665876426137205.\n",
      "[I 2024-09-22 20:42:20,282] Trial 15 finished with value: 0.662498147873759 and parameters: {'n_estimators': 389, 'learning_rate': 0.007256543313626921, 'max_depth': 9, 'subsample': 0.7496481279323524, 'colsample_bytree': 0.595335496151139, 'gamma': 2.69391018474212, 'reg_alpha': 0.0001853547950128899, 'reg_lambda': 0.0033776243193374706}. Best is trial 5 with value: 0.6665876426137205.\n",
      "[I 2024-09-22 20:42:27,928] Trial 16 finished with value: 0.663950214846644 and parameters: {'n_estimators': 608, 'learning_rate': 0.003149108881385037, 'max_depth': 5, 'subsample': 0.8815277447272357, 'colsample_bytree': 0.8339040710823761, 'gamma': 1.5250827189914484, 'reg_alpha': 0.0031660395402732374, 'reg_lambda': 0.00029885869381523263}. Best is trial 5 with value: 0.6665876426137205.\n",
      "[I 2024-09-22 20:44:59,670] Trial 17 finished with value: 0.6555934212475922 and parameters: {'n_estimators': 791, 'learning_rate': 0.0012722376887928809, 'max_depth': 20, 'subsample': 0.6947553773967916, 'colsample_bytree': 0.8734924588152053, 'gamma': 2.0642969214930327, 'reg_alpha': 0.00026297592614972504, 'reg_lambda': 0.20768035812978505}. Best is trial 5 with value: 0.6665876426137205.\n",
      "[I 2024-09-22 20:45:03,159] Trial 18 finished with value: 0.6652244777004 and parameters: {'n_estimators': 410, 'learning_rate': 0.00605639827154752, 'max_depth': 3, 'subsample': 0.7942758043228105, 'colsample_bytree': 0.6405407346620574, 'gamma': 3.1630897804675078, 'reg_alpha': 0.04005110358142034, 'reg_lambda': 0.00709540062116486}. Best is trial 5 with value: 0.6665876426137205.\n",
      "[I 2024-09-22 20:45:07,509] Trial 19 finished with value: 0.6643354571047564 and parameters: {'n_estimators': 556, 'learning_rate': 0.031574658831157204, 'max_depth': 3, 'subsample': 0.8172612122490696, 'colsample_bytree': 0.6452901020239931, 'gamma': 3.6016859509540065, 'reg_alpha': 0.045488659004602326, 'reg_lambda': 0.012067968463140831}. Best is trial 5 with value: 0.6665876426137205.\n",
      "[I 2024-09-22 20:45:19,470] Trial 20 finished with value: 0.6650170395614166 and parameters: {'n_estimators': 778, 'learning_rate': 0.006679160998000512, 'max_depth': 10, 'subsample': 0.8999507407617557, 'colsample_bytree': 0.5030374514214315, 'gamma': 4.915987639055697, 'reg_alpha': 3.899965034436643e-05, 'reg_lambda': 0.1593730249276525}. Best is trial 5 with value: 0.6665876426137205.\n",
      "[I 2024-09-22 20:45:24,619] Trial 21 finished with value: 0.663653874648096 and parameters: {'n_estimators': 390, 'learning_rate': 0.0022439178130085335, 'max_depth': 5, 'subsample': 0.7813522853767494, 'colsample_bytree': 0.7794150209137108, 'gamma': 2.889439288503694, 'reg_alpha': 0.00703933850692315, 'reg_lambda': 0.0063669360931142525}. Best is trial 5 with value: 0.6665876426137205.\n",
      "[I 2024-09-22 20:45:29,547] Trial 22 finished with value: 0.6654615498592384 and parameters: {'n_estimators': 451, 'learning_rate': 0.004756711410135854, 'max_depth': 4, 'subsample': 0.7335163989155938, 'colsample_bytree': 0.6778651756345433, 'gamma': 3.2935696680731175, 'reg_alpha': 0.05650879924899724, 'reg_lambda': 0.0007957189164115383}. Best is trial 5 with value: 0.6665876426137205.\n",
      "[I 2024-09-22 20:45:35,757] Trial 23 finished with value: 0.6652837457401096 and parameters: {'n_estimators': 481, 'learning_rate': 0.010875439684594899, 'max_depth': 4, 'subsample': 0.8345950792307519, 'colsample_bytree': 0.6634054644306444, 'gamma': 3.2496097342104444, 'reg_alpha': 0.05999408466518106, 'reg_lambda': 0.0004114665966850484}. Best is trial 5 with value: 0.6665876426137205.\n",
      "[I 2024-09-22 20:45:40,889] Trial 24 finished with value: 0.6652837457401096 and parameters: {'n_estimators': 496, 'learning_rate': 0.010511445226754124, 'max_depth': 4, 'subsample': 0.8487203677532653, 'colsample_bytree': 0.6552728048074027, 'gamma': 3.6045729534156967, 'reg_alpha': 0.09235598807184546, 'reg_lambda': 0.0005592188282824522}. Best is trial 5 with value: 0.6665876426137205.\n",
      "[I 2024-09-22 20:45:51,841] Trial 25 finished with value: 0.6614016891391318 and parameters: {'n_estimators': 612, 'learning_rate': 0.010780646479402018, 'max_depth': 7, 'subsample': 0.6417666560666859, 'colsample_bytree': 0.5522737661114115, 'gamma': 2.491842951019863, 'reg_alpha': 0.8496621496367865, 'reg_lambda': 0.00014267076776697108}. Best is trial 5 with value: 0.6665876426137205.\n",
      "[I 2024-09-22 20:45:55,613] Trial 26 finished with value: 0.6656393539783672 and parameters: {'n_estimators': 307, 'learning_rate': 0.025098147459179702, 'max_depth': 7, 'subsample': 0.7134073227395998, 'colsample_bytree': 0.4194223329023768, 'gamma': 4.021469302770476, 'reg_alpha': 0.7126896470386613, 'reg_lambda': 4.706122534742753e-05}. Best is trial 5 with value: 0.6665876426137205.\n",
      "[I 2024-09-22 20:45:58,194] Trial 27 finished with value: 0.6645725292635946 and parameters: {'n_estimators': 297, 'learning_rate': 0.06112734661449443, 'max_depth': 8, 'subsample': 0.7088531308948302, 'colsample_bytree': 0.41045545375820025, 'gamma': 4.064149146460775, 'reg_alpha': 1.651478265602932, 'reg_lambda': 3.199878177225437e-05}. Best is trial 5 with value: 0.6665876426137205.\n",
      "[I 2024-09-22 20:46:00,491] Trial 28 finished with value: 0.6656393539783672 and parameters: {'n_estimators': 144, 'learning_rate': 0.026699469791483414, 'max_depth': 6, 'subsample': 0.5460460032482495, 'colsample_bytree': 0.4497099223430592, 'gamma': 3.4541875446218726, 'reg_alpha': 1.1336364904281384, 'reg_lambda': 7.743624789183303e-05}. Best is trial 5 with value: 0.6665876426137205.\n",
      "[I 2024-09-22 20:46:02,622] Trial 29 finished with value: 0.667535931249074 and parameters: {'n_estimators': 161, 'learning_rate': 0.023637232110549508, 'max_depth': 10, 'subsample': 0.5123782849166352, 'colsample_bytree': 0.4601014227238866, 'gamma': 4.908678350289863, 'reg_alpha': 2.8404901856482785, 'reg_lambda': 5.5941183332297184e-05}. Best is trial 29 with value: 0.667535931249074.\n",
      "[I 2024-09-22 20:46:04,133] Trial 30 finished with value: 0.6681582456660246 and parameters: {'n_estimators': 101, 'learning_rate': 0.022737220766732798, 'max_depth': 14, 'subsample': 0.5900308522212518, 'colsample_bytree': 0.46035824990725305, 'gamma': 4.753661168175376, 'reg_alpha': 2.902996145405512, 'reg_lambda': 4.093513728690933e-05}. Best is trial 30 with value: 0.6681582456660246.\n",
      "[I 2024-09-22 20:46:05,904] Trial 31 finished with value: 0.6678322714476219 and parameters: {'n_estimators': 105, 'learning_rate': 0.02215352127768368, 'max_depth': 14, 'subsample': 0.564425819672875, 'colsample_bytree': 0.4491483492118356, 'gamma': 4.926557406352502, 'reg_alpha': 3.1809052231538772, 'reg_lambda': 3.34404743017675e-05}. Best is trial 30 with value: 0.6681582456660246.\n",
      "[I 2024-09-22 20:46:08,397] Trial 32 finished with value: 0.6683064157652986 and parameters: {'n_estimators': 183, 'learning_rate': 0.018572182900897728, 'max_depth': 14, 'subsample': 0.5598039779061428, 'colsample_bytree': 0.46323445091836185, 'gamma': 4.999765243514014, 'reg_alpha': 3.1118248249265634, 'reg_lambda': 2.0842578151693984e-05}. Best is trial 32 with value: 0.6683064157652986.\n",
      "[I 2024-09-22 20:46:10,093] Trial 33 finished with value: 0.6670321529115425 and parameters: {'n_estimators': 101, 'learning_rate': 0.015700636542135868, 'max_depth': 14, 'subsample': 0.5747718371220734, 'colsample_bytree': 0.5426095472543954, 'gamma': 4.987455725403955, 'reg_alpha': 2.9763275984718844, 'reg_lambda': 2.3865607291245845e-05}. Best is trial 32 with value: 0.6683064157652986.\n",
      "[I 2024-09-22 20:46:12,122] Trial 34 finished with value: 0.6671506889909616 and parameters: {'n_estimators': 205, 'learning_rate': 0.04374691529316691, 'max_depth': 15, 'subsample': 0.50685548406218, 'colsample_bytree': 0.4773964017789899, 'gamma': 4.606811511842331, 'reg_alpha': 3.961741388151237, 'reg_lambda': 0.00011029840975047709}. Best is trial 32 with value: 0.6683064157652986.\n",
      "[I 2024-09-22 20:46:16,223] Trial 35 finished with value: 0.6667358127129945 and parameters: {'n_estimators': 195, 'learning_rate': 0.018960414436399915, 'max_depth': 17, 'subsample': 0.585224085926192, 'colsample_bytree': 0.5406599811195787, 'gamma': 4.621819778585226, 'reg_alpha': 0.41878589526092286, 'reg_lambda': 2.153286722484397e-05}. Best is trial 32 with value: 0.6683064157652986.\n",
      "[I 2024-09-22 20:46:19,034] Trial 36 finished with value: 0.667091420951252 and parameters: {'n_estimators': 236, 'learning_rate': 0.01947044428805572, 'max_depth': 14, 'subsample': 0.5435116998942314, 'colsample_bytree': 0.45600673718977613, 'gamma': 4.368306122988906, 'reg_alpha': 2.6800711590536928, 'reg_lambda': 0.0001673681006738815}. Best is trial 32 with value: 0.6683064157652986.\n",
      "[I 2024-09-22 20:46:20,663] Trial 37 finished with value: 0.6686027559638464 and parameters: {'n_estimators': 155, 'learning_rate': 0.04386628163107259, 'max_depth': 18, 'subsample': 0.6261488237076447, 'colsample_bytree': 0.5180947766829549, 'gamma': 4.748690220732907, 'reg_alpha': 4.574191307954041, 'reg_lambda': 1.2911305179147854e-05}. Best is trial 37 with value: 0.6686027559638464.\n",
      "[I 2024-09-22 20:46:22,809] Trial 38 finished with value: 0.6682767817454438 and parameters: {'n_estimators': 280, 'learning_rate': 0.048350035355098596, 'max_depth': 19, 'subsample': 0.6239910578264398, 'colsample_bytree': 0.5246072868918131, 'gamma': 4.127625990724724, 'reg_alpha': 5.604890004915777, 'reg_lambda': 1.3415833151690378e-05}. Best is trial 37 with value: 0.6686027559638464.\n",
      "[I 2024-09-22 20:46:25,522] Trial 39 finished with value: 0.6638613127870795 and parameters: {'n_estimators': 269, 'learning_rate': 0.05167463214116283, 'max_depth': 19, 'subsample': 0.6229738012504261, 'colsample_bytree': 0.5661481368317024, 'gamma': 4.009309266552041, 'reg_alpha': 0.429889211373349, 'reg_lambda': 7.0535083024372325}. Best is trial 37 with value: 0.6686027559638464.\n",
      "[I 2024-09-22 20:46:28,407] Trial 40 finished with value: 0.6575196325381538 and parameters: {'n_estimators': 329, 'learning_rate': 0.07221767776237889, 'max_depth': 17, 'subsample': 0.6620167571630726, 'colsample_bytree': 0.5170572514967968, 'gamma': 4.608863709167555, 'reg_alpha': 0.1343142551798875, 'reg_lambda': 1.1189457702194834e-05}. Best is trial 37 with value: 0.6686027559638464.\n",
      "[I 2024-09-22 20:46:30,149] Trial 41 finished with value: 0.6677730034079122 and parameters: {'n_estimators': 171, 'learning_rate': 0.040122371345692846, 'max_depth': 18, 'subsample': 0.5751098630404566, 'colsample_bytree': 0.48442929172292043, 'gamma': 4.258408184074584, 'reg_alpha': 5.7594462326629765, 'reg_lambda': 2.3422713222462745e-05}. Best is trial 37 with value: 0.6686027559638464.\n",
      "[I 2024-09-22 20:46:31,429] Trial 42 finished with value: 0.6683064157652986 and parameters: {'n_estimators': 108, 'learning_rate': 0.03153949531953387, 'max_depth': 15, 'subsample': 0.60540188119698, 'colsample_bytree': 0.5202190930360138, 'gamma': 4.721364221194263, 'reg_alpha': 9.840874910938767, 'reg_lambda': 1.775718761294314e-05}. Best is trial 37 with value: 0.6686027559638464.\n",
      "[I 2024-09-22 20:46:33,672] Trial 43 finished with value: 0.6677730034079123 and parameters: {'n_estimators': 236, 'learning_rate': 0.03125405239632215, 'max_depth': 16, 'subsample': 0.6137144296920125, 'colsample_bytree': 0.5268295633784202, 'gamma': 4.69085529743642, 'reg_alpha': 5.753843905442475, 'reg_lambda': 1.1429542241268817e-05}. Best is trial 37 with value: 0.6686027559638464.\n",
      "[I 2024-09-22 20:46:36,187] Trial 44 finished with value: 0.6610164468810193 and parameters: {'n_estimators': 172, 'learning_rate': 0.052736626890880114, 'max_depth': 15, 'subsample': 0.6415536395721912, 'colsample_bytree': 0.575580485335945, 'gamma': 3.8482072353438, 'reg_alpha': 1.4172795025478298, 'reg_lambda': 1.7595345485183885e-05}. Best is trial 37 with value: 0.6686027559638464.\n",
      "[I 2024-09-22 20:46:38,121] Trial 45 finished with value: 0.6676248333086383 and parameters: {'n_estimators': 132, 'learning_rate': 0.014289343225678852, 'max_depth': 20, 'subsample': 0.5947154508843321, 'colsample_bytree': 0.6181731723146261, 'gamma': 4.212964638258402, 'reg_alpha': 6.958901651507025, 'reg_lambda': 9.22230843796248e-05}. Best is trial 37 with value: 0.6686027559638464.\n",
      "[I 2024-09-22 20:46:40,270] Trial 46 finished with value: 0.6680100755667506 and parameters: {'n_estimators': 347, 'learning_rate': 0.08281508467667877, 'max_depth': 18, 'subsample': 0.5356287879409412, 'colsample_bytree': 0.7404936262074333, 'gamma': 4.492172901502829, 'reg_alpha': 9.002524395226889, 'reg_lambda': 4.370858998526406e-05}. Best is trial 37 with value: 0.6686027559638464.\n",
      "[I 2024-09-22 20:46:43,725] Trial 47 finished with value: 0.6660542302563343 and parameters: {'n_estimators': 251, 'learning_rate': 0.016830930058055627, 'max_depth': 13, 'subsample': 0.6337762430548984, 'colsample_bytree': 0.5002355825716261, 'gamma': 4.753288043738437, 'reg_alpha': 1.7348331286685903, 'reg_lambda': 0.00019089731341414271}. Best is trial 37 with value: 0.6686027559638464.\n",
      "[I 2024-09-22 20:46:46,267] Trial 48 finished with value: 0.6635649725885316 and parameters: {'n_estimators': 103, 'learning_rate': 0.03151648555294416, 'max_depth': 16, 'subsample': 0.6649635766936816, 'colsample_bytree': 0.42868302626279764, 'gamma': 4.2993081195381375, 'reg_alpha': 0.4127956024648564, 'reg_lambda': 1.625440227814924e-05}. Best is trial 37 with value: 0.6686027559638464.\n",
      "[I 2024-09-22 20:46:47,856] Trial 49 finished with value: 0.6645132612238851 and parameters: {'n_estimators': 207, 'learning_rate': 0.09770722415035654, 'max_depth': 11, 'subsample': 0.6022479863008369, 'colsample_bytree': 0.701754774070361, 'gamma': 4.479000509134382, 'reg_alpha': 4.573377281411673, 'reg_lambda': 6.895950283565026e-05}. Best is trial 37 with value: 0.6686027559638464.\n",
      "[I 2024-09-22 20:46:50,681] Trial 50 finished with value: 0.6639205808267892 and parameters: {'n_estimators': 264, 'learning_rate': 0.0430534174576365, 'max_depth': 19, 'subsample': 0.5564670353411675, 'colsample_bytree': 0.48231489689895485, 'gamma': 4.7642639877522175, 'reg_alpha': 0.6684719035402886, 'reg_lambda': 1.012449366590317e-05}. Best is trial 37 with value: 0.6686027559638464.\n",
      "[I 2024-09-22 20:46:52,822] Trial 51 finished with value: 0.6668839828122686 and parameters: {'n_estimators': 333, 'learning_rate': 0.06726459299374908, 'max_depth': 18, 'subsample': 0.5306880127418769, 'colsample_bytree': 0.734324840376763, 'gamma': 4.4737737433614715, 'reg_alpha': 8.396262142354052, 'reg_lambda': 4.2920797607927644e-05}. Best is trial 37 with value: 0.6686027559638464.\n",
      "[I 2024-09-22 20:46:56,184] Trial 52 finished with value: 0.6582604830345236 and parameters: {'n_estimators': 345, 'learning_rate': 0.08166913150807524, 'max_depth': 18, 'subsample': 0.5320215563143355, 'colsample_bytree': 0.7587292547570335, 'gamma': 3.754316548498724, 'reg_alpha': 1.890547374927774, 'reg_lambda': 3.306877312170496e-05}. Best is trial 37 with value: 0.6686027559638464.\n",
      "[I 2024-09-22 20:46:57,712] Trial 53 finished with value: 0.6682175137057342 and parameters: {'n_estimators': 169, 'learning_rate': 0.05339223228160907, 'max_depth': 15, 'subsample': 0.6614731111777563, 'colsample_bytree': 0.5225538103237287, 'gamma': 4.494676447766342, 'reg_alpha': 8.426885036268633, 'reg_lambda': 2.02162364573295e-05}. Best is trial 37 with value: 0.6686027559638464.\n",
      "[I 2024-09-22 20:46:59,432] Trial 54 finished with value: 0.6658467921173506 and parameters: {'n_estimators': 179, 'learning_rate': 0.05402257061023776, 'max_depth': 13, 'subsample': 0.654936724712677, 'colsample_bytree': 0.5202212580102831, 'gamma': 4.1357465778532605, 'reg_alpha': 4.48680382256896, 'reg_lambda': 2.012820678443383e-05}. Best is trial 37 with value: 0.6686027559638464.\n",
      "[I 2024-09-22 20:47:02,177] Trial 55 finished with value: 0.6624388798340494 and parameters: {'n_estimators': 139, 'learning_rate': 0.03673434176075828, 'max_depth': 15, 'subsample': 0.6739461771836947, 'colsample_bytree': 0.5732863376695122, 'gamma': 4.999491282777685, 'reg_alpha': 0.0011435705195231044, 'reg_lambda': 1.0026699014642385e-05}. Best is trial 37 with value: 0.6686027559638464.\n",
      "[I 2024-09-22 20:47:05,336] Trial 56 finished with value: 0.664957771521707 and parameters: {'n_estimators': 230, 'learning_rate': 0.028398813416093068, 'max_depth': 12, 'subsample': 0.6848375180240633, 'colsample_bytree': 0.6149602546657819, 'gamma': 3.909199604591032, 'reg_alpha': 2.2123886540282185, 'reg_lambda': 7.358166486522583e-05}. Best is trial 37 with value: 0.6686027559638464.\n",
      "[I 2024-09-22 20:47:09,622] Trial 57 finished with value: 0.666795080752704 and parameters: {'n_estimators': 955, 'learning_rate': 0.04391115047183479, 'max_depth': 15, 'subsample': 0.6198975993558462, 'colsample_bytree': 0.4345476137255315, 'gamma': 4.769478037754555, 'reg_alpha': 9.703325635949604, 'reg_lambda': 0.000277758803299565}. Best is trial 37 with value: 0.6686027559638464.\n",
      "[I 2024-09-22 20:47:11,785] Trial 58 finished with value: 0.6652244777003999 and parameters: {'n_estimators': 135, 'learning_rate': 0.03625151390527921, 'max_depth': 17, 'subsample': 0.5923850397023286, 'colsample_bytree': 0.47556694172313096, 'gamma': 4.364942846581184, 'reg_alpha': 1.0357091278578536, 'reg_lambda': 0.47596138541062527}. Best is trial 37 with value: 0.6686027559638464.\n",
      "[I 2024-09-22 20:47:14,184] Trial 59 finished with value: 0.6622610757149208 and parameters: {'n_estimators': 191, 'learning_rate': 0.05964395769288789, 'max_depth': 19, 'subsample': 0.6319978858312179, 'colsample_bytree': 0.525424923809767, 'gamma': 4.771731317806161, 'reg_alpha': 0.21872712813049558, 'reg_lambda': 1.671265185694649e-05}. Best is trial 37 with value: 0.6686027559638464.\n",
      "[I 2024-09-22 20:47:17,511] Trial 60 finished with value: 0.6682175137057342 and parameters: {'n_estimators': 270, 'learning_rate': 0.013199454005849322, 'max_depth': 12, 'subsample': 0.6062474902763438, 'colsample_bytree': 0.5924571795599209, 'gamma': 4.515624746806986, 'reg_alpha': 4.573287720576803, 'reg_lambda': 2.8898000110936207e-05}. Best is trial 37 with value: 0.6686027559638464.\n",
      "[I 2024-09-22 20:47:21,032] Trial 61 finished with value: 0.66881019410283 and parameters: {'n_estimators': 285, 'learning_rate': 0.012844155928137755, 'max_depth': 12, 'subsample': 0.6091994974410853, 'colsample_bytree': 0.5585331697684806, 'gamma': 4.540814320246449, 'reg_alpha': 3.6761446694544437, 'reg_lambda': 2.9886247023454594e-05}. Best is trial 61 with value: 0.66881019410283.\n",
      "[I 2024-09-22 20:47:24,553] Trial 62 finished with value: 0.6693732404800711 and parameters: {'n_estimators': 280, 'learning_rate': 0.00825632738478534, 'max_depth': 11, 'subsample': 0.6057741286145659, 'colsample_bytree': 0.5872774730040421, 'gamma': 4.546409225676042, 'reg_alpha': 5.393412727127433, 'reg_lambda': 2.8042868741254796e-05}. Best is trial 62 with value: 0.6693732404800711.\n",
      "[I 2024-09-22 20:47:29,509] Trial 63 finished with value: 0.6685138539042822 and parameters: {'n_estimators': 439, 'learning_rate': 0.008766241093234556, 'max_depth': 11, 'subsample': 0.6470372412991351, 'colsample_bytree': 0.5567490595559067, 'gamma': 4.235966606011903, 'reg_alpha': 5.900886619012739, 'reg_lambda': 0.00012928084658432416}. Best is trial 62 with value: 0.6693732404800711.\n",
      "[I 2024-09-22 20:47:34,383] Trial 64 finished with value: 0.6687212920432657 and parameters: {'n_estimators': 437, 'learning_rate': 0.009026635144758618, 'max_depth': 11, 'subsample': 0.5660708844862136, 'colsample_bytree': 0.5623711012134462, 'gamma': 4.176418501017925, 'reg_alpha': 5.3915763788244995, 'reg_lambda': 0.00010922941494683168}. Best is trial 62 with value: 0.6693732404800711.\n",
      "[I 2024-09-22 20:47:42,618] Trial 65 finished with value: 0.6626759519928879 and parameters: {'n_estimators': 547, 'learning_rate': 0.01243168012968445, 'max_depth': 11, 'subsample': 0.5679399411410532, 'colsample_bytree': 0.6214468597349938, 'gamma': 3.667915873792188, 'reg_alpha': 1.2790068181140575, 'reg_lambda': 0.0012894419674478917}. Best is trial 62 with value: 0.6693732404800711.\n",
      "[I 2024-09-22 20:47:51,374] Trial 66 finished with value: 0.6631797303304193 and parameters: {'n_estimators': 443, 'learning_rate': 0.008685888229413467, 'max_depth': 9, 'subsample': 0.5531247995116882, 'colsample_bytree': 0.5588459521789486, 'gamma': 3.454111918773942, 'reg_alpha': 0.6424748973368828, 'reg_lambda': 0.000121297512137424}. Best is trial 62 with value: 0.6693732404800711.\n",
      "[I 2024-09-22 20:48:03,837] Trial 67 finished with value: 0.6637427767076604 and parameters: {'n_estimators': 429, 'learning_rate': 0.007990071747152308, 'max_depth': 11, 'subsample': 0.5856156973863506, 'colsample_bytree': 0.5996975038386685, 'gamma': 2.1463440115722117, 'reg_alpha': 2.1789727692252496, 'reg_lambda': 0.0004214506755276377}. Best is trial 62 with value: 0.6693732404800711.\n",
      "[I 2024-09-22 20:48:09,301] Trial 68 finished with value: 0.6686323899837013 and parameters: {'n_estimators': 364, 'learning_rate': 0.0060437498155086625, 'max_depth': 9, 'subsample': 0.6431641969533883, 'colsample_bytree': 0.6764457243157587, 'gamma': 4.261669898308924, 'reg_alpha': 3.7116894760890613, 'reg_lambda': 0.00019996031761322544}. Best is trial 62 with value: 0.6693732404800711.\n",
      "[I 2024-09-22 20:48:17,997] Trial 69 finished with value: 0.6658467921173506 and parameters: {'n_estimators': 304, 'learning_rate': 0.006057954992457659, 'max_depth': 9, 'subsample': 0.6473478506444704, 'colsample_bytree': 0.6697141037579446, 'gamma': 1.2705968478739273, 'reg_alpha': 3.5762940750512935, 'reg_lambda': 0.00020973835909620823}. Best is trial 62 with value: 0.6693732404800711.\n",
      "[I 2024-09-22 20:48:25,022] Trial 70 finished with value: 0.6653726477996741 and parameters: {'n_estimators': 374, 'learning_rate': 0.009140096200123937, 'max_depth': 10, 'subsample': 0.7016262387872692, 'colsample_bytree': 0.5443712859309596, 'gamma': 3.8987135602381344, 'reg_alpha': 0.9483960294386832, 'reg_lambda': 0.033533285376432305}. Best is trial 62 with value: 0.6693732404800711.\n",
      "[I 2024-09-22 20:48:31,336] Trial 71 finished with value: 0.6697584827381834 and parameters: {'n_estimators': 518, 'learning_rate': 0.004983315523177665, 'max_depth': 13, 'subsample': 0.6106857957877571, 'colsample_bytree': 0.5808598044555509, 'gamma': 4.30992302896286, 'reg_alpha': 6.062777929424166, 'reg_lambda': 6.003877366430758e-05}. Best is trial 71 with value: 0.6697584827381834.\n",
      "[I 2024-09-22 20:48:38,124] Trial 72 finished with value: 0.6676544673284932 and parameters: {'n_estimators': 512, 'learning_rate': 0.005658196034100368, 'max_depth': 13, 'subsample': 0.576747691445883, 'colsample_bytree': 0.6383068818127913, 'gamma': 4.248179592160449, 'reg_alpha': 3.684393587900524, 'reg_lambda': 6.231638621020862e-05}. Best is trial 71 with value: 0.6697584827381834.\n",
      "[I 2024-09-22 20:48:45,023] Trial 73 finished with value: 0.6691361683212328 and parameters: {'n_estimators': 467, 'learning_rate': 0.004816113806411817, 'max_depth': 11, 'subsample': 0.520617673018299, 'colsample_bytree': 0.5850476758819385, 'gamma': 4.044319486300504, 'reg_alpha': 2.255440344533801, 'reg_lambda': 0.00010144294710069742}. Best is trial 71 with value: 0.6697584827381834.\n",
      "[I 2024-09-22 20:48:51,304] Trial 74 finished with value: 0.6685731219439918 and parameters: {'n_estimators': 556, 'learning_rate': 0.004371995350403169, 'max_depth': 10, 'subsample': 0.5234867822457271, 'colsample_bytree': 0.5814937741495655, 'gamma': 4.188374485629618, 'reg_alpha': 5.603301042043878, 'reg_lambda': 0.00010854479529795294}. Best is trial 71 with value: 0.6697584827381834.\n",
      "[I 2024-09-22 20:48:58,530] Trial 75 finished with value: 0.6690769002815232 and parameters: {'n_estimators': 470, 'learning_rate': 0.004312867584391646, 'max_depth': 8, 'subsample': 0.5244531413159708, 'colsample_bytree': 0.5844048834651587, 'gamma': 3.4359953036790354, 'reg_alpha': 1.86404478965001, 'reg_lambda': 0.0006037682767124563}. Best is trial 71 with value: 0.6697584827381834.\n",
      "[I 2024-09-22 20:49:05,985] Trial 76 finished with value: 0.6687805600829753 and parameters: {'n_estimators': 480, 'learning_rate': 0.0037385808343022636, 'max_depth': 8, 'subsample': 0.5027117629498857, 'colsample_bytree': 0.6090282089006509, 'gamma': 3.464148281266632, 'reg_alpha': 2.2083016978885865, 'reg_lambda': 0.0006777714870879585}. Best is trial 71 with value: 0.6697584827381834.\n",
      "[I 2024-09-22 20:49:14,297] Trial 77 finished with value: 0.6673581271299451 and parameters: {'n_estimators': 474, 'learning_rate': 0.003778128251463004, 'max_depth': 8, 'subsample': 0.5007336059293925, 'colsample_bytree': 0.6862460191044425, 'gamma': 3.4288971507746053, 'reg_alpha': 1.6039013469332049, 'reg_lambda': 0.0007075260773365553}. Best is trial 71 with value: 0.6697584827381834.\n",
      "[I 2024-09-22 20:49:29,218] Trial 78 finished with value: 0.6675951992887834 and parameters: {'n_estimators': 532, 'learning_rate': 0.0031492181028529398, 'max_depth': 9, 'subsample': 0.5131849158030094, 'colsample_bytree': 0.636847997834634, 'gamma': 2.985325447722987, 'reg_alpha': 0.5657739647155752, 'reg_lambda': 0.0013694436146450245}. Best is trial 71 with value: 0.6697584827381834.\n",
      "[I 2024-09-22 20:49:39,905] Trial 79 finished with value: 0.6640687509260632 and parameters: {'n_estimators': 415, 'learning_rate': 0.004930805242908923, 'max_depth': 8, 'subsample': 0.5167443887471936, 'colsample_bytree': 0.6100222930564939, 'gamma': 2.7417262784795366, 'reg_alpha': 0.005828534177788207, 'reg_lambda': 0.00039643077827871125}. Best is trial 71 with value: 0.6697584827381834.\n",
      "[I 2024-09-22 20:49:45,265] Trial 80 finished with value: 0.6664098384945919 and parameters: {'n_estimators': 374, 'learning_rate': 0.006946905626581323, 'max_depth': 7, 'subsample': 0.5451768807776383, 'colsample_bytree': 0.7126311323292045, 'gamma': 3.9327922113113667, 'reg_alpha': 1.9954338497965862, 'reg_lambda': 0.0002442403254642502}. Best is trial 71 with value: 0.6697584827381834.\n",
      "[I 2024-09-22 20:49:58,294] Trial 81 finished with value: 0.6669432508519781 and parameters: {'n_estimators': 589, 'learning_rate': 0.0018642397140795485, 'max_depth': 12, 'subsample': 0.9332593173532903, 'colsample_bytree': 0.5860941025348895, 'gamma': 3.7416817733253263, 'reg_alpha': 2.525771597914005, 'reg_lambda': 0.0009349598644174809}. Best is trial 71 with value: 0.6697584827381834.\n",
      "[I 2024-09-22 20:50:07,531] Trial 82 finished with value: 0.6674173951696549 and parameters: {'n_estimators': 491, 'learning_rate': 0.0029987148438478835, 'max_depth': 9, 'subsample': 0.5233567371432218, 'colsample_bytree': 0.601451000933376, 'gamma': 4.009899324347787, 'reg_alpha': 1.1790340457848492, 'reg_lambda': 0.002530157323446245}. Best is trial 71 with value: 0.6697584827381834.\n",
      "[I 2024-09-22 20:50:14,949] Trial 83 finished with value: 0.6687212920432657 and parameters: {'n_estimators': 461, 'learning_rate': 0.004208615002453566, 'max_depth': 12, 'subsample': 0.5407823290362838, 'colsample_bytree': 0.6513616940591005, 'gamma': 3.316931420117119, 'reg_alpha': 4.0307897803447466, 'reg_lambda': 0.0004902737199780987}. Best is trial 71 with value: 0.6697584827381834.\n",
      "[I 2024-09-22 20:50:23,623] Trial 84 finished with value: 0.6683656838050082 and parameters: {'n_estimators': 466, 'learning_rate': 0.0034933045601905142, 'max_depth': 13, 'subsample': 0.5013540095869269, 'colsample_bytree': 0.628276239593267, 'gamma': 3.1573729692663886, 'reg_alpha': 2.7943774926368814, 'reg_lambda': 0.000475997095325432}. Best is trial 71 with value: 0.6697584827381834.\n",
      "[I 2024-09-22 20:50:33,403] Trial 85 finished with value: 0.6670617869313972 and parameters: {'n_estimators': 416, 'learning_rate': 0.004524855946186886, 'max_depth': 12, 'subsample': 0.5402269711347413, 'colsample_bytree': 0.6628623510234603, 'gamma': 3.545757807700653, 'reg_alpha': 1.4795115363258406, 'reg_lambda': 0.00034876782125662075}. Best is trial 71 with value: 0.6697584827381834.\n",
      "[I 2024-09-22 20:50:49,811] Trial 86 finished with value: 0.6626463179730331 and parameters: {'n_estimators': 509, 'learning_rate': 0.005373990627088295, 'max_depth': 10, 'subsample': 0.558824653853523, 'colsample_bytree': 0.6534592665014963, 'gamma': 3.2251000244126855, 'reg_alpha': 0.3120139682136292, 'reg_lambda': 0.0038654195740070413}. Best is trial 71 with value: 0.6697584827381834.\n",
      "[I 2024-09-22 20:51:08,704] Trial 87 finished with value: 0.6608386427618906 and parameters: {'n_estimators': 580, 'learning_rate': 0.006533153286471281, 'max_depth': 11, 'subsample': 0.5691237047894089, 'colsample_bytree': 0.6833513267122233, 'gamma': 3.3208112834170262, 'reg_alpha': 0.0003727890113875748, 'reg_lambda': 0.0001613700524310699}. Best is trial 71 with value: 0.6697584827381834.\n",
      "[I 2024-09-22 20:51:13,732] Trial 88 finished with value: 0.6664691065343014 and parameters: {'n_estimators': 395, 'learning_rate': 0.0026061472193512993, 'max_depth': 10, 'subsample': 0.5233331816027165, 'colsample_bytree': 0.5758791354382639, 'gamma': 3.685948874113851, 'reg_alpha': 6.8612001939423966, 'reg_lambda': 0.0017660683011502863}. Best is trial 71 with value: 0.6697584827381834.\n",
      "[I 2024-09-22 20:51:21,341] Trial 89 finished with value: 0.6678619054674767 and parameters: {'n_estimators': 666, 'learning_rate': 0.003933752304730783, 'max_depth': 6, 'subsample': 0.5496300774934195, 'colsample_bytree': 0.6065219563631186, 'gamma': 4.385413400127338, 'reg_alpha': 0.8896159422802115, 'reg_lambda': 0.0007302026698640415}. Best is trial 71 with value: 0.6697584827381834.\n",
      "[I 2024-09-22 20:51:45,240] Trial 90 finished with value: 0.6621129056156467 and parameters: {'n_estimators': 458, 'learning_rate': 0.003453329543644014, 'max_depth': 12, 'subsample': 0.5779109208411201, 'colsample_bytree': 0.5414368928541456, 'gamma': 2.6675452431511415, 'reg_alpha': 0.02681254560348051, 'reg_lambda': 9.230798519017369e-05}. Best is trial 71 with value: 0.6697584827381834.\n",
      "[I 2024-09-22 20:51:50,940] Trial 91 finished with value: 0.66881019410283 and parameters: {'n_estimators': 519, 'learning_rate': 0.0075909189960290824, 'max_depth': 9, 'subsample': 0.6014024620490593, 'colsample_bytree': 0.562620163172306, 'gamma': 4.053589476850363, 'reg_alpha': 4.67616502000057, 'reg_lambda': 0.0005759203036312628}. Best is trial 71 with value: 0.6697584827381834.\n",
      "[I 2024-09-22 20:51:56,854] Trial 92 finished with value: 0.66881019410283 and parameters: {'n_estimators': 534, 'learning_rate': 0.007905498633462573, 'max_depth': 8, 'subsample': 0.6144714149248411, 'colsample_bytree': 0.5564866323575917, 'gamma': 4.080551390025127, 'reg_alpha': 3.5409553348999876, 'reg_lambda': 0.0006399532562375403}. Best is trial 71 with value: 0.6697584827381834.\n",
      "[I 2024-09-22 20:52:02,283] Trial 93 finished with value: 0.6680693436064603 and parameters: {'n_estimators': 531, 'learning_rate': 0.007385692289511834, 'max_depth': 7, 'subsample': 0.5969888224585218, 'colsample_bytree': 0.5683232334394251, 'gamma': 4.070854487219787, 'reg_alpha': 6.413767106400521, 'reg_lambda': 0.000638251913729171}. Best is trial 71 with value: 0.6697584827381834.\n",
      "[I 2024-09-22 20:52:08,889] Trial 94 finished with value: 0.6650466735812713 and parameters: {'n_estimators': 638, 'learning_rate': 0.011937045247416437, 'max_depth': 8, 'subsample': 0.6129581785915139, 'colsample_bytree': 0.5887780336208832, 'gamma': 3.805120064955789, 'reg_alpha': 2.2182490468629648, 'reg_lambda': 0.0009801238380033625}. Best is trial 71 with value: 0.6697584827381834.\n",
      "[I 2024-09-22 20:52:15,487] Trial 95 finished with value: 0.6692547044006518 and parameters: {'n_estimators': 509, 'learning_rate': 0.0052288538586133925, 'max_depth': 11, 'subsample': 0.5821764302392134, 'colsample_bytree': 0.5534256358566118, 'gamma': 3.61429457036828, 'reg_alpha': 4.445804460355015, 'reg_lambda': 0.004551478436335987}. Best is trial 71 with value: 0.6697584827381834.\n",
      "[I 2024-09-22 20:52:20,260] Trial 96 finished with value: 0.6681878796858794 and parameters: {'n_estimators': 494, 'learning_rate': 0.009548404359815538, 'max_depth': 11, 'subsample': 0.5642658907928909, 'colsample_bytree': 0.553149004790407, 'gamma': 3.518947178110311, 'reg_alpha': 9.92523965241964, 'reg_lambda': 0.01860529051567326}. Best is trial 71 with value: 0.6697584827381834.\n",
      "[I 2024-09-22 20:52:26,624] Trial 97 finished with value: 0.6694325085197808 and parameters: {'n_estimators': 543, 'learning_rate': 0.0049068700395026085, 'max_depth': 8, 'subsample': 0.5860232874973368, 'colsample_bytree': 0.5055541360516476, 'gamma': 3.9705740975991977, 'reg_alpha': 3.404293951773278, 'reg_lambda': 0.009643558045754863}. Best is trial 71 with value: 0.6697584827381834.\n",
      "[I 2024-09-22 20:52:33,972] Trial 98 finished with value: 0.6687212920432656 and parameters: {'n_estimators': 745, 'learning_rate': 0.007366677291082841, 'max_depth': 7, 'subsample': 0.5840754019597731, 'colsample_bytree': 0.5020230521784504, 'gamma': 3.937446435590677, 'reg_alpha': 3.1557390034338892, 'reg_lambda': 0.06659619241188384}. Best is trial 71 with value: 0.6697584827381834.\n",
      "[I 2024-09-22 20:52:42,844] Trial 99 finished with value: 0.6674470291895096 and parameters: {'n_estimators': 589, 'learning_rate': 0.004772089427931807, 'max_depth': 8, 'subsample': 0.6126474655668868, 'colsample_bytree': 0.5329740831358788, 'gamma': 3.6026035351031096, 'reg_alpha': 1.6374790866843172, 'reg_lambda': 0.005003670683210682}. Best is trial 71 with value: 0.6697584827381834.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Reduced Features Optuna Tuned\n",
      "Best params: {'n_estimators': 518, 'learning_rate': 0.004983315523177665, 'max_depth': 13, 'subsample': 0.6106857957877571, 'colsample_bytree': 0.5808598044555509, 'gamma': 4.30992302896286, 'reg_alpha': 6.062777929424166, 'reg_lambda': 6.003877366430758e-05}\n",
      "Best score: 0.6697584827381834\n"
     ]
    }
   ],
   "source": [
    "# XGBoost Reduced Features\n",
    "xgb_reduced_params, xgb_reduced_best_score = tune_xgb(X_train_selected, y_train, tscv, \"accuracy\", RANDOM_SEED)\n",
    "\n",
    "print(\"XGBoost Reduced Features Optuna Tuned\")\n",
    "print(\"Best params:\", xgb_reduced_params)\n",
    "print(\"Best score:\", xgb_reduced_best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Reduced Features Optuna Tuned\n",
      "accuracy: 0.6697584827381834\n",
      "precision: 0.6671377748462455\n",
      "recall: 0.6782240136995322\n",
      "f1: 0.6724907446429867\n",
      "roc_auc: 0.7379171617379086\n"
     ]
    }
   ],
   "source": [
    "xgb_reduced_tuned = XGBClassifier(random_state=RANDOM_SEED, n_jobs=-1, **xgb_reduced_params)\n",
    "\n",
    "print(\"XGBoost Reduced Features Optuna Tuned\")\n",
    "xgb_reduced_tuned.fit(X_train_selected, y_train)\n",
    "\n",
    "# Cross validation\n",
    "xgb_reduced_tuned_scores = cross_validate(xgb_reduced_tuned, X_train_selected, y_train, cv=tscv, scoring=SCORING)\n",
    "\n",
    "for metric in SCORING:\n",
    "    print(f\"{metric}: {xgb_reduced_tuned_scores[f'test_{metric}'].mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Reduced Features Tuned Test Set\n",
      "Accuracy: 0.6004938271604938\n",
      "Precision: 0.5989887203422792\n",
      "Recall: 0.6083349792613075\n",
      "F1: 0.6036256736893679\n",
      "ROC-AUC: 0.6447931878169126\n"
     ]
    }
   ],
   "source": [
    "# Test set evaluation\n",
    "print(\"XGBoost Reduced Features Tuned Test Set\")\n",
    "evaluate_test_set(xgb_reduced_tuned, X_test_selected, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
